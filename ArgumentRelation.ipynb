{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucacontalbo/ArgumentRelation/blob/main/ArgumentRelation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky2et35Vyxhs",
        "outputId": "cfbdbb10-337b-42c3-9e69-348cbb07a56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFwY-xBMq1dR",
        "outputId": "717a28bf-53df-4e50-e8ed-fd46080707c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMNLyzTly41e",
        "outputId": "de7fbe56-2511-4c9e-fa23-e4d46466609e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1anU-7aAYPfQ-YWIA0AJDKz_AqkD19g_x/AttackSupport\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/AttackSupport/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tePLdrxvDTib",
        "outputId": "d1aa0127-1578-4826-e18c-1ba1508de504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "   print(\"Training on GPU\")\n",
        "   device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfqTHh1L6dA0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class dataset(Dataset):\n",
        "    \"\"\"wrap in PyTorch Dataset\"\"\"\n",
        "    def __init__(self, examples):\n",
        "        super(dataset, self).__init__()\n",
        "        self.examples = examples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.examples[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "\n",
        "def collate_fn(examples):\n",
        "    ids_sent1, segs_sent1, att_mask_sent1, ids_sent2, segs_sent2, att_mask_sent2, labels = map(list, zip(*examples))\n",
        "\n",
        "    ids_sent1 = torch.tensor(ids_sent1, dtype=torch.long)\n",
        "    segs_sent1 = torch.tensor(segs_sent1, dtype=torch.long)\n",
        "    att_mask_sent1 = torch.tensor(att_mask_sent1, dtype=torch.long)\n",
        "    ids_sent2 = torch.tensor(ids_sent2, dtype=torch.long)\n",
        "    segs_sent2 = torch.tensor(segs_sent2, dtype=torch.long)\n",
        "    att_mask_sent2 = torch.tensor(att_mask_sent2, dtype=torch.long)\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    return ids_sent1, segs_sent1, att_mask_sent1, ids_sent2, segs_sent2, att_mask_sent2, labels\n",
        "\n",
        "def collate_fn_concatenated(examples):\n",
        "    ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels = map(list, zip(*examples))\n",
        "\n",
        "    ids_sent1 = torch.tensor(ids_sent1, dtype=torch.long)\n",
        "    segs_sent1 = torch.tensor(segs_sent1, dtype=torch.long)\n",
        "    att_mask_sent1 = torch.tensor(att_mask_sent1, dtype=torch.long)\n",
        "    position_sep = torch.tensor(position_sep, dtype=torch.long)\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    return ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels\n",
        "\n",
        "def collate_fn_concatenated_adv(examples):\n",
        "    ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels = map(list, zip(*examples))\n",
        "\n",
        "    ids_sent1 = torch.tensor(ids_sent1, dtype=torch.long)\n",
        "    segs_sent1 = torch.tensor(segs_sent1, dtype=torch.long)\n",
        "    att_mask_sent1 = torch.tensor(att_mask_sent1, dtype=torch.long)\n",
        "    position_sep = torch.tensor(position_sep, dtype=torch.long)\n",
        "    #labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    return ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4y_C5W0r0Bl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import collections\n",
        "import codecs\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "\n",
        "class DataProcessor:\n",
        "\n",
        "  def __init__(self,):\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(args[\"model_name\"])\n",
        "    self.max_sent_len = 150\n",
        "\n",
        "  def __str__(self,):\n",
        "    pattern = \"\"\"General data processor: \\n\\n Tokenizer: {}\\n\\nMax sentence length: {}\"\"\".format(args[\"model_name\"], self.max_sent_len)\n",
        "    return pattern\n",
        "\n",
        "  def _get_examples(self, dataset, dataset_type=\"train\"):\n",
        "    examples = []\n",
        "\n",
        "    for row in dataset:\n",
        "      id, sentence1, sentence2, _, _, _, label = row\n",
        "\n",
        "      \"\"\"\n",
        "      for the first sentence\n",
        "      \"\"\"\n",
        "\n",
        "      ids_sent1 = self.tokenizer.encode(sentence1)\n",
        "      segs_sent1 = [0] * len(ids_sent1)\n",
        "      segs_sent1[1:-1] = [1] * (len(ids_sent1)-2)\n",
        "\n",
        "      \"\"\"\n",
        "      for the second sentence\n",
        "      \"\"\"\n",
        "\n",
        "      ids_sent2 = self.tokenizer.encode(sentence2)\n",
        "      segs_sent2 = [0] * len(ids_sent2)\n",
        "      segs_sent2[1:-1] = [1] * (len(ids_sent2)-2)\n",
        "\n",
        "      assert len(ids_sent1) == len(segs_sent1)\n",
        "      assert len(ids_sent2) == len(segs_sent2)\n",
        "\n",
        "      pad_id = self.tokenizer.encode(self.tokenizer.pad_token, add_special_tokens=False)[0]\n",
        "\n",
        "      if len(ids_sent1) < self.max_sent_len:\n",
        "        res = self.max_sent_len - len(ids_sent1)\n",
        "        att_mask_sent1 = [1] * len(ids_sent1) + [0] * res\n",
        "        ids_sent1 += [pad_id] * res\n",
        "        segs_sent1 += [0] * res\n",
        "      else:\n",
        "        ids_sent1 = ids_sent1[:self.max_sent_len]\n",
        "        segs_sent1 = segs_sent1[:self.max_sent_len]\n",
        "        att_mask_sent1 = [1] * self.max_sent_len\n",
        "\n",
        "      if len(ids_sent2) < self.max_sent_len:\n",
        "        res = self.max_sent_len - len(ids_sent2)\n",
        "        att_mask_sent2 = [1] * len(ids_sent2) + [0] * res\n",
        "        ids_sent2 += [pad_id] * res\n",
        "        segs_sent2 += [0] * res\n",
        "      else:\n",
        "        ids_sent2 = ids_sent2[:self.max_sent_len]\n",
        "        segs_sent2 = segs_sent2[:self.max_sent_len]\n",
        "        att_mask_sent2 = [1] * self.max_sent_len\n",
        "\n",
        "      example = [ids_sent1, segs_sent1, att_mask_sent1, ids_sent2, segs_sent2, att_mask_sent2, label]\n",
        "\n",
        "      examples.append(example)\n",
        "\n",
        "    print(f\"finished preprocessing examples in {dataset_type}\")\n",
        "\n",
        "    return examples\n",
        "\n",
        "  def _get_examples_concatenated(self, dataset, dataset_type=\"train\"):\n",
        "    examples = []\n",
        "\n",
        "    for row in tqdm(dataset, desc=\"tokenizing...\"):\n",
        "      id, sentence1, sentence2, _, _, _, label = row\n",
        "\n",
        "      \"\"\"\n",
        "      for the first sentence\n",
        "      \"\"\"\n",
        "\n",
        "      sentence1_length = len(self.tokenizer.encode(sentence1))\n",
        "      sentence2_length = len(self.tokenizer.encode(sentence2))\n",
        "      #sentence1 += \" </s> \"+sentence2\n",
        "\n",
        "      ids_sent1 = self.tokenizer.encode(sentence1, sentence2)\n",
        "      segs_sent1 = [0] * sentence1_length + [1] * (sentence2_length)\n",
        "      position_sep = [1] * len(ids_sent1)\n",
        "      position_sep[sentence1_length] = 1\n",
        "      position_sep[0] = 0\n",
        "      position_sep[1] = 1\n",
        "\n",
        "      assert len(ids_sent1) == len(position_sep)\n",
        "      assert len(ids_sent1) == len(segs_sent1)\n",
        "\n",
        "      pad_id = self.tokenizer.encode(self.tokenizer.pad_token, add_special_tokens=False)[0]\n",
        "\n",
        "      if len(ids_sent1) < self.max_sent_len:\n",
        "        res = self.max_sent_len - len(ids_sent1)\n",
        "        att_mask_sent1 = [1] * len(ids_sent1) + [0] * res\n",
        "        ids_sent1 += [pad_id] * res\n",
        "        segs_sent1 += [0] * res\n",
        "        position_sep += [0] * res\n",
        "      else:\n",
        "        ids_sent1 = ids_sent1[:self.max_sent_len]\n",
        "        segs_sent1 = segs_sent1[:self.max_sent_len]\n",
        "        att_mask_sent1 = [1] * self.max_sent_len\n",
        "        position_sep = position_sep[:self.max_sent_len]\n",
        "\n",
        "      example = [ids_sent1, segs_sent1, att_mask_sent1, position_sep, label]\n",
        "\n",
        "      examples.append(example)\n",
        "\n",
        "    print(f\"finished preprocessing examples in {dataset_type}\")\n",
        "\n",
        "    return examples\n",
        "\n",
        "class DiscourseMarkerProcessor(DataProcessor):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(DiscourseMarkerProcessor, self).__init__()\n",
        "    #https://pdf.sciencedirectassets.com/271806/1-s2.0-S0378216600X00549/1-s2.0-S0378216698001015/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGgaCXVzLWVhc3QtMSJIMEYCIQCiYMlVmna%2BTaXH5hqdwfhEBWd2VPRNoAHlQLGxzvNEqAIhAO3TVTA51qn13kKQp2bTlzGkaKnf6NhMYtr7laU%2Byy0vKrwFCMH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBRoMMDU5MDAzNTQ2ODY1Igzyz%2F2NAMoW0RbAZ%2BMqkAWG017si0y%2FOokz5T44gGpNBL07jup8MAQjv8iwoi4XGALwCP0nf%2FgHD1ZE%2B%2BQGuaLPuShgLg7Y3%2Fcsv2VjkbfrNBSdZPYhqpzpAClSmP2Zs0DszX0zXdmnx4uFyls6d9jCG4TQkhqTsNCGsnKjU89G7z9NMutpaWqEGcUWT6MVMXpxILGQfeu5zLM0ILcft20VXs2dnMMIjWXA5jd0pG8HnAXdils2AmfgTqt%2B9cHn5BXhv%2FaSXX9a7lwR7EbIoUqZVLo%2BDJR2JLtaLYdoZR01FI3FhNAk7Hx1ZLd3RSWWQrRy3ovGKbKnTYC8Jn%2Bs1w1tkF4OJzCy7EZg578HFrPsvxQrUGwtkXfY1BIralzc9JmYZ%2FS1VPIVSvZSM6E3sUUIND14uQDKhQyTQh6WBbG1djkU8M9bW%2ByVDRj8CKEoWdN4ofK3WuRD87QQEAJQ8jwnl0rCtVIYecZyfQzTnpdO0jafDlritW%2BlfSDqyd8ob%2F%2BkljgtN1m8IFKNQ9lopVjvwCzDa5R%2F0WvchF%2BqNMzImVtUHTgXgJOcGC6y9OSVqRGFgQtPhy6W26WodWQxaFsBMTn49dM6rzsyNhd301U4SYL5vTLrLhjmm3%2Ft5JqKHS7JaAbmKYa4DvabWH4Qs2WHsZMxVd8L3KU%2FIeyaQwATOf3TZVCVPWUriUg%2FAKFcuceC1AaUE5MKWB8Qe2Cb5%2FpagPPYTztfNluPar21xLpY7cayKABv%2FkyIa2N9MsaPm8VEvSb90Sl1EkJAxXP3kVU2XTtZqcYPuHgdSyUwh%2FDC%2F0Y1FlLyZW%2BLrnVmL9sqtORiZcZU20jVgXM8HoLIG2vvo0er4qyok9ZxzykuzhClN6ZULz%2FTja1y%2FdhF2UR89jCk%2BuOxBjqwARYSDjyJE7HksxP39FMsgAM0RH2Us2vj22eV6lkbG1n1%2BZm%2B4a4UeUfzibr4B6BdF%2BB3i%2FHsJ3QF1AnxdSS%2F0x5HnBmGCct1etAdyP60bbBH8p1dCgNQL7kb%2BqKINd78nYfrM0D0a4U%2Fxm2FUNln3swIdVpXtLtz0qY2QSaHbc6Ir6BCR8Kqm0FKQyhv1JSMkKfIdFQ9pYCVy8VAr%2BLBA9uSXfFDz6N67ruhh%2BzJWFn1&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20240506T173714Z&X-Amz-SignedHeaders=host&X-Amz-Expires=299&X-Amz-Credential=ASIAQ3PHCVTYUU54IYV3%2F20240506%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=7303563def203481e9802185fa8eab7dd21d58c841cd92621bbbdb18e253f595&hash=62697dff1cc869850b2d38305ff2ad1a35ad33938dbb92466663bdb1bf67d069&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0378216698001015&tid=spdf-c2371d97-52db-456d-a333-31d65dde09f3&sid=c8e761cb3c79f3499a2a90d699ea19871d47gxrqb&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=091359520307070d01&rr=87fabcafde0b0e1b&cc=it\n",
        "    # TODO: refactor\n",
        "    self.mapping = elements_dict = {\n",
        "      \"accordingly\": 0,\n",
        "      \"also\": 1,\n",
        "      \"although\": 2,\n",
        "      \"and\": 1,\n",
        "      \"as_a_result\": 0,\n",
        "      \"because_of_that\": 0,\n",
        "      \"because_of_this\": 0,\n",
        "      \"besides\": 0,\n",
        "      \"but\": 2,\n",
        "      \"by_comparison\": 2,\n",
        "      \"by_contrast\": 2,\n",
        "      \"consequently\": 0,\n",
        "      \"conversely\": 0,\n",
        "      \"especially\": 1,\n",
        "      \"further\": 1,\n",
        "      \"furthermore\": 1,\n",
        "      \"hence\": 0,\n",
        "      \"however\": 2,\n",
        "      \"in_contrast\": 2,\n",
        "      \"instead\": 2,\n",
        "      \"likewise\": 1,\n",
        "      \"moreover\": 1,\n",
        "      \"namely\": 1,\n",
        "      \"nevertheless\": 2,\n",
        "      \"nonetheless\": 2,\n",
        "      \"on_the_contrary\": 2,\n",
        "      \"on_the_other_hand\": 2,\n",
        "      \"otherwise\": 1,\n",
        "      \"rather\": 2,\n",
        "      \"similarly\": 1,\n",
        "      \"so\": 0,\n",
        "      \"still\": 2,\n",
        "      \"then\": 0,\n",
        "      \"therefore\": 0,\n",
        "      \"though\": 2,\n",
        "      \"thus\": 0,\n",
        "      \"well\": 1,\n",
        "      \"yet\": 2\n",
        "    }\n",
        "\n",
        "    \"\"\"self.mapping = elements_dict = {\n",
        "      \"accordingly\": 0,\n",
        "      \"also\": 0,\n",
        "      \"although\": 1,\n",
        "      \"and\": 0,\n",
        "      \"as_a_result\": 0,\n",
        "      \"because_of_that\": 0,\n",
        "      \"because_of_this\": 0,\n",
        "      \"besides\": 0,\n",
        "      \"but\": 1,\n",
        "      \"by_comparison\": 1,\n",
        "      \"by_contrast\": 1,\n",
        "      \"consequently\": 0,\n",
        "      \"conversely\": 0,\n",
        "      \"especially\": 0,\n",
        "      \"further\": 0,\n",
        "      \"furthermore\": 0,\n",
        "      \"hence\": 0,\n",
        "      \"however\": 1,\n",
        "      \"in_contrast\": 1,\n",
        "      \"instead\": 1,\n",
        "      \"likewise\": 0,\n",
        "      \"moreover\": 0,\n",
        "      \"namely\": 0,\n",
        "      \"nevertheless\": 1,\n",
        "      \"nonetheless\": 1,\n",
        "      \"on_the_contrary\": 1,\n",
        "      \"on_the_other_hand\": 1,\n",
        "      \"otherwise\": 0,\n",
        "      \"rather\": 1,\n",
        "      \"similarly\": 0,\n",
        "      \"so\": 0,\n",
        "      \"still\": 1,\n",
        "      \"then\": 0,\n",
        "      \"therefore\": 0,\n",
        "      \"though\": 1,\n",
        "      \"thus\": 0,\n",
        "      \"well\": 0,\n",
        "      \"yet\": 1\n",
        "    }\"\"\"\n",
        "\n",
        "    self.id_to_word = {\n",
        "      0: 'no-conn',\n",
        "      1: 'absolutely',\n",
        "      2: 'accordingly',\n",
        "      3: 'actually',\n",
        "      4: 'additionally',\n",
        "      5: 'admittedly',\n",
        "      6: 'afterward',\n",
        "      7: 'again',\n",
        "      8: 'already',\n",
        "      9: 'also',\n",
        "      10: 'alternately',\n",
        "      11: 'alternatively',\n",
        "      12: 'although',\n",
        "      13: 'altogether',\n",
        "      14: 'amazingly',\n",
        "      15: 'and',\n",
        "      16: 'anyway',\n",
        "      17: 'apparently',\n",
        "      18: 'arguably',\n",
        "      19: 'as_a_result',\n",
        "      20: 'basically',\n",
        "      21: 'because_of_that',\n",
        "      22: 'because_of_this',\n",
        "      23: 'besides',\n",
        "      24: 'but',\n",
        "      25: 'by_comparison',\n",
        "      26: 'by_contrast',\n",
        "      27: 'by_doing_this',\n",
        "      28: 'by_then',\n",
        "      29: 'certainly',\n",
        "      30: 'clearly',\n",
        "      31: 'coincidentally',\n",
        "      32: 'collectively',\n",
        "      33: 'consequently',\n",
        "      34: 'conversely',\n",
        "      35: 'curiously',\n",
        "      36: 'currently',\n",
        "      37: 'elsewhere',\n",
        "      38: 'especially',\n",
        "      39: 'essentially',\n",
        "      40: 'eventually',\n",
        "      41: 'evidently',\n",
        "      42: 'finally',\n",
        "      43: 'first',\n",
        "      44: 'firstly',\n",
        "      45: 'for_example',\n",
        "      46: 'for_instance',\n",
        "      47: 'fortunately',\n",
        "      48: 'frankly',\n",
        "      49: 'frequently',\n",
        "      50: 'further',\n",
        "      51: 'furthermore',\n",
        "      52: 'generally',\n",
        "      53: 'gradually',\n",
        "      54: 'happily',\n",
        "      55: 'hence',\n",
        "      56: 'here',\n",
        "      57: 'historically',\n",
        "      58: 'honestly',\n",
        "      59: 'hopefully',\n",
        "      60: 'however',\n",
        "      61: 'ideally',\n",
        "      62: 'immediately',\n",
        "      63: 'importantly',\n",
        "      64: 'in_contrast',\n",
        "      65: 'in_fact',\n",
        "      66: 'in_other_words',\n",
        "      67: 'in_particular',\n",
        "      68: 'in_short',\n",
        "      69: 'in_sum',\n",
        "      70: 'in_the_end',\n",
        "      71: 'in_the_meantime',\n",
        "      72: 'in_turn',\n",
        "      73: 'incidentally',\n",
        "      74: 'increasingly',\n",
        "      75: 'indeed',\n",
        "      76: 'inevitably',\n",
        "      77: 'initially',\n",
        "      78: 'instead',\n",
        "      79: 'interestingly',\n",
        "      80: 'ironically',\n",
        "      81: 'lastly',\n",
        "      82: 'lately',\n",
        "      83: 'later',\n",
        "      84: 'likewise',\n",
        "      85: 'locally',\n",
        "      86: 'luckily',\n",
        "      87: 'maybe',\n",
        "      88: 'meaning',\n",
        "      89: 'meantime',\n",
        "      90: 'meanwhile',\n",
        "      91: 'moreover',\n",
        "      92: 'mostly',\n",
        "      93: 'namely',\n",
        "      94: 'nationally',\n",
        "      95: 'naturally',\n",
        "      96: 'nevertheless',\n",
        "      97: 'next',\n",
        "      98: 'nonetheless',\n",
        "      99: 'normally',\n",
        "      100: 'notably',\n",
        "      101: 'now',\n",
        "      102: 'obviously',\n",
        "      103: 'occasionally',\n",
        "      104: 'oddly',\n",
        "      105: 'often',\n",
        "      106: 'on_the_contrary',\n",
        "      107: 'on_the_other_hand',\n",
        "      108: 'once',\n",
        "      109: 'only',\n",
        "      110: 'optionally',\n",
        "      111: 'or',\n",
        "      112: 'originally',\n",
        "      113: 'otherwise',\n",
        "      114: 'overall',\n",
        "      115: 'particularly',\n",
        "      116: 'perhaps',\n",
        "      117: 'personally',\n",
        "      118: 'plus',\n",
        "      119: 'preferably',\n",
        "      120: 'presently',\n",
        "      121: 'presumably',\n",
        "      122: 'previously',\n",
        "      123: 'probably',\n",
        "      124: 'rather',\n",
        "      125: 'realistically',\n",
        "      126: 'really',\n",
        "      127: 'recently',\n",
        "      128: 'regardless',\n",
        "      129: 'remarkably',\n",
        "      130: 'sadly',\n",
        "      131: 'second',\n",
        "      132: 'secondly',\n",
        "      133: 'separately',\n",
        "      134: 'seriously',\n",
        "      135: 'significantly',\n",
        "      136: 'similarly',\n",
        "      137: 'simultaneously',\n",
        "      138: 'slowly',\n",
        "      139: 'so',\n",
        "      140: 'sometimes',\n",
        "      141: 'soon',\n",
        "      142: 'specifically',\n",
        "      143: 'still',\n",
        "      144: 'strangely',\n",
        "      145: 'subsequently',\n",
        "      146: 'suddenly',\n",
        "      147: 'supposedly',\n",
        "      148: 'surely',\n",
        "      149: 'surprisingly',\n",
        "      150: 'technically',\n",
        "      151: 'thankfully',\n",
        "      152: 'then',\n",
        "      153: 'theoretically',\n",
        "      154: 'thereafter',\n",
        "      155: 'thereby',\n",
        "      156: 'therefore',\n",
        "      157: 'third',\n",
        "      158: 'thirdly',\n",
        "      159: 'this',\n",
        "      160: 'though',\n",
        "      161: 'thus',\n",
        "      162: 'together',\n",
        "      163: 'traditionally',\n",
        "      164: 'truly',\n",
        "      165: 'truthfully',\n",
        "      166: 'typically',\n",
        "      167: 'ultimately',\n",
        "      168: 'undoubtedly',\n",
        "      169: 'unfortunately',\n",
        "      170: 'unsurprisingly',\n",
        "      171: 'usually',\n",
        "      172: 'well',\n",
        "      173: 'yet'\n",
        "    }\n",
        "\n",
        "\n",
        "  def process_dataset(self, dataset, name=\"train\"):\n",
        "    result = []\n",
        "    new_dataset = []\n",
        "\n",
        "    for sample in dataset:\n",
        "      if self.id_to_word[sample[\"label\"]] not in self.mapping.keys():\n",
        "        continue\n",
        "\n",
        "      new_dataset.append([sample[\"sentence1\"], sample[\"sentence2\"], self.mapping[self.id_to_word[sample[\"label\"]]]])\n",
        "\n",
        "    one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "    labels = []\n",
        "\n",
        "    for i, sample in tqdm(enumerate(new_dataset), desc=\"processing labels...\"):\n",
        "      labels.append([sample[-1]])\n",
        "\n",
        "    print(\"one hot encoding...\")\n",
        "    labels = one_hot_encoder.fit_transform(labels)\n",
        "\n",
        "    for i, (sample, label) in tqdm(enumerate(zip(new_dataset, labels)), desc=\"creating results...\"):\n",
        "      result.append([f\"{name}_{i}\", sample[0], sample[1], [], [], [], label])\n",
        "\n",
        "    examples = self._get_examples_concatenated(result, name)\n",
        "    return examples\n",
        "\n",
        "\n",
        "class StudentEssayProcessor(DataProcessor):\n",
        "\n",
        "  def __init__(self,):\n",
        "    super(StudentEssayProcessor,self).__init__()\n",
        "\n",
        "  def padding(self, input, maxlen):\n",
        "      \"\"\"\n",
        "      Padding the input sequence\n",
        "      \"\"\"\n",
        "\n",
        "      id, sentences, target, source_sentiment, target_sentiment, knowledge, label_distribution = zip(*input)\n",
        "\n",
        "      sentences = torch.nn.utils.rnn.pad_sequence([torch.tensor(s) for s in sentences], batch_first=True, padding_value=0)\n",
        "      knowledge = torch.nn.utils.rnn.pad_sequence([torch.tensor(k) for k in knowledge], batch_first=True, padding_value=0)\n",
        "      target = torch.nn.utils.rnn.pad_sequence([torch.tensor(t) for t in target], batch_first=True, padding_value=0)\n",
        "\n",
        "      return list(zip(sentences, knowledge, target, label_distribution))\n",
        "\n",
        "\n",
        "  def create_batches_of_sentence_ids(self, sentences, batch_equal_size, max_batch_size):\n",
        "      \"\"\"\n",
        "      Groups together sentences into batches\n",
        "      If max_batch_size is positive, this value determines the maximum number of sentences in each batch.\n",
        "      If max_batch_size has a negative value, the function dynamically creates the batches such that each batch contains abs(max_batch_size) words.\n",
        "      Returns a list of lists with sentences ids.\n",
        "      \"\"\"\n",
        "      batches_of_sentence_ids = []\n",
        "      if batch_equal_size == True:\n",
        "          sentence_ids_by_length = collections.OrderedDict()\n",
        "          sentence_length_sum = 0.0\n",
        "          for i in range(len(sentences)):\n",
        "              length = len(sentences[i])\n",
        "              if length not in sentence_ids_by_length:\n",
        "                  sentence_ids_by_length[length] = []\n",
        "              sentence_ids_by_length[length].append(i)\n",
        "\n",
        "          for sentence_length in sentence_ids_by_length:\n",
        "              if max_batch_size > 0:\n",
        "                  batch_size = max_batch_size\n",
        "              else:\n",
        "                  batch_size = int((-1 * max_batch_size) / sentence_length)\n",
        "\n",
        "              for i in range(0, len(sentence_ids_by_length[sentence_length]), batch_size):\n",
        "                  batches_of_sentence_ids.append(sentence_ids_by_length[sentence_length][i:i + batch_size])\n",
        "      else:\n",
        "          current_batch = []\n",
        "          max_sentence_length = 0\n",
        "          for i in range(len(sentences)):\n",
        "              current_batch.append(i)\n",
        "              if len(sentences[i]) > max_sentence_length:\n",
        "                  max_sentence_length = len(sentences[i])\n",
        "              if (max_batch_size > 0 and len(current_batch) >= max_batch_size) \\\n",
        "                or (max_batch_size <= 0 and len(current_batch)*max_sentence_length >= (-1 * max_batch_size)):\n",
        "                  batches_of_sentence_ids.append(current_batch)\n",
        "                  current_batch = []\n",
        "                  max_sentence_length = 0\n",
        "          if len(current_batch) > 0:\n",
        "              batches_of_sentence_ids.append(current_batch)\n",
        "      return batches_of_sentence_ids\n",
        "\n",
        "\n",
        "  def read_input_files(self, file_path, max_sentence_length=-1, name=\"train\"):\n",
        "      \"\"\"\n",
        "      Reads input files in tab-separated format.\n",
        "      Will split file_paths on comma, reading from multiple files.\n",
        "      \"\"\"\n",
        "\n",
        "      # Code copied from https://aclanthology.org/2023.eacl-main.182.pdf\n",
        "      # TODO: refactor, several objects are not needed\n",
        "\n",
        "      sentences = []\n",
        "      labels = []\n",
        "      label_distribution=[]\n",
        "      target = []\n",
        "      knowledge = []\n",
        "      story_id_know=[]\n",
        "      lst2=[]\n",
        "      target_sentences = []\n",
        "      source_senti = []\n",
        "      target_senti = []\n",
        "      id=[]\n",
        "      count = 0\n",
        "\n",
        "      with codecs.open(file_path, encoding=\"ISO-8859-1\", mode=\"r\") as f:\n",
        "        for line in f:\n",
        "              know =[]\n",
        "              #print(line)\n",
        "              count +=1\n",
        "              #print(count)\n",
        "              line = line.replace(\"\\n\",\"\")\n",
        "              line = line.split(\"\\t\")\n",
        "\n",
        "              if line == ['\\r']:\n",
        "                      continue\n",
        "              count +=1\n",
        "              story_id = line[0]\n",
        "              sent = line[1].strip()\n",
        "              target = line[3].strip()\n",
        "              #print(target)\n",
        "              label = line[-1].strip()\n",
        "              facts = line[-2].strip()\n",
        "\n",
        "              facts = facts.replace(\"_\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"(\", \"\").replace(\"(\", \"\")\n",
        "\n",
        "              lst2.append(facts)\n",
        "\n",
        "              sentences.append(sent)\n",
        "              target_sentences.append(target)\n",
        "              id.append(story_id)\n",
        "\n",
        "              l=[0,0]\n",
        "              if label == 'supports' or label == 'support' or label == 'because':\n",
        "                    l=[1,0]\n",
        "              elif label == 'attacks' or label == 'attack' or label == 'but':\n",
        "                    l=[0,1]\n",
        "              label_distribution.append(l)\n",
        "\n",
        "      result = []\n",
        "      for i in range(len(label_distribution)):\n",
        "        result.append([id[i],sentences[i],target_sentences[i], [], [], lst2[i], label_distribution[i]])\n",
        "\n",
        "      examples = self._get_examples_concatenated(result, name)\n",
        "\n",
        "      return examples\n",
        "\n",
        "class DebateProcessor(DataProcessor):\n",
        "\n",
        "  def __init__(self,):\n",
        "    super(DebateProcessor,self).__init__()\n",
        "\n",
        "  def padding(self, input, maxlen):\n",
        "      \"\"\"\n",
        "      Padding the input sequence.....\n",
        "      \"\"\"\n",
        "\n",
        "      id, sentences, target, source_sentiment, target_sentiment, knowledge, label_distribution = zip(*input)\n",
        "\n",
        "      sentences = torch.nn.utils.rnn.pad_sequence([torch.tensor(s) for s in sentences], batch_first=True, padding_value=0)\n",
        "      knowledge = torch.nn.utils.rnn.pad_sequence([torch.tensor(k) for k in knowledge], batch_first=True, padding_value=0)\n",
        "      target = torch.nn.utils.rnn.pad_sequence([torch.tensor(t) for t in target], batch_first=True, padding_value=0)\n",
        "\n",
        "      return list(zip(sentences, knowledge, target, label_distribution))\n",
        "\n",
        "\n",
        "  def create_batches_of_sentence_ids(self, sentences, batch_equal_size, max_batch_size):\n",
        "      \"\"\"\n",
        "      Groups together sentences into batches\n",
        "      If max_batch_size is positive, this value determines the maximum number of sentences in each batch.\n",
        "      If max_batch_size has a negative value, the function dynamically creates the batches such that each batch contains abs(max_batch_size) words.\n",
        "      Returns a list of lists with sentences ids.\n",
        "      \"\"\"\n",
        "      batches_of_sentence_ids = []\n",
        "      if batch_equal_size == True:\n",
        "          sentence_ids_by_length = collections.OrderedDict()\n",
        "          sentence_length_sum = 0.0\n",
        "          for i in range(len(sentences)):\n",
        "              length = len(sentences[i])\n",
        "              if length not in sentence_ids_by_length:\n",
        "                  sentence_ids_by_length[length] = []\n",
        "              sentence_ids_by_length[length].append(i)\n",
        "\n",
        "          for sentence_length in sentence_ids_by_length:\n",
        "              if max_batch_size > 0:\n",
        "                  batch_size = max_batch_size\n",
        "              else:\n",
        "                  batch_size = int((-1 * max_batch_size) / sentence_length)\n",
        "\n",
        "              for i in range(0, len(sentence_ids_by_length[sentence_length]), batch_size):\n",
        "                  batches_of_sentence_ids.append(sentence_ids_by_length[sentence_length][i:i + batch_size])\n",
        "      else:\n",
        "          current_batch = []\n",
        "          max_sentence_length = 0\n",
        "          for i in range(len(sentences)):\n",
        "              current_batch.append(i)\n",
        "              if len(sentences[i]) > max_sentence_length:\n",
        "                  max_sentence_length = len(sentences[i])\n",
        "              if (max_batch_size > 0 and len(current_batch) >= max_batch_size) \\\n",
        "                or (max_batch_size <= 0 and len(current_batch)*max_sentence_length >= (-1 * max_batch_size)):\n",
        "                  batches_of_sentence_ids.append(current_batch)\n",
        "                  current_batch = []\n",
        "                  max_sentence_length = 0\n",
        "          if len(current_batch) > 0:\n",
        "              batches_of_sentence_ids.append(current_batch)\n",
        "      return batches_of_sentence_ids\n",
        "\n",
        "\n",
        "  def read_input_files(self, file_path, max_sentence_length=-1, name=\"train\"):\n",
        "      \"\"\"\n",
        "      Reads input files in tab-separated format.\n",
        "      Will split file_paths on comma, reading from multiple files.\n",
        "      \"\"\"\n",
        "      sentences = []\n",
        "      labels = []\n",
        "      label_distribution=[]\n",
        "      target = []\n",
        "      knowledge = []\n",
        "      story_id_know=[]\n",
        "      lst2=[]\n",
        "      target_sentences = []\n",
        "      source_senti = []\n",
        "      target_senti = []\n",
        "      id=[]\n",
        "      count = 0\n",
        "\n",
        "      with codecs.open(file_path, encoding=\"ISO-8859-1\", mode=\"r\") as f:\n",
        "        for line in f:\n",
        "              know =[]\n",
        "              #print(line)\n",
        "              count +=1\n",
        "              #print(count)\n",
        "              line = line.replace(\"\\n\",\"\")\n",
        "              line = line.split(\"\\t\")\n",
        "\n",
        "              if line == ['\\r']:\n",
        "                      continue\n",
        "              count +=1\n",
        "              story_id = line[0]\n",
        "              sent = line[1].strip()\n",
        "              target = line[3].strip()\n",
        "              #print(target)\n",
        "              label = line[-1].strip()\n",
        "              facts = line[-2].strip()\n",
        "\n",
        "              facts = facts.replace(\"_\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"(\", \"\").replace(\"(\", \"\")\n",
        "\n",
        "              lst2.append(facts)\n",
        "\n",
        "              sentences.append(sent)\n",
        "              target_sentences.append(target)\n",
        "              id.append(story_id)\n",
        "\n",
        "              l=[0,0]\n",
        "              if label == 'supports' or label == 'support' or label == 'because':\n",
        "                    l=[1,0]\n",
        "              elif label == 'attacks' or label == 'attack' or label == 'but':\n",
        "                    l=[0,1]\n",
        "              label_distribution.append(l)\n",
        "              #print(label_distribution)\n",
        "\n",
        "      result = []\n",
        "      for i in range(len(label_distribution)):\n",
        "        result.append([id[i],sentences[i],target_sentences[i], [], [], lst2[i], label_distribution[i]])\n",
        "\n",
        "      examples = self._get_examples_concatenated(result, name)\n",
        "\n",
        "      return examples\n",
        "\n",
        "\n",
        "class MARGProcessor(DataProcessor):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MARGProcessor, self).__init__()\n",
        "    self.pipe = pipeline(\"text-classification\", model=\"sileod/roberta-base-discourse-marker-prediction\")\n",
        "\n",
        "  def read_input_files(self, file_path, max_sent_length=-1, name=\"train\"):\n",
        "      \"\"\"\n",
        "      Reads input files in tab-separated format.\n",
        "      Will split file_paths on comma, reading from multiple files.\n",
        "      \"\"\"\n",
        "\n",
        "      # Code copied from https://aclanthology.org/2023.eacl-main.182.pdf\n",
        "      # TODO: refactor, several objects are not needed\n",
        "\n",
        "      sentences = []\n",
        "      labels = []\n",
        "      label_distribution=[]\n",
        "      target = []\n",
        "      knowledge = []\n",
        "      story_id_know=[]\n",
        "      lst2=[]\n",
        "      target_sentences = []\n",
        "      source_senti = []\n",
        "      target_senti = []\n",
        "      id=[]\n",
        "      count = 0\n",
        "\n",
        "      df = pd.read_csv(file_path)\n",
        "      for i,row in df.iterrows():\n",
        "              if row[-1] != name:\n",
        "                continue\n",
        "              know =[]\n",
        "              #print(line)\n",
        "              count +=1\n",
        "              #print(count)\n",
        "\n",
        "              count +=1\n",
        "              story_id = row[0]\n",
        "              sent = row[1].strip()\n",
        "              target = row[2].strip()\n",
        "\n",
        "              ds_marker = self.pipe(f\"{sent}</s></s>{target}\")[0][\"label\"]\n",
        "              ds_marker = ds_marker.replace(\"_\", \" \")\n",
        "              ds_marker = ds_marker[0].upper() + ds_marker[1:]\n",
        "              target = target[0].lower() + target[1:]\n",
        "              target = ds_marker + \" \" + target\n",
        "\n",
        "              #print(target)\n",
        "              label = row[3].strip()\n",
        "              facts = row[-3].strip()\n",
        "\n",
        "              facts = facts.replace(\"_\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"(\", \"\").replace(\"(\", \"\")\n",
        "\n",
        "              lst2.append(facts)\n",
        "\n",
        "              sentences.append(sent)\n",
        "              target_sentences.append(target)\n",
        "              id.append(story_id)\n",
        "\n",
        "              l=[0,0,0]\n",
        "              if label == 'supports' or label == 'support' or label == 'because':\n",
        "                l = [1,0,0]\n",
        "              elif label == 'attacks' or label == 'attack' or label == 'but':\n",
        "                l = [0,1,0]\n",
        "              elif label == 'neither':\n",
        "                l = [0,0,1]\n",
        "\n",
        "              label_distribution.append(l)\n",
        "\n",
        "      result = []\n",
        "      for i in range(len(label_distribution)):\n",
        "        result.append([id[i],sentences[i],target_sentences[i], [], [], lst2[i], label_distribution[i]])\n",
        "\n",
        "      examples = self._get_examples_concatenated(result, name)\n",
        "\n",
        "      return examples\n",
        "\n",
        "class NKProcessor(DataProcessor):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(NKProcessor, self).__init__()\n",
        "\n",
        "  def read_input_files(self, file_path, max_sent_length=-1, name=\"train\"):\n",
        "      \"\"\"\n",
        "      Reads input files in tab-separated format.\n",
        "      Will split file_paths on comma, reading from multiple files.\n",
        "      \"\"\"\n",
        "\n",
        "      sentences = []\n",
        "      label_distribution=[]\n",
        "      target = []\n",
        "      target_sentences = []\n",
        "      id=[]\n",
        "\n",
        "      df = pd.read_csv(file_path, sep=\"\\t\")\n",
        "      for i,row in df.iterrows():\n",
        "              id_sample = row[0]\n",
        "              label = row[2]\n",
        "\n",
        "              sent = row[3].strip()\n",
        "              target = row[4].strip()\n",
        "\n",
        "              sentences.append(sent)\n",
        "              target_sentences.append(target)\n",
        "              id.append(id_sample)\n",
        "\n",
        "              l=[0,0,0]\n",
        "              if label == 'supports' or label == 'support' or label == 'because':\n",
        "                l = [1,0,0]\n",
        "              elif label == 'attacks' or label == 'attack' or label == 'but':\n",
        "                l = [0,1,0]\n",
        "              elif label == 'no_relation':\n",
        "                l = [0,0,1]\n",
        "\n",
        "              label_distribution.append(l)\n",
        "\n",
        "      result = []\n",
        "      for i in range(len(label_distribution)):\n",
        "        result.append([id[i],sentences[i],target_sentences[i], [], [], [], label_distribution[i]])\n",
        "\n",
        "      examples = self._get_examples_concatenated(result, name)\n",
        "\n",
        "      return examples\n",
        "\n",
        "class StudentEssayWithDiscourseInjectionProcessor(DataProcessor):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(StudentEssayWithDiscourseInjectionProcessor, self).__init__()\n",
        "    self.pipe = pipeline(\"text-classification\", model=\"sileod/roberta-base-discourse-marker-prediction\")\n",
        "\n",
        "  def padding(self, input, maxlen):\n",
        "      \"\"\"\n",
        "      Padding the input sequence\n",
        "      \"\"\"\n",
        "\n",
        "      id, sentences, target, source_sentiment, target_sentiment, knowledge, label_distribution = zip(*input)\n",
        "\n",
        "      sentences = torch.nn.utils.rnn.pad_sequence([torch.tensor(s) for s in sentences], batch_first=True, padding_value=0)\n",
        "      knowledge = torch.nn.utils.rnn.pad_sequence([torch.tensor(k) for k in knowledge], batch_first=True, padding_value=0)\n",
        "      target = torch.nn.utils.rnn.pad_sequence([torch.tensor(t) for t in target], batch_first=True, padding_value=0)\n",
        "\n",
        "      return list(zip(sentences, knowledge, target, label_distribution))\n",
        "\n",
        "\n",
        "  def create_batches_of_sentence_ids(self, sentences, batch_equal_size, max_batch_size):\n",
        "      \"\"\"\n",
        "      Groups together sentences into batches\n",
        "      If max_batch_size is positive, this value determines the maximum number of sentences in each batch.\n",
        "      If max_batch_size has a negative value, the function dynamically creates the batches such that each batch contains abs(max_batch_size) words.\n",
        "      Returns a list of lists with sentences ids.\n",
        "      \"\"\"\n",
        "      batches_of_sentence_ids = []\n",
        "      if batch_equal_size == True:\n",
        "          sentence_ids_by_length = collections.OrderedDict()\n",
        "          sentence_length_sum = 0.0\n",
        "          for i in range(len(sentences)):\n",
        "              length = len(sentences[i])\n",
        "              if length not in sentence_ids_by_length:\n",
        "                  sentence_ids_by_length[length] = []\n",
        "              sentence_ids_by_length[length].append(i)\n",
        "\n",
        "          for sentence_length in sentence_ids_by_length:\n",
        "              if max_batch_size > 0:\n",
        "                  batch_size = max_batch_size\n",
        "              else:\n",
        "                  batch_size = int((-1 * max_batch_size) / sentence_length)\n",
        "\n",
        "              for i in range(0, len(sentence_ids_by_length[sentence_length]), batch_size):\n",
        "                  batches_of_sentence_ids.append(sentence_ids_by_length[sentence_length][i:i + batch_size])\n",
        "      else:\n",
        "          current_batch = []\n",
        "          max_sentence_length = 0\n",
        "          for i in range(len(sentences)):\n",
        "              current_batch.append(i)\n",
        "              if len(sentences[i]) > max_sentence_length:\n",
        "                  max_sentence_length = len(sentences[i])\n",
        "              if (max_batch_size > 0 and len(current_batch) >= max_batch_size) \\\n",
        "                or (max_batch_size <= 0 and len(current_batch)*max_sentence_length >= (-1 * max_batch_size)):\n",
        "                  batches_of_sentence_ids.append(current_batch)\n",
        "                  current_batch = []\n",
        "                  max_sentence_length = 0\n",
        "          if len(current_batch) > 0:\n",
        "              batches_of_sentence_ids.append(current_batch)\n",
        "      return batches_of_sentence_ids\n",
        "\n",
        "\n",
        "  def read_input_files(self, file_path, max_sentence_length=-1, name=\"train\"):\n",
        "      \"\"\"\n",
        "      Reads input files in tab-separated format.\n",
        "      Will split file_paths on comma, reading from multiple files.\n",
        "      \"\"\"\n",
        "\n",
        "      # Code copied from https://aclanthology.org/2023.eacl-main.182.pdf\n",
        "      # TODO: refactor, several objects are not needed\n",
        "\n",
        "      sentences = []\n",
        "      labels = []\n",
        "      label_distribution=[]\n",
        "      target = []\n",
        "      knowledge = []\n",
        "      story_id_know=[]\n",
        "      lst2=[]\n",
        "      target_sentences = []\n",
        "      source_senti = []\n",
        "      target_senti = []\n",
        "      id=[]\n",
        "      count = 0\n",
        "\n",
        "      with codecs.open(file_path, encoding=\"ISO-8859-1\", mode=\"r\") as f:\n",
        "        for line in f:\n",
        "              know =[]\n",
        "              #print(line)\n",
        "              count +=1\n",
        "              #print(count)\n",
        "              line = line.replace(\"\\n\",\"\")\n",
        "              line = line.split(\"\\t\")\n",
        "\n",
        "              if line == ['\\r']:\n",
        "                      continue\n",
        "              count +=1\n",
        "              story_id = line[0]\n",
        "              sent = line[1].strip()\n",
        "              target = line[3].strip()\n",
        "              ds_marker = self.pipe(f\"{sent}</s></s>{target}\")[0][\"label\"]\n",
        "              ds_marker = ds_marker.replace(\"_\", \" \")\n",
        "              ds_marker = ds_marker[0].upper() + ds_marker[1:]\n",
        "              target = target[0].lower() + target[1:]\n",
        "              target = ds_marker + \" \" + target\n",
        "              #print(target)\n",
        "              label = line[-1].strip()\n",
        "              facts = line[-2].strip()\n",
        "\n",
        "              facts = facts.replace(\"_\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"(\", \"\").replace(\"(\", \"\")\n",
        "\n",
        "              lst2.append(facts)\n",
        "\n",
        "              sentences.append(sent)\n",
        "              target_sentences.append(target)\n",
        "              id.append(story_id)\n",
        "\n",
        "              l=[0,0]\n",
        "              if label == 'supports' or label == 'support' or label == 'because':\n",
        "                    l=[1,0]\n",
        "              elif label == 'attacks' or label == 'attack' or label == 'but':\n",
        "                    l=[0,1]\n",
        "              label_distribution.append(l)\n",
        "\n",
        "      result = []\n",
        "      for i in range(len(label_distribution)):\n",
        "        result.append([id[i],sentences[i],target_sentences[i], [], [], lst2[i], label_distribution[i]])\n",
        "\n",
        "      examples = self._get_examples_concatenated(result, name)\n",
        "\n",
        "      return examples\n",
        "\n",
        "\n",
        "class DebateWithDiscourseInjectionProcessor(DataProcessor):\n",
        "\n",
        "  def __init__(self,):\n",
        "    super(DebateWithDiscourseInjectionProcessor,self).__init__()\n",
        "    self.pipe = pipeline(\"text-classification\", model=\"sileod/roberta-base-discourse-marker-prediction\")\n",
        "\n",
        "  def padding(self, input, maxlen):\n",
        "      \"\"\"\n",
        "      Padding the input sequence.....\n",
        "      \"\"\"\n",
        "\n",
        "      id, sentences, target, source_sentiment, target_sentiment, knowledge, label_distribution = zip(*input)\n",
        "\n",
        "      sentences = torch.nn.utils.rnn.pad_sequence([torch.tensor(s) for s in sentences], batch_first=True, padding_value=0)\n",
        "      knowledge = torch.nn.utils.rnn.pad_sequence([torch.tensor(k) for k in knowledge], batch_first=True, padding_value=0)\n",
        "      target = torch.nn.utils.rnn.pad_sequence([torch.tensor(t) for t in target], batch_first=True, padding_value=0)\n",
        "\n",
        "      return list(zip(sentences, knowledge, target, label_distribution))\n",
        "\n",
        "\n",
        "  def create_batches_of_sentence_ids(self, sentences, batch_equal_size, max_batch_size):\n",
        "      \"\"\"\n",
        "      Groups together sentences into batches\n",
        "      If max_batch_size is positive, this value determines the maximum number of sentences in each batch.\n",
        "      If max_batch_size has a negative value, the function dynamically creates the batches such that each batch contains abs(max_batch_size) words.\n",
        "      Returns a list of lists with sentences ids.\n",
        "      \"\"\"\n",
        "      batches_of_sentence_ids = []\n",
        "      if batch_equal_size == True:\n",
        "          sentence_ids_by_length = collections.OrderedDict()\n",
        "          sentence_length_sum = 0.0\n",
        "          for i in range(len(sentences)):\n",
        "              length = len(sentences[i])\n",
        "              if length not in sentence_ids_by_length:\n",
        "                  sentence_ids_by_length[length] = []\n",
        "              sentence_ids_by_length[length].append(i)\n",
        "\n",
        "          for sentence_length in sentence_ids_by_length:\n",
        "              if max_batch_size > 0:\n",
        "                  batch_size = max_batch_size\n",
        "              else:\n",
        "                  batch_size = int((-1 * max_batch_size) / sentence_length)\n",
        "\n",
        "              for i in range(0, len(sentence_ids_by_length[sentence_length]), batch_size):\n",
        "                  batches_of_sentence_ids.append(sentence_ids_by_length[sentence_length][i:i + batch_size])\n",
        "      else:\n",
        "          current_batch = []\n",
        "          max_sentence_length = 0\n",
        "          for i in range(len(sentences)):\n",
        "              current_batch.append(i)\n",
        "              if len(sentences[i]) > max_sentence_length:\n",
        "                  max_sentence_length = len(sentences[i])\n",
        "              if (max_batch_size > 0 and len(current_batch) >= max_batch_size) \\\n",
        "                or (max_batch_size <= 0 and len(current_batch)*max_sentence_length >= (-1 * max_batch_size)):\n",
        "                  batches_of_sentence_ids.append(current_batch)\n",
        "                  current_batch = []\n",
        "                  max_sentence_length = 0\n",
        "          if len(current_batch) > 0:\n",
        "              batches_of_sentence_ids.append(current_batch)\n",
        "      return batches_of_sentence_ids\n",
        "\n",
        "\n",
        "  def read_input_files(self, file_path, max_sentence_length=-1, name=\"train\"):\n",
        "      \"\"\"\n",
        "      Reads input files in tab-separated format.\n",
        "      Will split file_paths on comma, reading from multiple files.\n",
        "      \"\"\"\n",
        "      sentences = []\n",
        "      labels = []\n",
        "      label_distribution=[]\n",
        "      target = []\n",
        "      knowledge = []\n",
        "      story_id_know=[]\n",
        "      lst2=[]\n",
        "      target_sentences = []\n",
        "      source_senti = []\n",
        "      target_senti = []\n",
        "      id=[]\n",
        "      count = 0\n",
        "\n",
        "      with codecs.open(file_path, encoding=\"ISO-8859-1\", mode=\"r\") as f:\n",
        "        for line in f:\n",
        "              know =[]\n",
        "              #print(line)\n",
        "              count +=1\n",
        "              #print(count)\n",
        "              line = line.replace(\"\\n\",\"\")\n",
        "              line = line.split(\"\\t\")\n",
        "\n",
        "              if line == ['\\r']:\n",
        "                      continue\n",
        "              count +=1\n",
        "              story_id = line[0]\n",
        "              sent = line[1].strip()\n",
        "              target = line[3].strip()\n",
        "              ds_marker = self.pipe(f\"{sent}</s></s>{target}\")[0][\"label\"]\n",
        "              ds_marker = ds_marker.replace(\"_\", \" \")\n",
        "              ds_marker = ds_marker[0].upper() + ds_marker[1:]\n",
        "              target = target[0].lower() + target[1:]\n",
        "              target = ds_marker + \" \" + target\n",
        "              #print(target)\n",
        "              label = line[-1].strip()\n",
        "              facts = line[-2].strip()\n",
        "\n",
        "              facts = facts.replace(\"_\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"(\", \"\").replace(\"(\", \"\")\n",
        "\n",
        "              lst2.append(facts)\n",
        "\n",
        "              sentences.append(sent)\n",
        "              target_sentences.append(target)\n",
        "              id.append(story_id)\n",
        "\n",
        "              l=[0,0]\n",
        "              if label == 'supports' or label == 'support' or label == 'because':\n",
        "                    l=[1,0]\n",
        "              elif label == 'attacks' or label == 'attack' or label == 'but':\n",
        "                    l=[0,1]\n",
        "              label_distribution.append(l)\n",
        "              #print(label_distribution)\n",
        "\n",
        "      result = []\n",
        "      for i in range(len(label_distribution)):\n",
        "        result.append([id[i],sentences[i],target_sentences[i], [], [], lst2[i], label_distribution[i]])\n",
        "\n",
        "      examples = self._get_examples_concatenated(result, name)\n",
        "\n",
        "      return examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArK77n3-_k82"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "from torch import nn\n",
        "\n",
        "class GRLayer(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, lmbd=0.01):\n",
        "        ctx.lmbd = torch.tensor(lmbd)\n",
        "        return x.reshape_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        grad_input = grad_output.clone()\n",
        "        return ctx.lmbd * grad_input.neg(), None\n",
        "\n",
        "class DoubleAdversarialNet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DoubleAdversarialNet, self).__init__()\n",
        "\n",
        "    self.plm = AutoModel.from_pretrained(args[\"model_name\"])\n",
        "    config = self.plm.config\n",
        "    config.type_vocab_size = 4\n",
        "    self.plm.embeddings.token_type_embeddings = nn.Embedding(\n",
        "      config.type_vocab_size, config.hidden_size\n",
        "    )\n",
        "    self.plm._init_weights(self.plm.embeddings.token_type_embeddings)\n",
        "\n",
        "    self.num_classes = args[\"num_classes\"]\n",
        "    self.num_classes_adv = args[\"num_classes_adv\"]\n",
        "    self.embed_size = args[\"embed_size\"]\n",
        "\n",
        "    self.first_last_avg = args[\"first_last_avg\"]\n",
        "\n",
        "    for param in self.plm.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    self.linear_layer = torch.nn.Linear(in_features=self.embed_size, out_features=self.num_classes)\n",
        "    self.linear_layer_adv = torch.nn.Linear(in_features=self.embed_size, out_features=self.num_classes_adv)\n",
        "    self.task_linear = torch.nn.Linear(in_features=self.embed_size, out_features=self.num_classes)\n",
        "    self.attack_linear = torch.nn.Linear(in_features=self.embed_size, out_features=self.num_classes)\n",
        "    self.support_linear = torch.nn.Linear(in_features=self.embed_size, out_features=self.num_classes)\n",
        "\n",
        "    self.multi_head_att = torch.nn.MultiheadAttention(self.embed_size, 8, batch_first=True)\n",
        "    self.Q = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.K = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.V = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "\n",
        "    self._init_weights(self.linear_layer)\n",
        "    self._init_weights(self.linear_layer_adv)\n",
        "    self._init_weights(self.Q)\n",
        "    self._init_weights(self.K)\n",
        "    self._init_weights(self.V)\n",
        "    self._init_weights(self.multi_head_att)\n",
        "    self._init_weights(self.task_linear)\n",
        "    self._init_weights(self.attack_linear)\n",
        "    self._init_weights(self.support_linear)\n",
        "\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "    \"\"\"Initialize the weights\"\"\"\n",
        "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "      module.weight.data.normal_(mean=0.0, std=self.plm.config.initializer_range)\n",
        "    elif isinstance(module, nn.LayerNorm):\n",
        "      module.bias.data.zero_()\n",
        "      module.weight.data.fill_(1.0)\n",
        "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "      module.bias.data.zero_()\n",
        "\n",
        "  @torch.autocast(device_type=\"cuda\")\n",
        "  def forward(self, ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels):\n",
        "    out_sent1 = self.plm(ids_sent1, token_type_ids=segs_sent1, attention_mask=att_mask_sent1, output_hidden_states=True)\n",
        "\n",
        "    last_sent1, first_sent1 = out_sent1.hidden_states[-1], out_sent1.hidden_states[1]\n",
        "\n",
        "    if self.first_last_avg:\n",
        "      embed_sent1 = torch.div((last_sent1 + first_sent1), 2)\n",
        "    else:\n",
        "      embed_sent1 = last_sent1\n",
        "\n",
        "    tar_mask_sent1 = (segs_sent1 == 0).long()\n",
        "    tar_mask_sent2 = (segs_sent1 == 1).long()\n",
        "\n",
        "    H_sent1 = torch.mul(tar_mask_sent1.unsqueeze(2), embed_sent1)\n",
        "    H_sent2 = torch.mul(tar_mask_sent2.unsqueeze(2), embed_sent1)\n",
        "\n",
        "    K_sent1 = self.K(H_sent1)\n",
        "    V_sent1 = self.V(H_sent1)\n",
        "    Q_sent2 = self.Q(H_sent2)\n",
        "\n",
        "    att_output = self.multi_head_att(Q_sent2, K_sent1, V_sent1)\n",
        "\n",
        "    H_sent = torch.mean(att_output[0], dim=1)\n",
        "\n",
        "    if self.training:\n",
        "      batch_size = H_sent.shape[0]\n",
        "      samples = H_sent[:batch_size // 2, :]\n",
        "      embed_sent1_std = embed_sent1[:batch_size // 2, :, :]\n",
        "      labels_std = torch.tensor(labels[:batch_size // 2]).to(device)\n",
        "\n",
        "      emb_attack = embed_sent1_std[(labels_std == torch.tensor([0,1]).to(device)).all(dim=1)]\n",
        "      emb_support = embed_sent1_std[(labels_std == torch.tensor([1,0]).to(device)).all(dim=1)]\n",
        "\n",
        "      samples_adv = H_sent[batch_size // 2:, :]\n",
        "      embed_sent1_adv = embed_sent1[batch_size // 2:, :, :]\n",
        "      labels_adv = torch.tensor(labels[batch_size // 2:]).to(device)\n",
        "\n",
        "      emb_contr = embed_sent1_adv[(labels_adv == torch.tensor([1,0,0]).to(device)).all(dim=1)]\n",
        "      emb_other = embed_sent1_adv[(labels_adv == torch.tensor([0,1,0]).to(device)).all(dim=1) | (labels_adv == torch.tensor([0,0,1]).to(device)).all(dim=1)]\n",
        "\n",
        "      predictions = self.linear_layer(samples)\n",
        "      predictions_adv = self.linear_layer_adv(samples_adv)\n",
        "\n",
        "      mean_grl = GRLayer.apply(torch.mean(embed_sent1, dim=1), .01)\n",
        "      mean_grl_attack = GRLayer.apply(torch.mean(torch.cat([emb_attack, emb_contr], dim=0), dim=1), .01)\n",
        "      mean_grl_support = GRLayer.apply(torch.mean(torch.cat([emb_support, emb_other], dim=0), dim=1), .01)\n",
        "\n",
        "      task_prediction = self.task_linear(mean_grl)\n",
        "      attack_prediction = self.attack_linear(mean_grl_attack)\n",
        "      support_prediction = self.support_linear(mean_grl_support)\n",
        "\n",
        "      return predictions, predictions_adv, task_prediction, attack_prediction, support_prediction\n",
        "    else:\n",
        "      predictions = self.linear_layer(H_sent)\n",
        "\n",
        "      return predictions\n",
        "\n",
        "class AdversarialNet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(AdversarialNet, self).__init__()\n",
        "\n",
        "    self.plm = AutoModel.from_pretrained(args[\"model_name\"])\n",
        "    config = self.plm.config\n",
        "    config.type_vocab_size = 4\n",
        "    self.plm.embeddings.token_type_embeddings = nn.Embedding(\n",
        "      config.type_vocab_size, config.hidden_size\n",
        "    )\n",
        "    self.plm._init_weights(self.plm.embeddings.token_type_embeddings)\n",
        "\n",
        "    self.num_classes = args[\"num_classes\"]\n",
        "    self.num_classes_adv = args[\"num_classes_adv\"]\n",
        "    self.embed_size = args[\"embed_size\"]\n",
        "\n",
        "    self.first_last_avg = args[\"first_last_avg\"]\n",
        "\n",
        "    for param in self.plm.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    self.linear_layer = torch.nn.Linear(in_features=self.embed_size, out_features=self.num_classes)\n",
        "    self.linear_layer_adv = torch.nn.Linear(in_features=self.embed_size, out_features=self.num_classes_adv)\n",
        "    self.task_linear = torch.nn.Linear(in_features=self.embed_size, out_features=2)\n",
        "\n",
        "    self.multi_head_att = torch.nn.MultiheadAttention(self.embed_size, 8, batch_first=True)\n",
        "    self.Q = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.K = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.V = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "\n",
        "    self._init_weights(self.linear_layer)\n",
        "    self._init_weights(self.linear_layer_adv)\n",
        "    self._init_weights(self.Q)\n",
        "    self._init_weights(self.K)\n",
        "    self._init_weights(self.V)\n",
        "    self._init_weights(self.multi_head_att)\n",
        "    self._init_weights(self.task_linear)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "    \"\"\"Initialize the weights\"\"\"\n",
        "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "      module.weight.data.normal_(mean=0.0, std=self.plm.config.initializer_range)\n",
        "    elif isinstance(module, nn.LayerNorm):\n",
        "      module.bias.data.zero_()\n",
        "      module.weight.data.fill_(1.0)\n",
        "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "      module.bias.data.zero_()\n",
        "\n",
        "  @torch.autocast(device_type=\"cuda\")\n",
        "  def forward(self, ids_sent1, segs_sent1, att_mask_sent1, position_sep, visualize=False):\n",
        "    out_sent1 = self.plm(ids_sent1, token_type_ids=segs_sent1, attention_mask=att_mask_sent1, output_hidden_states=True)\n",
        "\n",
        "    last_sent1, first_sent1 = out_sent1.hidden_states[-1], out_sent1.hidden_states[1]\n",
        "\n",
        "    if self.first_last_avg:\n",
        "      embed_sent1 = torch.div((last_sent1 + first_sent1), 2)\n",
        "    else:\n",
        "      embed_sent1 = last_sent1\n",
        "\n",
        "    tar_mask_sent1 = (segs_sent1 == 0).long()\n",
        "    tar_mask_sent2 = (segs_sent1 == 1).long()\n",
        "\n",
        "    H_sent1 = torch.mul(tar_mask_sent1.unsqueeze(2), embed_sent1)\n",
        "    H_sent2 = torch.mul(tar_mask_sent2.unsqueeze(2), embed_sent1)\n",
        "\n",
        "    K_sent1 = self.K(H_sent1)\n",
        "    V_sent1 = self.V(H_sent1)\n",
        "    Q_sent2 = self.Q(H_sent2)\n",
        "\n",
        "    att_output = self.multi_head_att(Q_sent2, K_sent1, V_sent1)\n",
        "\n",
        "    H_sent = torch.mean(att_output[0], dim=1)\n",
        "\n",
        "    if visualize:\n",
        "      return H_sent\n",
        "    if self.training:\n",
        "      batch_size = H_sent.shape[0]\n",
        "      samples = H_sent[:batch_size // 2, :]\n",
        "      samples_adv = H_sent[batch_size // 2:, ]\n",
        "\n",
        "      predictions = self.linear_layer(samples)\n",
        "      predictions_adv = self.linear_layer_adv(samples_adv)\n",
        "\n",
        "      mean_grl = GRLayer.apply(torch.mean(embed_sent1, dim=1), .01)\n",
        "      task_prediction = self.task_linear(mean_grl)\n",
        "\n",
        "      return predictions, predictions_adv, task_prediction\n",
        "    else:\n",
        "      predictions = self.linear_layer(H_sent)\n",
        "\n",
        "      return predictions\n",
        "\n",
        "class BaselineModelWithSentenceComparisonAndCue(torch.nn.Module):\n",
        "  def __init__(self, attention):\n",
        "    super(BaselineModelWithSentenceComparisonAndCue, self).__init__()\n",
        "\n",
        "    self.plm = AutoModel.from_pretrained(args[\"model_name\"])\n",
        "    config = self.plm.config\n",
        "    config.type_vocab_size = 4\n",
        "    self.attention = attention\n",
        "    self.plm.embeddings.token_type_embeddings = nn.Embedding(\n",
        "      config.type_vocab_size, config.hidden_size\n",
        "    )\n",
        "    self.plm._init_weights(self.plm.embeddings.token_type_embeddings)\n",
        "\n",
        "    self.num_classes = args[\"num_classes\"]\n",
        "    self.embed_size = args[\"embed_size\"]\n",
        "\n",
        "    self.first_last_avg = args[\"first_last_avg\"]\n",
        "\n",
        "    for param in self.plm.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    self.linear_layer = torch.nn.Linear(in_features=self.embed_size*3, out_features=args[\"num_classes\"])\n",
        "    self.multi_head_att = torch.nn.MultiheadAttention(self.embed_size, 8, batch_first=True)\n",
        "    self.Q = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.K = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.V = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    \"\"\"self.linear_initial_sent = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.linear_end_sent = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\"\"\"\n",
        "    self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    self._init_weights(self.linear_layer)\n",
        "    self._init_weights(self.Q)\n",
        "    self._init_weights(self.K)\n",
        "    self._init_weights(self.V)\n",
        "    self._init_weights(self.multi_head_att)\n",
        "    \"\"\"self._init_weights(self.linear_initial_sent)\n",
        "    self._init_weights(self.linear_end_sent)\"\"\"\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "    \"\"\"Initialize the weights\"\"\"\n",
        "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "      module.weight.data.normal_(mean=0.0, std=self.plm.config.initializer_range)\n",
        "    elif isinstance(module, nn.LayerNorm):\n",
        "      module.bias.data.zero_()\n",
        "      module.weight.data.fill_(1.0)\n",
        "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "      module.bias.data.zero_()\n",
        "\n",
        "  @torch.autocast(device_type=\"cuda\")\n",
        "  def forward(self, ids_sent1, segs_sent1, att_mask_sent1, position_sep):\n",
        "    out_sent1 = self.plm(ids_sent1, token_type_ids=segs_sent1, attention_mask=att_mask_sent1, output_hidden_states=True)\n",
        "\n",
        "    last_sent1, first_sent1 = out_sent1.hidden_states[-1], out_sent1.hidden_states[1]\n",
        "\n",
        "    if self.first_last_avg:\n",
        "      embed_sent1 = torch.div((last_sent1 + first_sent1), 2)\n",
        "    else:\n",
        "      embed_sent1 = last_sent1\n",
        "\n",
        "    if self.attention:\n",
        "      tar_mask_sent1 = (segs_sent1 == 0).long()\n",
        "      tar_mask_sent2 = (segs_sent1 == 1).long()\n",
        "\n",
        "      H_sent1 = torch.mul(tar_mask_sent1.unsqueeze(2), embed_sent1)\n",
        "      H_sent2 = torch.mul(tar_mask_sent2.unsqueeze(2), embed_sent1)\n",
        "\n",
        "      K_sent1 = self.K(H_sent1)\n",
        "      V_sent1 = self.V(H_sent1)\n",
        "      Q_sent2 = self.Q(H_sent2)\n",
        "\n",
        "      att_output = self.multi_head_att(Q_sent2, K_sent1, V_sent1)[0]\n",
        "    else:\n",
        "      att_output = embed_sent1\n",
        "\n",
        "    initial_sent1 = att_output[:,0,:]\n",
        "    initial_sent2 = att_output[torch.arange(att_output.shape[0]), torch.argmax(segs_sent1 * torch.arange(att_output.shape[1], 0, -1).to(device), dim=-1)]\n",
        "    end_sent2 = att_output[torch.arange(att_output.shape[0]), torch.sum(att_mask_sent1, dim=-1)-1]\n",
        "\n",
        "    initial_sent1 = self.linear_initial_sent(initial_sent1)\n",
        "    end_sent2 = self.linear_end_sent(end_sent2)\n",
        "    gate = self.sigmoid(initial_sent1 + end_sent2)\n",
        "\n",
        "    final_emb = initial_sent2 * gate\n",
        "\n",
        "    predictions = self.linear_layer(final_emb)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "class BaselineModelWithSentenceComparison(torch.nn.Module):\n",
        "  def __init__(self, attention):\n",
        "    super(BaselineModelWithSentenceComparison, self).__init__()\n",
        "\n",
        "    self.plm = AutoModel.from_pretrained(args[\"model_name\"])\n",
        "    config = self.plm.config\n",
        "    config.type_vocab_size = 4\n",
        "    self.plm.embeddings.token_type_embeddings = nn.Embedding(\n",
        "      config.type_vocab_size, config.hidden_size\n",
        "    )\n",
        "    self.plm._init_weights(self.plm.embeddings.token_type_embeddings)\n",
        "\n",
        "    self.num_classes = args[\"num_classes\"]\n",
        "    self.embed_size = args[\"embed_size\"]\n",
        "    self.attention = attention\n",
        "\n",
        "    self.first_last_avg = args[\"first_last_avg\"]\n",
        "\n",
        "    for param in self.plm.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    self.linear_layer = torch.nn.Linear(in_features=self.embed_size, out_features=args[\"num_classes\"])\n",
        "    self.multi_head_att = torch.nn.MultiheadAttention(self.embed_size, 8, batch_first=True)\n",
        "    self.Q = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.K = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.V = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "\n",
        "    self._init_weights(self.linear_layer)\n",
        "    self._init_weights(self.Q)\n",
        "    self._init_weights(self.K)\n",
        "    self._init_weights(self.V)\n",
        "    self._init_weights(self.multi_head_att)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "    \"\"\"Initialize the weights\"\"\"\n",
        "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "      module.weight.data.normal_(mean=0.0, std=self.plm.config.initializer_range)\n",
        "    elif isinstance(module, nn.LayerNorm):\n",
        "      module.bias.data.zero_()\n",
        "      module.weight.data.fill_(1.0)\n",
        "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "      module.bias.data.zero_()\n",
        "\n",
        "  @torch.autocast(device_type=\"cuda\")\n",
        "  def forward(self, ids_sent1, segs_sent1, att_mask_sent1, position_sep):\n",
        "    out_sent1 = self.plm(ids_sent1, token_type_ids=segs_sent1, attention_mask=att_mask_sent1, output_hidden_states=True)\n",
        "\n",
        "    last_sent1, first_sent1 = out_sent1.hidden_states[-1], out_sent1.hidden_states[1]\n",
        "\n",
        "    if self.first_last_avg:\n",
        "      embed_sent1 = torch.div((last_sent1 + first_sent1), 2)\n",
        "    else:\n",
        "      embed_sent1 = last_sent1\n",
        "\n",
        "    if self.attention:\n",
        "      tar_mask_sent1 = (segs_sent1 == 0).long()\n",
        "      tar_mask_sent2 = (segs_sent1 == 1).long()\n",
        "\n",
        "      H_sent1 = torch.mul(tar_mask_sent1.unsqueeze(2), embed_sent1)\n",
        "      H_sent2 = torch.mul(tar_mask_sent2.unsqueeze(2), embed_sent1)\n",
        "\n",
        "      K_sent1 = self.K(H_sent1)\n",
        "      V_sent1 = self.V(H_sent1)\n",
        "      Q_sent2 = self.Q(H_sent2)\n",
        "\n",
        "      att_output = self.multi_head_att(Q_sent2, K_sent1, V_sent1)\n",
        "\n",
        "      H_sent = torch.mean(att_output[0], dim=1)\n",
        "    else:\n",
        "      H_sent = torch.mean(embed_sent1, dim=1)\n",
        "\n",
        "    predictions = self.linear_layer(H_sent)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "class BaselineModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BaselineModel, self).__init__()\n",
        "\n",
        "    self.plm = AutoModel.from_pretrained(args[\"model_name\"])\n",
        "    config = self.plm.config\n",
        "    config.type_vocab_size = 4\n",
        "    self.plm.embeddings.token_type_embeddings = nn.Embedding(\n",
        "      config.type_vocab_size, config.hidden_size\n",
        "    )\n",
        "    self.plm._init_weights(self.plm.embeddings.token_type_embeddings)\n",
        "\n",
        "    self.num_classes = args[\"num_classes\"]\n",
        "    self.embed_size = args[\"embed_size\"]\n",
        "\n",
        "    self.first_last_avg = args[\"first_last_avg\"]\n",
        "\n",
        "    for param in self.plm.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    self.linear_layer = torch.nn.Linear(in_features=self.embed_size, out_features=args[\"num_classes\"])\n",
        "\n",
        "    self._init_weights(self.linear_layer)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "    \"\"\"Initialize the weights\"\"\"\n",
        "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "      module.weight.data.normal_(mean=0.0, std=self.plm.config.initializer_range)\n",
        "    elif isinstance(module, nn.LayerNorm):\n",
        "      module.bias.data.zero_()\n",
        "      module.weight.data.fill_(1.0)\n",
        "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "      module.bias.data.zero_()\n",
        "\n",
        "  @torch.autocast(device_type=\"cuda\")\n",
        "  def forward(self, ids_sent1, segs_sent1, att_mask_sent1, position_sep):\n",
        "    out_sent1 = self.plm(ids_sent1, token_type_ids=segs_sent1, attention_mask=att_mask_sent1, output_hidden_states=True)\n",
        "\n",
        "    last_sent1, first_sent1 = out_sent1.hidden_states[-1], out_sent1.hidden_states[1]\n",
        "\n",
        "    if self.first_last_avg:\n",
        "      embed_sent1 = torch.div((last_sent1 + first_sent1), 2)\n",
        "    else:\n",
        "      embed_sent1 = last_sent1\n",
        "\n",
        "    tar_mask_sent1 = (position_sep == 1).long()\n",
        "\n",
        "    H_sent1 = torch.mul(tar_mask_sent1.unsqueeze(2), embed_sent1)\n",
        "\n",
        "    H_mean1 = torch.mean(embed_sent1, dim=1)\n",
        "\n",
        "    predictions = self.linear_layer(H_mean1)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "class SiameseBaselineModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SiameseBaselineModel, self).__init__()\n",
        "\n",
        "    self.plm = AutoModel.from_pretrained(args[\"model_name\"])\n",
        "    config = self.plm.config\n",
        "    config.type_vocab_size = 4\n",
        "    self.plm.embeddings.token_type_embeddings = nn.Embedding(\n",
        "      config.type_vocab_size, config.hidden_size\n",
        "    )\n",
        "    self.plm._init_weights(self.plm.embeddings.token_type_embeddings)\n",
        "\n",
        "    self.num_classes = args[\"num_classes\"]\n",
        "    self.embed_size = args[\"embed_size\"]\n",
        "\n",
        "    self.first_last_avg = args[\"first_last_avg\"]\n",
        "\n",
        "    for param in self.plm.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    self.linear_layer = torch.nn.Linear(in_features=self.embed_size*2, out_features=args[\"num_classes\"])\n",
        "\n",
        "    self._init_weights(self.linear_layer)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "    \"\"\"Initialize the weights\"\"\"\n",
        "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "      module.weight.data.normal_(mean=0.0, std=self.plm.config.initializer_range)\n",
        "    elif isinstance(module, nn.LayerNorm):\n",
        "      module.bias.data.zero_()\n",
        "      module.weight.data.fill_(1.0)\n",
        "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "      module.bias.data.zero_()\n",
        "\n",
        "  @torch.autocast(device_type=\"cuda\")\n",
        "  def forward(self, ids_sent1, segs_sent1, att_mask_sent1, ids_sent2, segs_sent2, att_mask_sent2):\n",
        "    out_sent1 = self.plm(ids_sent1, token_type_ids=segs_sent1, attention_mask=att_mask_sent1, output_hidden_states=True)\n",
        "    out_sent2 = self.plm(ids_sent2, token_type_ids=segs_sent2, attention_mask=att_mask_sent2, output_hidden_states=True)\n",
        "\n",
        "    last_sent1, first_sent1 = out_sent1.hidden_states[-1], out_sent1.hidden_states[1]\n",
        "    last_sent2, first_sent2 = out_sent2.hidden_states[-1], out_sent2.hidden_states[1]\n",
        "\n",
        "    if self.first_last_avg:\n",
        "      embed_sent1 = torch.div((last_sent1 + first_sent1), 2)\n",
        "      embed_sent2 = torch.div((last_sent2 + first_sent2), 2)\n",
        "    else:\n",
        "      embed_sent1 = last_sent1\n",
        "      embed_sent2 = last_sent2\n",
        "\n",
        "    tar_mask_sent1 = (segs_sent1 == 1).long()\n",
        "    tar_mask_sent2 = (segs_sent2 == 1).long()\n",
        "\n",
        "    H_sent1 = torch.mul(tar_mask_sent1.unsqueeze(2), embed_sent1)\n",
        "    H_sent2 = torch.mul(tar_mask_sent2.unsqueeze(2), embed_sent2)\n",
        "\n",
        "    H_mean1 = torch.mean(embed_sent1, dim=1)\n",
        "    H_mean2 = torch.mean(embed_sent2, dim=1)\n",
        "\n",
        "    H_cat = torch.cat((H_mean1, H_mean2), dim=-1)\n",
        "\n",
        "    predictions = self.linear_layer(H_cat)\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtBDFwz4Ban5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "def set_random_seeds(seed):\n",
        "    \"\"\"\n",
        "    set random seed\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "\n",
        "def output_metrics(labels, preds):\n",
        "    \"\"\"\n",
        "\n",
        "    :param labels: ground truth labels\n",
        "    :param preds: prediction labels\n",
        "    :return: accuracy, precision, recall, f1\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    precision = precision_score(labels, preds, average=\"macro\")\n",
        "    recall = recall_score(labels, preds, average=\"macro\")\n",
        "    f1 = f1_score(labels, preds, average=\"macro\")\n",
        "\n",
        "    print(\"{:15}{:<.3f}\".format('accuracy:', accuracy))\n",
        "    print(\"{:15}{:<.3f}\".format('precision:', precision))\n",
        "    print(\"{:15}{:<.3f}\".format('recall:', recall))\n",
        "    print(\"{:15}{:<.3f}\".format('f1:', f1))\n",
        "\n",
        "    return accuracy, precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOgUyIFcKg4W"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Sampler\n",
        "\n",
        "class BalancedSampler(Sampler):\n",
        "    def __init__(self, dataset1, dataset2, batch_size):\n",
        "        self.dataset1 = dataset1\n",
        "        self.dataset2 = dataset2\n",
        "        self.batch_size = batch_size\n",
        "        self.total_size = len(dataset1) + len(dataset2)\n",
        "        self.indices1 = list(range(len(dataset1)))\n",
        "        self.indices2 = list(range(len(dataset2)))\n",
        "        self.epoch = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.epoch += 1\n",
        "        batch = []\n",
        "        indices1 = self.indices1.copy()\n",
        "        indices2 = self.indices2.copy()\n",
        "\n",
        "        indices1 = torch.randperm(len(self.dataset1)).cpu().tolist()\n",
        "        indices2 = torch.randperm(len(self.dataset2)) +len(indices1)\n",
        "        indices2 = indices2.cpu().tolist()\n",
        "\n",
        "        for i in range(self.total_size // self.batch_size):\n",
        "            batch_size1 = min(self.batch_size // 2, len(indices1))\n",
        "            if batch_size1 < (self.batch_size // 2):\n",
        "              break\n",
        "            batch_size2 = self.batch_size - batch_size1\n",
        "            batch.extend([indices1.pop() for _ in range(batch_size1)])\n",
        "            batch.extend([indices2.pop() for _ in range(batch_size2)])\n",
        "\n",
        "            yield batch\n",
        "            batch = []\n",
        "            if len(indices1) == 0:\n",
        "              break\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.total_size + self.batch_size - 1) // self.batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XNhht6HtmJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "772bfc23-1656-4093-9c32-00d23e6fadba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**** trying with seed 1 ****\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "tokenizing...: 100%|| 6486/6486 [00:02<00:00, 2904.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished preprocessing examples in train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing...: 100%|| 2164/2164 [00:00<00:00, 2676.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished preprocessing examples in dev\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing...: 100%|| 2162/2162 [00:00<00:00, 2839.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished preprocessing examples in test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1491: FutureWarning: The repository for discovery contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/discovery\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Start training: epoch 1 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rIteration:   0%|          | 0/5443 [00:00<?, ?it/s]<ipython-input-7-55bc33ab5f24>:104: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  labels_adv = torch.tensor(labels[batch_size // 2:]).to(device)\n",
            "Iteration:   4%|         | 202/5443 [00:35<15:19,  5.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 35.4311318397522, Epoch: 1, training loss: 672.6889321804047, current learning rate 1e-05\n",
            "val loss: 23.51508218050003\n",
            "accuracy:      0.544\n",
            "precision:     0.558\n",
            "recall:        0.543\n",
            "f1:            0.511\n",
            "val loss: 23.55283659696579\n",
            "accuracy:      0.532\n",
            "precision:     0.568\n",
            "recall:        0.545\n",
            "f1:            0.496\n",
            "===== Start training: epoch 2 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.57761740684509, Epoch: 2, training loss: 982.3146138191223, current learning rate 1e-05\n",
            "val loss: 20.68849152326584\n",
            "accuracy:      0.678\n",
            "precision:     0.704\n",
            "recall:        0.677\n",
            "f1:            0.666\n",
            "val loss: 20.99238896369934\n",
            "accuracy:      0.670\n",
            "precision:     0.703\n",
            "recall:        0.678\n",
            "f1:            0.661\n",
            "===== Start training: epoch 3 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.59173560142517, Epoch: 3, training loss: 1100.918616771698, current learning rate 1e-05\n",
            "val loss: 18.50782334804535\n",
            "accuracy:      0.743\n",
            "precision:     0.752\n",
            "recall:        0.743\n",
            "f1:            0.741\n",
            "val loss: 18.974529027938843\n",
            "accuracy:      0.718\n",
            "precision:     0.732\n",
            "recall:        0.723\n",
            "f1:            0.716\n",
            "===== Start training: epoch 4 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.64956521987915, Epoch: 4, training loss: 1121.9929451942444, current learning rate 1e-05\n",
            "val loss: 18.352797627449036\n",
            "accuracy:      0.754\n",
            "precision:     0.755\n",
            "recall:        0.754\n",
            "f1:            0.754\n",
            "val loss: 18.061638951301575\n",
            "accuracy:      0.751\n",
            "precision:     0.751\n",
            "recall:        0.749\n",
            "f1:            0.749\n",
            "===== Start training: epoch 5 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.61758542060852, Epoch: 5, training loss: 1095.024887561798, current learning rate 1e-05\n",
            "val loss: 20.466246634721756\n",
            "accuracy:      0.745\n",
            "precision:     0.746\n",
            "recall:        0.745\n",
            "f1:            0.745\n",
            "val loss: 19.703871190547943\n",
            "accuracy:      0.747\n",
            "precision:     0.748\n",
            "recall:        0.746\n",
            "f1:            0.746\n",
            "===== Start training: epoch 6 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<15:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.72006678581238, Epoch: 6, training loss: 1011.033688545227, current learning rate 1e-05\n",
            "val loss: 21.96000063419342\n",
            "accuracy:      0.751\n",
            "precision:     0.752\n",
            "recall:        0.752\n",
            "f1:            0.752\n",
            "val loss: 22.160606563091278\n",
            "accuracy:      0.747\n",
            "precision:     0.747\n",
            "recall:        0.746\n",
            "f1:            0.746\n",
            "===== Start training: epoch 7 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<15:01,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.739649295806885, Epoch: 7, training loss: 877.6682722568512, current learning rate 1e-05\n",
            "val loss: 23.866338044404984\n",
            "accuracy:      0.754\n",
            "precision:     0.756\n",
            "recall:        0.754\n",
            "f1:            0.754\n",
            "val loss: 23.922076731920242\n",
            "accuracy:      0.752\n",
            "precision:     0.755\n",
            "recall:        0.754\n",
            "f1:            0.752\n",
            "===== Start training: epoch 8 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.61404895782471, Epoch: 8, training loss: 766.6637165546417, current learning rate 1e-05\n",
            "val loss: 22.264346450567245\n",
            "accuracy:      0.759\n",
            "precision:     0.761\n",
            "recall:        0.759\n",
            "f1:            0.759\n",
            "val loss: 22.349476873874664\n",
            "accuracy:      0.766\n",
            "precision:     0.768\n",
            "recall:        0.768\n",
            "f1:            0.766\n",
            "===== Start training: epoch 9 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.569072008132935, Epoch: 9, training loss: 654.9602193832397, current learning rate 1e-05\n",
            "val loss: 26.423242688179016\n",
            "accuracy:      0.744\n",
            "precision:     0.745\n",
            "recall:        0.745\n",
            "f1:            0.744\n",
            "val loss: 26.577793806791306\n",
            "accuracy:      0.744\n",
            "precision:     0.745\n",
            "recall:        0.742\n",
            "f1:            0.743\n",
            "===== Start training: epoch 10 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.54888319969177, Epoch: 10, training loss: 564.7366554737091, current learning rate 1e-05\n",
            "val loss: 31.007622331380844\n",
            "accuracy:      0.755\n",
            "precision:     0.759\n",
            "recall:        0.755\n",
            "f1:            0.754\n",
            "val loss: 31.121280014514923\n",
            "accuracy:      0.751\n",
            "precision:     0.757\n",
            "recall:        0.754\n",
            "f1:            0.751\n",
            "===== Start training: epoch 11 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.59877300262451, Epoch: 11, training loss: 495.88457584381104, current learning rate 1e-05\n",
            "val loss: 36.70407724380493\n",
            "accuracy:      0.748\n",
            "precision:     0.750\n",
            "recall:        0.748\n",
            "f1:            0.747\n",
            "val loss: 36.75815498828888\n",
            "accuracy:      0.743\n",
            "precision:     0.744\n",
            "recall:        0.741\n",
            "f1:            0.741\n",
            "===== Start training: epoch 12 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.56117630004883, Epoch: 12, training loss: 428.68018186092377, current learning rate 1e-05\n",
            "val loss: 36.872279822826385\n",
            "accuracy:      0.750\n",
            "precision:     0.751\n",
            "recall:        0.751\n",
            "f1:            0.751\n",
            "val loss: 36.41526639461517\n",
            "accuracy:      0.759\n",
            "precision:     0.760\n",
            "recall:        0.760\n",
            "f1:            0.759\n",
            "===== Start training: epoch 13 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.583630084991455, Epoch: 13, training loss: 385.3619467020035, current learning rate 1e-05\n",
            "val loss: 34.48030507564545\n",
            "accuracy:      0.752\n",
            "precision:     0.754\n",
            "recall:        0.752\n",
            "f1:            0.752\n",
            "val loss: 34.88252955675125\n",
            "accuracy:      0.751\n",
            "precision:     0.754\n",
            "recall:        0.753\n",
            "f1:            0.751\n",
            "===== Start training: epoch 14 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.48661732673645, Epoch: 14, training loss: 355.3525849580765, current learning rate 1e-05\n",
            "val loss: 44.13727152347565\n",
            "accuracy:      0.745\n",
            "precision:     0.746\n",
            "recall:        0.745\n",
            "f1:            0.745\n",
            "val loss: 45.34925550222397\n",
            "accuracy:      0.743\n",
            "precision:     0.746\n",
            "recall:        0.745\n",
            "f1:            0.743\n",
            "===== Start training: epoch 15 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:53,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.46142888069153, Epoch: 15, training loss: 334.74223470687866, current learning rate 1e-05\n",
            "val loss: 45.63799250125885\n",
            "accuracy:      0.748\n",
            "precision:     0.748\n",
            "recall:        0.748\n",
            "f1:            0.748\n",
            "val loss: 48.04848635196686\n",
            "accuracy:      0.742\n",
            "precision:     0.744\n",
            "recall:        0.743\n",
            "f1:            0.742\n",
            "===== Start training: epoch 16 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.47974371910095, Epoch: 16, training loss: 322.48500871658325, current learning rate 1e-05\n",
            "val loss: 45.65902614593506\n",
            "accuracy:      0.744\n",
            "precision:     0.745\n",
            "recall:        0.744\n",
            "f1:            0.744\n",
            "val loss: 46.375114262104034\n",
            "accuracy:      0.750\n",
            "precision:     0.752\n",
            "recall:        0.751\n",
            "f1:            0.750\n",
            "===== Start training: epoch 17 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.58361625671387, Epoch: 17, training loss: 340.20488250255585, current learning rate 1e-05\n",
            "val loss: 49.28996330499649\n",
            "accuracy:      0.746\n",
            "precision:     0.746\n",
            "recall:        0.747\n",
            "f1:            0.746\n",
            "val loss: 48.404049932956696\n",
            "accuracy:      0.749\n",
            "precision:     0.749\n",
            "recall:        0.749\n",
            "f1:            0.749\n",
            "===== Start training: epoch 18 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.476654052734375, Epoch: 18, training loss: 364.84057080745697, current learning rate 1e-05\n",
            "val loss: 49.93456047773361\n",
            "accuracy:      0.752\n",
            "precision:     0.752\n",
            "recall:        0.752\n",
            "f1:            0.752\n",
            "val loss: 50.1800891160965\n",
            "accuracy:      0.753\n",
            "precision:     0.752\n",
            "recall:        0.752\n",
            "f1:            0.752\n",
            "===== Start training: epoch 19 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.47538614273071, Epoch: 19, training loss: 374.5475867986679, current learning rate 1e-05\n",
            "val loss: 45.9968495965004\n",
            "accuracy:      0.755\n",
            "precision:     0.755\n",
            "recall:        0.755\n",
            "f1:            0.755\n",
            "val loss: 45.51885658502579\n",
            "accuracy:      0.758\n",
            "precision:     0.757\n",
            "recall:        0.758\n",
            "f1:            0.757\n",
            "===== Start training: epoch 20 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.49738001823425, Epoch: 20, training loss: 375.7521468400955, current learning rate 1e-05\n",
            "val loss: 43.010222136974335\n",
            "accuracy:      0.748\n",
            "precision:     0.753\n",
            "recall:        0.748\n",
            "f1:            0.746\n",
            "val loss: 43.02838450670242\n",
            "accuracy:      0.746\n",
            "precision:     0.752\n",
            "recall:        0.749\n",
            "f1:            0.745\n",
            "===== Start training: epoch 21 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.4958381652832, Epoch: 21, training loss: 371.3248063325882, current learning rate 1e-05\n",
            "val loss: 42.63000249862671\n",
            "accuracy:      0.762\n",
            "precision:     0.764\n",
            "recall:        0.763\n",
            "f1:            0.762\n",
            "val loss: 42.35555648803711\n",
            "accuracy:      0.763\n",
            "precision:     0.764\n",
            "recall:        0.764\n",
            "f1:            0.763\n",
            "===== Start training: epoch 22 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.46528601646423, Epoch: 22, training loss: 369.55856013298035, current learning rate 1e-05\n",
            "val loss: 50.03130483627319\n",
            "accuracy:      0.762\n",
            "precision:     0.765\n",
            "recall:        0.762\n",
            "f1:            0.761\n",
            "val loss: 49.256685972213745\n",
            "accuracy:      0.759\n",
            "precision:     0.763\n",
            "recall:        0.761\n",
            "f1:            0.759\n",
            "===== Start training: epoch 23 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.5636088848114, Epoch: 23, training loss: 365.93786013126373, current learning rate 1e-05\n",
            "val loss: 51.584200382232666\n",
            "accuracy:      0.759\n",
            "precision:     0.760\n",
            "recall:        0.759\n",
            "f1:            0.759\n",
            "val loss: 51.701335430145264\n",
            "accuracy:      0.757\n",
            "precision:     0.757\n",
            "recall:        0.758\n",
            "f1:            0.757\n",
            "===== Start training: epoch 24 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.54482102394104, Epoch: 24, training loss: 356.4238328933716, current learning rate 1e-05\n",
            "val loss: 63.10585165023804\n",
            "accuracy:      0.754\n",
            "precision:     0.755\n",
            "recall:        0.754\n",
            "f1:            0.754\n",
            "val loss: 61.15479397773743\n",
            "accuracy:      0.757\n",
            "precision:     0.759\n",
            "recall:        0.758\n",
            "f1:            0.757\n",
            "===== Start training: epoch 25 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.50326371192932, Epoch: 25, training loss: 331.5799437761307, current learning rate 1e-05\n",
            "val loss: 64.25281369686127\n",
            "accuracy:      0.757\n",
            "precision:     0.757\n",
            "recall:        0.758\n",
            "f1:            0.758\n",
            "val loss: 63.599738121032715\n",
            "accuracy:      0.761\n",
            "precision:     0.760\n",
            "recall:        0.761\n",
            "f1:            0.761\n",
            "===== Start training: epoch 26 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.47772669792175, Epoch: 26, training loss: 313.77783596515656, current learning rate 1e-05\n",
            "val loss: 53.95468312501907\n",
            "accuracy:      0.760\n",
            "precision:     0.763\n",
            "recall:        0.760\n",
            "f1:            0.759\n",
            "val loss: 53.26941227912903\n",
            "accuracy:      0.753\n",
            "precision:     0.757\n",
            "recall:        0.755\n",
            "f1:            0.753\n",
            "===== Start training: epoch 27 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.57344365119934, Epoch: 27, training loss: 318.087229013443, current learning rate 1e-05\n",
            "val loss: 55.18224322795868\n",
            "accuracy:      0.758\n",
            "precision:     0.758\n",
            "recall:        0.759\n",
            "f1:            0.758\n",
            "val loss: 54.569834649562836\n",
            "accuracy:      0.759\n",
            "precision:     0.759\n",
            "recall:        0.759\n",
            "f1:            0.758\n",
            "===== Start training: epoch 28 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.54012417793274, Epoch: 28, training loss: 304.65256452560425, current learning rate 1e-05\n",
            "val loss: 62.304373264312744\n",
            "accuracy:      0.760\n",
            "precision:     0.760\n",
            "recall:        0.761\n",
            "f1:            0.760\n",
            "val loss: 61.65096306800842\n",
            "accuracy:      0.766\n",
            "precision:     0.766\n",
            "recall:        0.766\n",
            "f1:            0.766\n",
            "===== Start training: epoch 29 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.52547740936279, Epoch: 29, training loss: 302.49224627017975, current learning rate 1e-05\n",
            "val loss: 49.65616816282272\n",
            "accuracy:      0.756\n",
            "precision:     0.757\n",
            "recall:        0.756\n",
            "f1:            0.755\n",
            "val loss: 50.4651620388031\n",
            "accuracy:      0.749\n",
            "precision:     0.752\n",
            "recall:        0.751\n",
            "f1:            0.749\n",
            "===== Start training: epoch 30 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.496989011764526, Epoch: 30, training loss: 308.8113968372345, current learning rate 1e-05\n",
            "val loss: 51.2683539390564\n",
            "accuracy:      0.765\n",
            "precision:     0.765\n",
            "recall:        0.765\n",
            "f1:            0.765\n",
            "val loss: 50.76712042093277\n",
            "accuracy:      0.761\n",
            "precision:     0.760\n",
            "recall:        0.760\n",
            "f1:            0.760\n",
            "best result:\n",
            "0.7608695652173914\n",
            "0.7604402483364203\n",
            "0.7603766144138815\n",
            "0.7604069605306847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Start training: epoch 1 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.526283979415894, Epoch: 1, training loss: 732.4561681747437, current learning rate 1e-05\n",
            "val loss: 23.460149347782135\n",
            "accuracy:      0.559\n",
            "precision:     0.576\n",
            "recall:        0.558\n",
            "f1:            0.530\n",
            "val loss: 23.503870248794556\n",
            "accuracy:      0.543\n",
            "precision:     0.577\n",
            "recall:        0.555\n",
            "f1:            0.513\n",
            "===== Start training: epoch 2 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.62705755233765, Epoch: 2, training loss: 1085.897569179535, current learning rate 1e-05\n",
            "val loss: 20.774281442165375\n",
            "accuracy:      0.675\n",
            "precision:     0.707\n",
            "recall:        0.674\n",
            "f1:            0.661\n",
            "val loss: 21.00206595659256\n",
            "accuracy:      0.669\n",
            "precision:     0.709\n",
            "recall:        0.677\n",
            "f1:            0.659\n",
            "===== Start training: epoch 3 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.68555927276611, Epoch: 3, training loss: 1206.4622478485107, current learning rate 1e-05\n",
            "val loss: 18.338292062282562\n",
            "accuracy:      0.725\n",
            "precision:     0.731\n",
            "recall:        0.725\n",
            "f1:            0.723\n",
            "val loss: 18.561100363731384\n",
            "accuracy:      0.713\n",
            "precision:     0.722\n",
            "recall:        0.717\n",
            "f1:            0.712\n",
            "===== Start training: epoch 4 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.68954634666443, Epoch: 4, training loss: 1218.7142930030823, current learning rate 1e-05\n",
            "val loss: 18.281585097312927\n",
            "accuracy:      0.750\n",
            "precision:     0.752\n",
            "recall:        0.751\n",
            "f1:            0.750\n",
            "val loss: 17.830446183681488\n",
            "accuracy:      0.748\n",
            "precision:     0.749\n",
            "recall:        0.750\n",
            "f1:            0.748\n",
            "===== Start training: epoch 5 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.61598300933838, Epoch: 5, training loss: 1142.3589525222778, current learning rate 1e-05\n",
            "val loss: 19.208124190568924\n",
            "accuracy:      0.750\n",
            "precision:     0.751\n",
            "recall:        0.751\n",
            "f1:            0.750\n",
            "val loss: 18.478179544210434\n",
            "accuracy:      0.749\n",
            "precision:     0.750\n",
            "recall:        0.748\n",
            "f1:            0.748\n",
            "===== Start training: epoch 6 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.61184215545654, Epoch: 6, training loss: 1048.4127535820007, current learning rate 1e-05\n",
            "val loss: 23.781272411346436\n",
            "accuracy:      0.753\n",
            "precision:     0.753\n",
            "recall:        0.753\n",
            "f1:            0.753\n",
            "val loss: 22.153336495161057\n",
            "accuracy:      0.753\n",
            "precision:     0.753\n",
            "recall:        0.753\n",
            "f1:            0.753\n",
            "===== Start training: epoch 7 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.61789345741272, Epoch: 7, training loss: 911.7971301078796, current learning rate 1e-05\n",
            "val loss: 25.335809379816055\n",
            "accuracy:      0.754\n",
            "precision:     0.756\n",
            "recall:        0.754\n",
            "f1:            0.753\n",
            "val loss: 24.291603833436966\n",
            "accuracy:      0.751\n",
            "precision:     0.754\n",
            "recall:        0.753\n",
            "f1:            0.751\n",
            "===== Start training: epoch 8 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.61613583564758, Epoch: 8, training loss: 788.6530814170837, current learning rate 1e-05\n",
            "val loss: 25.309872657060623\n",
            "accuracy:      0.749\n",
            "precision:     0.752\n",
            "recall:        0.749\n",
            "f1:            0.748\n",
            "val loss: 24.36504316329956\n",
            "accuracy:      0.750\n",
            "precision:     0.754\n",
            "recall:        0.753\n",
            "f1:            0.750\n",
            "===== Start training: epoch 9 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.61848592758179, Epoch: 9, training loss: 672.277321100235, current learning rate 1e-05\n",
            "val loss: 30.570971071720123\n",
            "accuracy:      0.748\n",
            "precision:     0.749\n",
            "recall:        0.749\n",
            "f1:            0.748\n",
            "val loss: 28.837051272392273\n",
            "accuracy:      0.755\n",
            "precision:     0.755\n",
            "recall:        0.755\n",
            "f1:            0.755\n",
            "===== Start training: epoch 10 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.57712125778198, Epoch: 10, training loss: 587.9115326404572, current learning rate 1e-05\n",
            "val loss: 35.56189000606537\n",
            "accuracy:      0.748\n",
            "precision:     0.759\n",
            "recall:        0.747\n",
            "f1:            0.745\n",
            "val loss: 35.61653959751129\n",
            "accuracy:      0.742\n",
            "precision:     0.757\n",
            "recall:        0.747\n",
            "f1:            0.741\n",
            "===== Start training: epoch 11 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.58150291442871, Epoch: 11, training loss: 513.3814961910248, current learning rate 1e-05\n",
            "val loss: 30.61510530114174\n",
            "accuracy:      0.752\n",
            "precision:     0.753\n",
            "recall:        0.752\n",
            "f1:            0.752\n",
            "val loss: 29.706574648618698\n",
            "accuracy:      0.763\n",
            "precision:     0.763\n",
            "recall:        0.764\n",
            "f1:            0.763\n",
            "===== Start training: epoch 12 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.640477657318115, Epoch: 12, training loss: 456.94525718688965, current learning rate 1e-05\n",
            "val loss: 34.3598957657814\n",
            "accuracy:      0.750\n",
            "precision:     0.752\n",
            "recall:        0.751\n",
            "f1:            0.750\n",
            "val loss: 34.86931562423706\n",
            "accuracy:      0.746\n",
            "precision:     0.747\n",
            "recall:        0.747\n",
            "f1:            0.746\n",
            "===== Start training: epoch 13 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.60959076881409, Epoch: 13, training loss: 411.2253565788269, current learning rate 1e-05\n",
            "val loss: 41.44793528318405\n",
            "accuracy:      0.753\n",
            "precision:     0.758\n",
            "recall:        0.753\n",
            "f1:            0.752\n",
            "val loss: 40.58051782846451\n",
            "accuracy:      0.754\n",
            "precision:     0.763\n",
            "recall:        0.758\n",
            "f1:            0.754\n",
            "===== Start training: epoch 14 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.59309363365173, Epoch: 14, training loss: 377.0542186498642, current learning rate 1e-05\n",
            "val loss: 40.88938879966736\n",
            "accuracy:      0.755\n",
            "precision:     0.758\n",
            "recall:        0.755\n",
            "f1:            0.754\n",
            "val loss: 39.765770852565765\n",
            "accuracy:      0.758\n",
            "precision:     0.762\n",
            "recall:        0.760\n",
            "f1:            0.757\n",
            "===== Start training: epoch 15 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.53240752220154, Epoch: 15, training loss: 354.1879014968872, current learning rate 1e-05\n",
            "val loss: 37.44071412086487\n",
            "accuracy:      0.750\n",
            "precision:     0.752\n",
            "recall:        0.751\n",
            "f1:            0.750\n",
            "val loss: 37.550378143787384\n",
            "accuracy:      0.746\n",
            "precision:     0.749\n",
            "recall:        0.748\n",
            "f1:            0.746\n",
            "===== Start training: epoch 16 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.52478647232056, Epoch: 16, training loss: 341.34894037246704, current learning rate 1e-05\n",
            "val loss: 37.905123591423035\n",
            "accuracy:      0.754\n",
            "precision:     0.754\n",
            "recall:        0.754\n",
            "f1:            0.754\n",
            "val loss: 37.55784910917282\n",
            "accuracy:      0.749\n",
            "precision:     0.749\n",
            "recall:        0.748\n",
            "f1:            0.749\n",
            "===== Start training: epoch 17 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.5142776966095, Epoch: 17, training loss: 332.8878153562546, current learning rate 1e-05\n",
            "val loss: 42.80442136526108\n",
            "accuracy:      0.746\n",
            "precision:     0.747\n",
            "recall:        0.746\n",
            "f1:            0.746\n",
            "val loss: 41.814244985580444\n",
            "accuracy:      0.750\n",
            "precision:     0.752\n",
            "recall:        0.752\n",
            "f1:            0.750\n",
            "===== Start training: epoch 18 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.573376417160034, Epoch: 18, training loss: 326.821212887764, current learning rate 1e-05\n",
            "val loss: 43.45241552591324\n",
            "accuracy:      0.747\n",
            "precision:     0.747\n",
            "recall:        0.747\n",
            "f1:            0.747\n",
            "val loss: 43.64768436551094\n",
            "accuracy:      0.738\n",
            "precision:     0.737\n",
            "recall:        0.737\n",
            "f1:            0.737\n",
            "===== Start training: epoch 19 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.55420470237732, Epoch: 19, training loss: 330.5501048564911, current learning rate 1e-05\n",
            "val loss: 48.13708174228668\n",
            "accuracy:      0.756\n",
            "precision:     0.758\n",
            "recall:        0.756\n",
            "f1:            0.755\n",
            "val loss: 49.72427171468735\n",
            "accuracy:      0.747\n",
            "precision:     0.751\n",
            "recall:        0.749\n",
            "f1:            0.747\n",
            "===== Start training: epoch 20 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.4693865776062, Epoch: 20, training loss: 326.54101836681366, current learning rate 1e-05\n",
            "val loss: 47.12648344039917\n",
            "accuracy:      0.745\n",
            "precision:     0.750\n",
            "recall:        0.745\n",
            "f1:            0.744\n",
            "val loss: 47.26224994659424\n",
            "accuracy:      0.737\n",
            "precision:     0.746\n",
            "recall:        0.741\n",
            "f1:            0.736\n",
            "===== Start training: epoch 21 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.474848985672, Epoch: 21, training loss: 317.9687613248825, current learning rate 1e-05\n",
            "val loss: 46.982950925827026\n",
            "accuracy:      0.762\n",
            "precision:     0.762\n",
            "recall:        0.762\n",
            "f1:            0.762\n",
            "val loss: 48.49547106027603\n",
            "accuracy:      0.751\n",
            "precision:     0.751\n",
            "recall:        0.751\n",
            "f1:            0.751\n",
            "===== Start training: epoch 22 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.52881121635437, Epoch: 22, training loss: 316.19618713855743, current learning rate 1e-05\n",
            "val loss: 44.20498675107956\n",
            "accuracy:      0.758\n",
            "precision:     0.759\n",
            "recall:        0.759\n",
            "f1:            0.758\n",
            "val loss: 46.79210251569748\n",
            "accuracy:      0.758\n",
            "precision:     0.759\n",
            "recall:        0.759\n",
            "f1:            0.758\n",
            "===== Start training: epoch 23 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.48931169509888, Epoch: 23, training loss: 316.9275028705597, current learning rate 1e-05\n",
            "val loss: 49.52585142850876\n",
            "accuracy:      0.750\n",
            "precision:     0.753\n",
            "recall:        0.750\n",
            "f1:            0.749\n",
            "val loss: 49.37129884958267\n",
            "accuracy:      0.750\n",
            "precision:     0.754\n",
            "recall:        0.752\n",
            "f1:            0.750\n",
            "===== Start training: epoch 24 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.51950407028198, Epoch: 24, training loss: 320.89205181598663, current learning rate 1e-05\n",
            "val loss: 46.60332763195038\n",
            "accuracy:      0.753\n",
            "precision:     0.753\n",
            "recall:        0.754\n",
            "f1:            0.753\n",
            "val loss: 47.22244119644165\n",
            "accuracy:      0.747\n",
            "precision:     0.746\n",
            "recall:        0.746\n",
            "f1:            0.746\n",
            "===== Start training: epoch 25 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.57902455329895, Epoch: 25, training loss: 314.952379822731, current learning rate 1e-05\n",
            "val loss: 47.814370691776276\n",
            "accuracy:      0.759\n",
            "precision:     0.759\n",
            "recall:        0.760\n",
            "f1:            0.759\n",
            "val loss: 48.17445206642151\n",
            "accuracy:      0.753\n",
            "precision:     0.754\n",
            "recall:        0.754\n",
            "f1:            0.753\n",
            "===== Start training: epoch 26 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.58941030502319, Epoch: 26, training loss: 320.1766735315323, current learning rate 1e-05\n",
            "val loss: 44.97420734167099\n",
            "accuracy:      0.754\n",
            "precision:     0.758\n",
            "recall:        0.754\n",
            "f1:            0.753\n",
            "val loss: 45.22207826375961\n",
            "accuracy:      0.755\n",
            "precision:     0.761\n",
            "recall:        0.758\n",
            "f1:            0.755\n",
            "===== Start training: epoch 27 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.6443612575531, Epoch: 27, training loss: 318.1576546430588, current learning rate 1e-05\n",
            "val loss: 49.38844442367554\n",
            "accuracy:      0.752\n",
            "precision:     0.752\n",
            "recall:        0.752\n",
            "f1:            0.752\n",
            "val loss: 49.04218250513077\n",
            "accuracy:      0.753\n",
            "precision:     0.753\n",
            "recall:        0.753\n",
            "f1:            0.753\n",
            "===== Start training: epoch 28 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.56680393218994, Epoch: 28, training loss: 311.8295202255249, current learning rate 1e-05\n",
            "val loss: 43.45180368423462\n",
            "accuracy:      0.757\n",
            "precision:     0.758\n",
            "recall:        0.758\n",
            "f1:            0.758\n",
            "val loss: 42.295942813158035\n",
            "accuracy:      0.764\n",
            "precision:     0.763\n",
            "recall:        0.763\n",
            "f1:            0.763\n",
            "===== Start training: epoch 29 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.578532218933105, Epoch: 29, training loss: 312.7532684803009, current learning rate 1e-05\n",
            "val loss: 38.11527842283249\n",
            "accuracy:      0.748\n",
            "precision:     0.749\n",
            "recall:        0.748\n",
            "f1:            0.748\n",
            "val loss: 36.9763218164444\n",
            "accuracy:      0.761\n",
            "precision:     0.763\n",
            "recall:        0.763\n",
            "f1:            0.761\n",
            "===== Start training: epoch 30 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.618794441223145, Epoch: 30, training loss: 313.5445946455002, current learning rate 1e-05\n",
            "val loss: 38.244065165519714\n",
            "accuracy:      0.768\n",
            "precision:     0.768\n",
            "recall:        0.768\n",
            "f1:            0.767\n",
            "val loss: 37.43093055486679\n",
            "accuracy:      0.759\n",
            "precision:     0.761\n",
            "recall:        0.761\n",
            "f1:            0.759\n",
            "best result:\n",
            "0.759481961147086\n",
            "0.7612853679987988\n",
            "0.761056886522725\n",
            "0.7594768154340132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Start training: epoch 1 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.57866454124451, Epoch: 1, training loss: 772.203812122345, current learning rate 1e-05\n",
            "val loss: 22.91184765100479\n",
            "accuracy:      0.621\n",
            "precision:     0.622\n",
            "recall:        0.621\n",
            "f1:            0.619\n",
            "val loss: 22.896551489830017\n",
            "accuracy:      0.631\n",
            "precision:     0.636\n",
            "recall:        0.634\n",
            "f1:            0.631\n",
            "===== Start training: epoch 2 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.640846490859985, Epoch: 2, training loss: 989.2513203620911, current learning rate 1e-05\n",
            "val loss: 20.101846039295197\n",
            "accuracy:      0.687\n",
            "precision:     0.722\n",
            "recall:        0.686\n",
            "f1:            0.674\n",
            "val loss: 20.2287078499794\n",
            "accuracy:      0.678\n",
            "precision:     0.722\n",
            "recall:        0.687\n",
            "f1:            0.668\n",
            "===== Start training: epoch 3 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.64835500717163, Epoch: 3, training loss: 1076.518002986908, current learning rate 1e-05\n",
            "val loss: 17.70043158531189\n",
            "accuracy:      0.742\n",
            "precision:     0.747\n",
            "recall:        0.742\n",
            "f1:            0.741\n",
            "val loss: 17.90121364593506\n",
            "accuracy:      0.730\n",
            "precision:     0.737\n",
            "recall:        0.733\n",
            "f1:            0.730\n",
            "===== Start training: epoch 4 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<15:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.71414923667908, Epoch: 4, training loss: 1106.012276172638, current learning rate 1e-05\n",
            "val loss: 18.40463352203369\n",
            "accuracy:      0.752\n",
            "precision:     0.752\n",
            "recall:        0.752\n",
            "f1:            0.752\n",
            "val loss: 17.478313267230988\n",
            "accuracy:      0.753\n",
            "precision:     0.753\n",
            "recall:        0.752\n",
            "f1:            0.752\n",
            "===== Start training: epoch 5 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.68737030029297, Epoch: 5, training loss: 1082.2291860580444, current learning rate 1e-05\n",
            "val loss: 19.399372160434723\n",
            "accuracy:      0.751\n",
            "precision:     0.752\n",
            "recall:        0.751\n",
            "f1:            0.751\n",
            "val loss: 18.451939672231674\n",
            "accuracy:      0.753\n",
            "precision:     0.753\n",
            "recall:        0.752\n",
            "f1:            0.752\n",
            "===== Start training: epoch 6 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.65886688232422, Epoch: 6, training loss: 1003.9428586959839, current learning rate 1e-05\n",
            "val loss: 22.056057423353195\n",
            "accuracy:      0.759\n",
            "precision:     0.759\n",
            "recall:        0.759\n",
            "f1:            0.759\n",
            "val loss: 20.227288961410522\n",
            "accuracy:      0.761\n",
            "precision:     0.761\n",
            "recall:        0.761\n",
            "f1:            0.761\n",
            "===== Start training: epoch 7 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.649025678634644, Epoch: 7, training loss: 894.9763128757477, current learning rate 1e-05\n",
            "val loss: 24.07169735431671\n",
            "accuracy:      0.757\n",
            "precision:     0.760\n",
            "recall:        0.757\n",
            "f1:            0.756\n",
            "val loss: 22.931541591882706\n",
            "accuracy:      0.750\n",
            "precision:     0.755\n",
            "recall:        0.752\n",
            "f1:            0.750\n",
            "===== Start training: epoch 8 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.669694662094116, Epoch: 8, training loss: 800.3005976676941, current learning rate 1e-05\n",
            "val loss: 26.072477102279663\n",
            "accuracy:      0.748\n",
            "precision:     0.755\n",
            "recall:        0.748\n",
            "f1:            0.746\n",
            "val loss: 24.44672918319702\n",
            "accuracy:      0.760\n",
            "precision:     0.770\n",
            "recall:        0.764\n",
            "f1:            0.760\n",
            "===== Start training: epoch 9 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.60068726539612, Epoch: 9, training loss: 700.1094121932983, current learning rate 1e-05\n",
            "val loss: 23.85662803053856\n",
            "accuracy:      0.756\n",
            "precision:     0.756\n",
            "recall:        0.756\n",
            "f1:            0.756\n",
            "val loss: 22.98112717270851\n",
            "accuracy:      0.755\n",
            "precision:     0.755\n",
            "recall:        0.755\n",
            "f1:            0.755\n",
            "===== Start training: epoch 10 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<15:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.72255992889404, Epoch: 10, training loss: 620.8901209831238, current learning rate 1e-05\n",
            "val loss: 32.450878620147705\n",
            "accuracy:      0.755\n",
            "precision:     0.765\n",
            "recall:        0.755\n",
            "f1:            0.753\n",
            "val loss: 32.29084002971649\n",
            "accuracy:      0.753\n",
            "precision:     0.764\n",
            "recall:        0.757\n",
            "f1:            0.752\n",
            "===== Start training: epoch 11 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.69342064857483, Epoch: 11, training loss: 546.0693151950836, current learning rate 1e-05\n",
            "val loss: 30.62426632642746\n",
            "accuracy:      0.766\n",
            "precision:     0.767\n",
            "recall:        0.766\n",
            "f1:            0.766\n",
            "val loss: 29.14056959748268\n",
            "accuracy:      0.771\n",
            "precision:     0.771\n",
            "recall:        0.771\n",
            "f1:            0.771\n",
            "===== Start training: epoch 12 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<15:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.71356773376465, Epoch: 12, training loss: 491.5405652523041, current learning rate 1e-05\n",
            "val loss: 34.36124235391617\n",
            "accuracy:      0.755\n",
            "precision:     0.756\n",
            "recall:        0.755\n",
            "f1:            0.754\n",
            "val loss: 34.525192856788635\n",
            "accuracy:      0.757\n",
            "precision:     0.759\n",
            "recall:        0.758\n",
            "f1:            0.757\n",
            "===== Start training: epoch 13 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.670390605926514, Epoch: 13, training loss: 456.98223650455475, current learning rate 1e-05\n",
            "val loss: 34.9645978808403\n",
            "accuracy:      0.761\n",
            "precision:     0.763\n",
            "recall:        0.761\n",
            "f1:            0.761\n",
            "val loss: 32.92070156335831\n",
            "accuracy:      0.774\n",
            "precision:     0.776\n",
            "recall:        0.776\n",
            "f1:            0.774\n",
            "===== Start training: epoch 14 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<15:01,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.73521852493286, Epoch: 14, training loss: 428.32722651958466, current learning rate 1e-05\n",
            "val loss: 38.92536002397537\n",
            "accuracy:      0.762\n",
            "precision:     0.767\n",
            "recall:        0.762\n",
            "f1:            0.761\n",
            "val loss: 37.12834721803665\n",
            "accuracy:      0.772\n",
            "precision:     0.777\n",
            "recall:        0.775\n",
            "f1:            0.772\n",
            "===== Start training: epoch 15 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.67143654823303, Epoch: 15, training loss: 400.6337547302246, current learning rate 1e-05\n",
            "val loss: 40.464176177978516\n",
            "accuracy:      0.766\n",
            "precision:     0.766\n",
            "recall:        0.767\n",
            "f1:            0.766\n",
            "val loss: 38.54677152633667\n",
            "accuracy:      0.775\n",
            "precision:     0.775\n",
            "recall:        0.775\n",
            "f1:            0.775\n",
            "===== Start training: epoch 16 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.65561366081238, Epoch: 16, training loss: 383.23870968818665, current learning rate 1e-05\n",
            "val loss: 36.59586971998215\n",
            "accuracy:      0.765\n",
            "precision:     0.766\n",
            "recall:        0.765\n",
            "f1:            0.765\n",
            "val loss: 35.184418857097626\n",
            "accuracy:      0.762\n",
            "precision:     0.763\n",
            "recall:        0.761\n",
            "f1:            0.761\n",
            "===== Start training: epoch 17 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.59074139595032, Epoch: 17, training loss: 373.42096734046936, current learning rate 1e-05\n",
            "val loss: 38.37720489501953\n",
            "accuracy:      0.756\n",
            "precision:     0.757\n",
            "recall:        0.757\n",
            "f1:            0.756\n",
            "val loss: 36.63338214159012\n",
            "accuracy:      0.757\n",
            "precision:     0.757\n",
            "recall:        0.758\n",
            "f1:            0.757\n",
            "===== Start training: epoch 18 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.597347259521484, Epoch: 18, training loss: 364.9994820356369, current learning rate 1e-05\n",
            "val loss: 40.35134291648865\n",
            "accuracy:      0.766\n",
            "precision:     0.767\n",
            "recall:        0.766\n",
            "f1:            0.766\n",
            "val loss: 40.636245906353\n",
            "accuracy:      0.756\n",
            "precision:     0.759\n",
            "recall:        0.758\n",
            "f1:            0.756\n",
            "===== Start training: epoch 19 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.60066890716553, Epoch: 19, training loss: 356.5056085586548, current learning rate 1e-05\n",
            "val loss: 39.25174903869629\n",
            "accuracy:      0.763\n",
            "precision:     0.764\n",
            "recall:        0.764\n",
            "f1:            0.763\n",
            "val loss: 38.69210457801819\n",
            "accuracy:      0.755\n",
            "precision:     0.756\n",
            "recall:        0.756\n",
            "f1:            0.755\n",
            "===== Start training: epoch 20 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.5972101688385, Epoch: 20, training loss: 345.39518773555756, current learning rate 1e-05\n",
            "val loss: 43.37619423866272\n",
            "accuracy:      0.743\n",
            "precision:     0.754\n",
            "recall:        0.742\n",
            "f1:            0.739\n",
            "val loss: 44.146648645401\n",
            "accuracy:      0.737\n",
            "precision:     0.754\n",
            "recall:        0.742\n",
            "f1:            0.735\n",
            "===== Start training: epoch 21 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.61787819862366, Epoch: 21, training loss: 335.91384506225586, current learning rate 1e-05\n",
            "val loss: 38.445125848054886\n",
            "accuracy:      0.763\n",
            "precision:     0.763\n",
            "recall:        0.764\n",
            "f1:            0.764\n",
            "val loss: 38.214216470718384\n",
            "accuracy:      0.757\n",
            "precision:     0.757\n",
            "recall:        0.757\n",
            "f1:            0.757\n",
            "===== Start training: epoch 22 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.572211027145386, Epoch: 22, training loss: 321.77089607715607, current learning rate 1e-05\n",
            "val loss: 43.24205666780472\n",
            "accuracy:      0.756\n",
            "precision:     0.758\n",
            "recall:        0.757\n",
            "f1:            0.756\n",
            "val loss: 41.88534218072891\n",
            "accuracy:      0.759\n",
            "precision:     0.762\n",
            "recall:        0.761\n",
            "f1:            0.759\n",
            "===== Start training: epoch 23 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.625913858413696, Epoch: 23, training loss: 319.68824446201324, current learning rate 1e-05\n",
            "val loss: 42.200169026851654\n",
            "accuracy:      0.760\n",
            "precision:     0.760\n",
            "recall:        0.760\n",
            "f1:            0.760\n",
            "val loss: 41.66834253072739\n",
            "accuracy:      0.760\n",
            "precision:     0.760\n",
            "recall:        0.761\n",
            "f1:            0.760\n",
            "===== Start training: epoch 24 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.654130935668945, Epoch: 24, training loss: 319.0410907268524, current learning rate 1e-05\n",
            "val loss: 44.88030084967613\n",
            "accuracy:      0.764\n",
            "precision:     0.765\n",
            "recall:        0.765\n",
            "f1:            0.764\n",
            "val loss: 43.78637009859085\n",
            "accuracy:      0.765\n",
            "precision:     0.765\n",
            "recall:        0.765\n",
            "f1:            0.765\n",
            "===== Start training: epoch 25 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.63444423675537, Epoch: 25, training loss: 313.3033918142319, current learning rate 1e-05\n",
            "val loss: 45.88456970453262\n",
            "accuracy:      0.767\n",
            "precision:     0.767\n",
            "recall:        0.767\n",
            "f1:            0.767\n",
            "val loss: 45.8519486784935\n",
            "accuracy:      0.765\n",
            "precision:     0.765\n",
            "recall:        0.765\n",
            "f1:            0.765\n",
            "===== Start training: epoch 26 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.585463762283325, Epoch: 26, training loss: 316.18401491642, current learning rate 1e-05\n",
            "val loss: 46.79458677768707\n",
            "accuracy:      0.763\n",
            "precision:     0.771\n",
            "recall:        0.763\n",
            "f1:            0.761\n",
            "val loss: 46.16529858112335\n",
            "accuracy:      0.757\n",
            "precision:     0.765\n",
            "recall:        0.761\n",
            "f1:            0.757\n",
            "===== Start training: epoch 27 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.580267667770386, Epoch: 27, training loss: 310.2706184387207, current learning rate 1e-05\n",
            "val loss: 43.55328053236008\n",
            "accuracy:      0.766\n",
            "precision:     0.766\n",
            "recall:        0.766\n",
            "f1:            0.766\n",
            "val loss: 45.109029829502106\n",
            "accuracy:      0.750\n",
            "precision:     0.750\n",
            "recall:        0.749\n",
            "f1:            0.749\n",
            "===== Start training: epoch 28 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.587430238723755, Epoch: 28, training loss: 307.51822674274445, current learning rate 1e-05\n",
            "val loss: 41.37980890274048\n",
            "accuracy:      0.768\n",
            "precision:     0.768\n",
            "recall:        0.768\n",
            "f1:            0.768\n",
            "val loss: 40.59495687484741\n",
            "accuracy:      0.765\n",
            "precision:     0.764\n",
            "recall:        0.763\n",
            "f1:            0.764\n",
            "===== Start training: epoch 29 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.50858998298645, Epoch: 29, training loss: 305.7791658639908, current learning rate 1e-05\n",
            "val loss: 40.97696566581726\n",
            "accuracy:      0.759\n",
            "precision:     0.759\n",
            "recall:        0.760\n",
            "f1:            0.759\n",
            "val loss: 40.310474932193756\n",
            "accuracy:      0.753\n",
            "precision:     0.752\n",
            "recall:        0.753\n",
            "f1:            0.752\n",
            "===== Start training: epoch 30 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.62999749183655, Epoch: 30, training loss: 306.76674485206604, current learning rate 1e-05\n",
            "val loss: 44.52905374765396\n",
            "accuracy:      0.761\n",
            "precision:     0.762\n",
            "recall:        0.761\n",
            "f1:            0.761\n",
            "val loss: 43.034017622470856\n",
            "accuracy:      0.765\n",
            "precision:     0.766\n",
            "recall:        0.766\n",
            "f1:            0.765\n",
            "best result:\n",
            "0.7645698427382054\n",
            "0.7644954858169948\n",
            "0.7634131913635019\n",
            "0.7637286818992517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Start training: epoch 1 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.62360715866089, Epoch: 1, training loss: 811.1482427120209, current learning rate 1e-05\n",
            "val loss: 22.85732215642929\n",
            "accuracy:      0.620\n",
            "precision:     0.620\n",
            "recall:        0.620\n",
            "f1:            0.620\n",
            "val loss: 22.812467336654663\n",
            "accuracy:      0.642\n",
            "precision:     0.644\n",
            "recall:        0.643\n",
            "f1:            0.641\n",
            "===== Start training: epoch 2 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.66127252578735, Epoch: 2, training loss: 951.4759593009949, current learning rate 1e-05\n",
            "val loss: 19.867391526699066\n",
            "accuracy:      0.686\n",
            "precision:     0.716\n",
            "recall:        0.685\n",
            "f1:            0.674\n",
            "val loss: 19.959649205207825\n",
            "accuracy:      0.683\n",
            "precision:     0.718\n",
            "recall:        0.691\n",
            "f1:            0.675\n",
            "===== Start training: epoch 3 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<15:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.70248079299927, Epoch: 3, training loss: 1007.9672727584839, current learning rate 1e-05\n",
            "val loss: 17.655198454856873\n",
            "accuracy:      0.749\n",
            "precision:     0.752\n",
            "recall:        0.749\n",
            "f1:            0.748\n",
            "val loss: 17.84778791666031\n",
            "accuracy:      0.737\n",
            "precision:     0.741\n",
            "recall:        0.739\n",
            "f1:            0.737\n",
            "===== Start training: epoch 4 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<15:01,  5.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.74469709396362, Epoch: 4, training loss: 1032.1879215240479, current learning rate 1e-05\n",
            "val loss: 17.403364598751068\n",
            "accuracy:      0.756\n",
            "precision:     0.756\n",
            "recall:        0.756\n",
            "f1:            0.756\n",
            "val loss: 16.889259696006775\n",
            "accuracy:      0.759\n",
            "precision:     0.759\n",
            "recall:        0.759\n",
            "f1:            0.759\n",
            "===== Start training: epoch 5 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<15:02,  5.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.78382086753845, Epoch: 5, training loss: 1019.5258502960205, current learning rate 1e-05\n",
            "val loss: 20.19579803943634\n",
            "accuracy:      0.756\n",
            "precision:     0.756\n",
            "recall:        0.756\n",
            "f1:            0.756\n",
            "val loss: 19.17756888270378\n",
            "accuracy:      0.759\n",
            "precision:     0.759\n",
            "recall:        0.758\n",
            "f1:            0.759\n",
            "===== Start training: epoch 6 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.684914350509644, Epoch: 6, training loss: 972.3054351806641, current learning rate 1e-05\n",
            "val loss: 21.917697995901108\n",
            "accuracy:      0.762\n",
            "precision:     0.762\n",
            "recall:        0.762\n",
            "f1:            0.762\n",
            "val loss: 20.505915015935898\n",
            "accuracy:      0.764\n",
            "precision:     0.764\n",
            "recall:        0.764\n",
            "f1:            0.764\n",
            "===== Start training: epoch 7 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.68102765083313, Epoch: 7, training loss: 888.1503219604492, current learning rate 1e-05\n",
            "val loss: 21.714040845632553\n",
            "accuracy:      0.753\n",
            "precision:     0.753\n",
            "recall:        0.753\n",
            "f1:            0.753\n",
            "val loss: 20.579463124275208\n",
            "accuracy:      0.759\n",
            "precision:     0.758\n",
            "recall:        0.759\n",
            "f1:            0.758\n",
            "===== Start training: epoch 8 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<15:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.70303392410278, Epoch: 8, training loss: 812.1069021224976, current learning rate 1e-05\n",
            "val loss: 24.112975597381592\n",
            "accuracy:      0.756\n",
            "precision:     0.765\n",
            "recall:        0.756\n",
            "f1:            0.754\n",
            "val loss: 22.590749353170395\n",
            "accuracy:      0.750\n",
            "precision:     0.761\n",
            "recall:        0.754\n",
            "f1:            0.749\n",
            "===== Start training: epoch 9 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<15:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.695316791534424, Epoch: 9, training loss: 731.164303779602, current learning rate 1e-05\n",
            "val loss: 26.472876101732254\n",
            "accuracy:      0.748\n",
            "precision:     0.749\n",
            "recall:        0.748\n",
            "f1:            0.748\n",
            "val loss: 24.678420692682266\n",
            "accuracy:      0.772\n",
            "precision:     0.772\n",
            "recall:        0.770\n",
            "f1:            0.770\n",
            "===== Start training: epoch 10 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.631792068481445, Epoch: 10, training loss: 659.6049907207489, current learning rate 1e-05\n",
            "val loss: 34.16384148597717\n",
            "accuracy:      0.748\n",
            "precision:     0.760\n",
            "recall:        0.748\n",
            "f1:            0.745\n",
            "val loss: 33.31488049030304\n",
            "accuracy:      0.740\n",
            "precision:     0.753\n",
            "recall:        0.744\n",
            "f1:            0.739\n",
            "===== Start training: epoch 11 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<15:01,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.741564989089966, Epoch: 11, training loss: 589.9639053344727, current learning rate 1e-05\n",
            "val loss: 31.79163607954979\n",
            "accuracy:      0.745\n",
            "precision:     0.748\n",
            "recall:        0.745\n",
            "f1:            0.745\n",
            "val loss: 30.468541234731674\n",
            "accuracy:      0.762\n",
            "precision:     0.765\n",
            "recall:        0.764\n",
            "f1:            0.762\n",
            "===== Start training: epoch 12 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.58071947097778, Epoch: 12, training loss: 541.2521417140961, current learning rate 1e-05\n",
            "val loss: 33.748093605041504\n",
            "accuracy:      0.762\n",
            "precision:     0.763\n",
            "recall:        0.762\n",
            "f1:            0.762\n",
            "val loss: 33.04828733205795\n",
            "accuracy:      0.762\n",
            "precision:     0.764\n",
            "recall:        0.764\n",
            "f1:            0.762\n",
            "===== Start training: epoch 13 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.54750204086304, Epoch: 13, training loss: 493.9668390750885, current learning rate 1e-05\n",
            "val loss: 36.86989298462868\n",
            "accuracy:      0.761\n",
            "precision:     0.762\n",
            "recall:        0.761\n",
            "f1:            0.761\n",
            "val loss: 35.466664493083954\n",
            "accuracy:      0.765\n",
            "precision:     0.765\n",
            "recall:        0.766\n",
            "f1:            0.765\n",
            "===== Start training: epoch 14 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.54572057723999, Epoch: 14, training loss: 465.50605821609497, current learning rate 1e-05\n",
            "val loss: 39.71781814098358\n",
            "accuracy:      0.755\n",
            "precision:     0.761\n",
            "recall:        0.754\n",
            "f1:            0.753\n",
            "val loss: 39.43659728765488\n",
            "accuracy:      0.751\n",
            "precision:     0.759\n",
            "recall:        0.754\n",
            "f1:            0.750\n",
            "===== Start training: epoch 15 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.59292984008789, Epoch: 15, training loss: 436.2304470539093, current learning rate 1e-05\n",
            "val loss: 40.31965547800064\n",
            "accuracy:      0.763\n",
            "precision:     0.763\n",
            "recall:        0.763\n",
            "f1:            0.763\n",
            "val loss: 39.186802446842194\n",
            "accuracy:      0.765\n",
            "precision:     0.764\n",
            "recall:        0.765\n",
            "f1:            0.764\n",
            "===== Start training: epoch 16 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.59267067909241, Epoch: 16, training loss: 417.58328092098236, current learning rate 1e-05\n",
            "val loss: 35.72589027881622\n",
            "accuracy:      0.756\n",
            "precision:     0.758\n",
            "recall:        0.757\n",
            "f1:            0.756\n",
            "val loss: 34.19767755270004\n",
            "accuracy:      0.763\n",
            "precision:     0.764\n",
            "recall:        0.764\n",
            "f1:            0.763\n",
            "===== Start training: epoch 17 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.52698278427124, Epoch: 17, training loss: 406.86275708675385, current learning rate 1e-05\n",
            "val loss: 42.1263707280159\n",
            "accuracy:      0.759\n",
            "precision:     0.760\n",
            "recall:        0.759\n",
            "f1:            0.759\n",
            "val loss: 40.34744572639465\n",
            "accuracy:      0.762\n",
            "precision:     0.763\n",
            "recall:        0.763\n",
            "f1:            0.762\n",
            "===== Start training: epoch 18 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.51439356803894, Epoch: 18, training loss: 396.91197526454926, current learning rate 1e-05\n",
            "val loss: 43.892225563526154\n",
            "accuracy:      0.757\n",
            "precision:     0.758\n",
            "recall:        0.758\n",
            "f1:            0.757\n",
            "val loss: 42.1363088786602\n",
            "accuracy:      0.763\n",
            "precision:     0.763\n",
            "recall:        0.763\n",
            "f1:            0.763\n",
            "===== Start training: epoch 19 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.608644008636475, Epoch: 19, training loss: 390.1326709985733, current learning rate 1e-05\n",
            "val loss: 46.62251687049866\n",
            "accuracy:      0.762\n",
            "precision:     0.762\n",
            "recall:        0.762\n",
            "f1:            0.761\n",
            "val loss: 45.28393203020096\n",
            "accuracy:      0.761\n",
            "precision:     0.762\n",
            "recall:        0.762\n",
            "f1:            0.761\n",
            "===== Start training: epoch 20 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.584322929382324, Epoch: 20, training loss: 386.56783521175385, current learning rate 1e-05\n",
            "val loss: 44.749148935079575\n",
            "accuracy:      0.756\n",
            "precision:     0.759\n",
            "recall:        0.757\n",
            "f1:            0.756\n",
            "val loss: 45.24710848927498\n",
            "accuracy:      0.752\n",
            "precision:     0.754\n",
            "recall:        0.754\n",
            "f1:            0.752\n",
            "===== Start training: epoch 21 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.49628281593323, Epoch: 21, training loss: 377.90308606624603, current learning rate 1e-05\n",
            "val loss: 46.392323076725006\n",
            "accuracy:      0.755\n",
            "precision:     0.756\n",
            "recall:        0.755\n",
            "f1:            0.754\n",
            "val loss: 45.92004728317261\n",
            "accuracy:      0.755\n",
            "precision:     0.757\n",
            "recall:        0.757\n",
            "f1:            0.755\n",
            "===== Start training: epoch 22 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:53,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.42891001701355, Epoch: 22, training loss: 368.62976944446564, current learning rate 1e-05\n",
            "val loss: 46.78062093257904\n",
            "accuracy:      0.753\n",
            "precision:     0.757\n",
            "recall:        0.753\n",
            "f1:            0.752\n",
            "val loss: 45.67578774690628\n",
            "accuracy:      0.754\n",
            "precision:     0.757\n",
            "recall:        0.756\n",
            "f1:            0.754\n",
            "===== Start training: epoch 23 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:52,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.40089201927185, Epoch: 23, training loss: 359.63607013225555, current learning rate 1e-05\n",
            "val loss: 38.629136085510254\n",
            "accuracy:      0.754\n",
            "precision:     0.755\n",
            "recall:        0.754\n",
            "f1:            0.754\n",
            "val loss: 37.70195943117142\n",
            "accuracy:      0.755\n",
            "precision:     0.756\n",
            "recall:        0.756\n",
            "f1:            0.755\n",
            "===== Start training: epoch 24 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.47203350067139, Epoch: 24, training loss: 355.053062081337, current learning rate 1e-05\n",
            "val loss: 41.20994907617569\n",
            "accuracy:      0.757\n",
            "precision:     0.758\n",
            "recall:        0.757\n",
            "f1:            0.757\n",
            "val loss: 40.722437500953674\n",
            "accuracy:      0.760\n",
            "precision:     0.762\n",
            "recall:        0.762\n",
            "f1:            0.760\n",
            "===== Start training: epoch 25 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.55545425415039, Epoch: 25, training loss: 351.1856609582901, current learning rate 1e-05\n",
            "val loss: 34.50590378046036\n",
            "accuracy:      0.759\n",
            "precision:     0.760\n",
            "recall:        0.759\n",
            "f1:            0.759\n",
            "val loss: 34.1767058968544\n",
            "accuracy:      0.758\n",
            "precision:     0.759\n",
            "recall:        0.759\n",
            "f1:            0.758\n",
            "===== Start training: epoch 26 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.5746066570282, Epoch: 26, training loss: 359.9869477748871, current learning rate 1e-05\n",
            "val loss: 42.2105268239975\n",
            "accuracy:      0.759\n",
            "precision:     0.761\n",
            "recall:        0.759\n",
            "f1:            0.759\n",
            "val loss: 42.059221267700195\n",
            "accuracy:      0.756\n",
            "precision:     0.759\n",
            "recall:        0.758\n",
            "f1:            0.756\n",
            "===== Start training: epoch 27 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.52546453475952, Epoch: 27, training loss: 360.94418263435364, current learning rate 1e-05\n",
            "val loss: 40.40218299627304\n",
            "accuracy:      0.770\n",
            "precision:     0.770\n",
            "recall:        0.771\n",
            "f1:            0.770\n",
            "val loss: 41.139342963695526\n",
            "accuracy:      0.756\n",
            "precision:     0.756\n",
            "recall:        0.756\n",
            "f1:            0.756\n",
            "===== Start training: epoch 28 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:53,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.46143102645874, Epoch: 28, training loss: 358.7315813302994, current learning rate 1e-05\n",
            "val loss: 42.12876099348068\n",
            "accuracy:      0.774\n",
            "precision:     0.774\n",
            "recall:        0.775\n",
            "f1:            0.775\n",
            "val loss: 40.20694172382355\n",
            "accuracy:      0.772\n",
            "precision:     0.772\n",
            "recall:        0.772\n",
            "f1:            0.772\n",
            "===== Start training: epoch 29 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.514307260513306, Epoch: 29, training loss: 366.57688653469086, current learning rate 1e-05\n",
            "val loss: 35.99532163143158\n",
            "accuracy:      0.758\n",
            "precision:     0.758\n",
            "recall:        0.759\n",
            "f1:            0.758\n",
            "val loss: 33.97372841835022\n",
            "accuracy:      0.769\n",
            "precision:     0.768\n",
            "recall:        0.768\n",
            "f1:            0.768\n",
            "===== Start training: epoch 30 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:52,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.40933871269226, Epoch: 30, training loss: 364.7486324310303, current learning rate 1e-05\n",
            "val loss: 37.93311661481857\n",
            "accuracy:      0.762\n",
            "precision:     0.763\n",
            "recall:        0.763\n",
            "f1:            0.763\n",
            "val loss: 36.832941472530365\n",
            "accuracy:      0.767\n",
            "precision:     0.766\n",
            "recall:        0.767\n",
            "f1:            0.767\n",
            "best result:\n",
            "0.7719703977798335\n",
            "0.7716084162790537\n",
            "0.7719313812481514\n",
            "0.771710129655391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.7608695652173914, 0.7604402483364203, 0.7603766144138815, 0.7604069605306847], [0.759481961147086, 0.7612853679987988, 0.761056886522725, 0.7594768154340132], [0.7645698427382054, 0.7644954858169948, 0.7634131913635019, 0.7637286818992517], [0.7719703977798335, 0.7716084162790537, 0.7719313812481514, 0.771710129655391]]\n",
            "**** trying with seed 2 ****\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing...: 100%|| 6486/6486 [00:02<00:00, 3124.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished preprocessing examples in train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing...: 100%|| 2164/2164 [00:00<00:00, 3082.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished preprocessing examples in dev\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing...: 100%|| 2162/2162 [00:00<00:00, 2957.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished preprocessing examples in test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1491: FutureWarning: The repository for discovery contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/discovery\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Start training: epoch 1 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:53,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.45226693153381, Epoch: 1, training loss: 723.1144616603851, current learning rate 1e-05\n",
            "val loss: 23.43153029680252\n",
            "accuracy:      0.517\n",
            "precision:     0.540\n",
            "recall:        0.519\n",
            "f1:            0.446\n",
            "val loss: 23.426265835762024\n",
            "accuracy:      0.533\n",
            "precision:     0.536\n",
            "recall:        0.518\n",
            "f1:            0.458\n",
            "===== Start training: epoch 2 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:53,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.45590925216675, Epoch: 2, training loss: 980.6032948493958, current learning rate 1e-05\n",
            "val loss: 19.68999344110489\n",
            "accuracy:      0.695\n",
            "precision:     0.704\n",
            "recall:        0.695\n",
            "f1:            0.692\n",
            "val loss: 19.962743371725082\n",
            "accuracy:      0.676\n",
            "precision:     0.690\n",
            "recall:        0.681\n",
            "f1:            0.673\n",
            "===== Start training: epoch 3 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.4922981262207, Epoch: 3, training loss: 1016.289936542511, current learning rate 1e-05\n",
            "val loss: 19.49106377363205\n",
            "accuracy:      0.729\n",
            "precision:     0.745\n",
            "recall:        0.728\n",
            "f1:            0.724\n",
            "val loss: 19.90785801410675\n",
            "accuracy:      0.712\n",
            "precision:     0.733\n",
            "recall:        0.718\n",
            "f1:            0.708\n",
            "===== Start training: epoch 4 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.582791805267334, Epoch: 4, training loss: 960.7883770465851, current learning rate 1e-05\n",
            "val loss: 19.425093173980713\n",
            "accuracy:      0.741\n",
            "precision:     0.742\n",
            "recall:        0.741\n",
            "f1:            0.741\n",
            "val loss: 19.531935393810272\n",
            "accuracy:      0.724\n",
            "precision:     0.726\n",
            "recall:        0.726\n",
            "f1:            0.724\n",
            "===== Start training: epoch 5 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.54076170921326, Epoch: 5, training loss: 908.2974536418915, current learning rate 1e-05\n",
            "val loss: 20.62224844098091\n",
            "accuracy:      0.729\n",
            "precision:     0.733\n",
            "recall:        0.729\n",
            "f1:            0.728\n",
            "val loss: 20.327835500240326\n",
            "accuracy:      0.731\n",
            "precision:     0.732\n",
            "recall:        0.729\n",
            "f1:            0.729\n",
            "===== Start training: epoch 6 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:53,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.447041034698486, Epoch: 6, training loss: 845.6714596748352, current learning rate 1e-05\n",
            "val loss: 21.66748684644699\n",
            "accuracy:      0.749\n",
            "precision:     0.751\n",
            "recall:        0.749\n",
            "f1:            0.749\n",
            "val loss: 20.85141521692276\n",
            "accuracy:      0.747\n",
            "precision:     0.750\n",
            "recall:        0.749\n",
            "f1:            0.747\n",
            "===== Start training: epoch 7 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:53,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.43399262428284, Epoch: 7, training loss: 768.6342272758484, current learning rate 1e-05\n",
            "val loss: 23.380544662475586\n",
            "accuracy:      0.745\n",
            "precision:     0.745\n",
            "recall:        0.745\n",
            "f1:            0.745\n",
            "val loss: 23.30519476532936\n",
            "accuracy:      0.742\n",
            "precision:     0.742\n",
            "recall:        0.743\n",
            "f1:            0.742\n",
            "===== Start training: epoch 8 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.62172341346741, Epoch: 8, training loss: 704.3740491867065, current learning rate 1e-05\n",
            "val loss: 30.512280464172363\n",
            "accuracy:      0.752\n",
            "precision:     0.752\n",
            "recall:        0.752\n",
            "f1:            0.752\n",
            "val loss: 30.310295462608337\n",
            "accuracy:      0.755\n",
            "precision:     0.755\n",
            "recall:        0.756\n",
            "f1:            0.755\n",
            "===== Start training: epoch 9 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.56570911407471, Epoch: 9, training loss: 638.2518496513367, current learning rate 1e-05\n",
            "val loss: 32.648853063583374\n",
            "accuracy:      0.748\n",
            "precision:     0.748\n",
            "recall:        0.749\n",
            "f1:            0.748\n",
            "val loss: 32.61694806814194\n",
            "accuracy:      0.739\n",
            "precision:     0.739\n",
            "recall:        0.739\n",
            "f1:            0.739\n",
            "===== Start training: epoch 10 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.64691781997681, Epoch: 10, training loss: 575.6952698230743, current learning rate 1e-05\n",
            "val loss: 35.119977831840515\n",
            "accuracy:      0.760\n",
            "precision:     0.760\n",
            "recall:        0.761\n",
            "f1:            0.760\n",
            "val loss: 34.4806404709816\n",
            "accuracy:      0.758\n",
            "precision:     0.758\n",
            "recall:        0.758\n",
            "f1:            0.758\n",
            "===== Start training: epoch 11 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.62559151649475, Epoch: 11, training loss: 508.7538652420044, current learning rate 1e-05\n",
            "val loss: 34.26965069770813\n",
            "accuracy:      0.751\n",
            "precision:     0.756\n",
            "recall:        0.751\n",
            "f1:            0.750\n",
            "val loss: 34.43992477655411\n",
            "accuracy:      0.747\n",
            "precision:     0.756\n",
            "recall:        0.751\n",
            "f1:            0.747\n",
            "===== Start training: epoch 12 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.57737898826599, Epoch: 12, training loss: 445.08671247959137, current learning rate 1e-05\n",
            "val loss: 35.0702810883522\n",
            "accuracy:      0.755\n",
            "precision:     0.756\n",
            "recall:        0.755\n",
            "f1:            0.754\n",
            "val loss: 34.533514857292175\n",
            "accuracy:      0.753\n",
            "precision:     0.758\n",
            "recall:        0.756\n",
            "f1:            0.753\n",
            "===== Start training: epoch 13 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.57058024406433, Epoch: 13, training loss: 393.90957856178284, current learning rate 1e-05\n",
            "val loss: 29.954997897148132\n",
            "accuracy:      0.751\n",
            "precision:     0.754\n",
            "recall:        0.751\n",
            "f1:            0.751\n",
            "val loss: 30.03352963924408\n",
            "accuracy:      0.748\n",
            "precision:     0.753\n",
            "recall:        0.751\n",
            "f1:            0.748\n",
            "===== Start training: epoch 14 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.473817586898804, Epoch: 14, training loss: 367.03764164447784, current learning rate 1e-05\n",
            "val loss: 38.595010459423065\n",
            "accuracy:      0.760\n",
            "precision:     0.760\n",
            "recall:        0.760\n",
            "f1:            0.760\n",
            "val loss: 38.18238294124603\n",
            "accuracy:      0.757\n",
            "precision:     0.757\n",
            "recall:        0.757\n",
            "f1:            0.757\n",
            "===== Start training: epoch 15 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.55721426010132, Epoch: 15, training loss: 360.7500454187393, current learning rate 1e-05\n",
            "val loss: 41.617550015449524\n",
            "accuracy:      0.753\n",
            "precision:     0.754\n",
            "recall:        0.754\n",
            "f1:            0.753\n",
            "val loss: 41.34032815694809\n",
            "accuracy:      0.752\n",
            "precision:     0.751\n",
            "recall:        0.751\n",
            "f1:            0.751\n",
            "===== Start training: epoch 16 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.52171874046326, Epoch: 16, training loss: 351.3586235046387, current learning rate 1e-05\n",
            "val loss: 50.650167405605316\n",
            "accuracy:      0.762\n",
            "precision:     0.762\n",
            "recall:        0.762\n",
            "f1:            0.762\n",
            "val loss: 50.5934756398201\n",
            "accuracy:      0.758\n",
            "precision:     0.759\n",
            "recall:        0.759\n",
            "f1:            0.758\n",
            "===== Start training: epoch 17 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.47733449935913, Epoch: 17, training loss: 345.0229104757309, current learning rate 1e-05\n",
            "val loss: 48.04312074184418\n",
            "accuracy:      0.765\n",
            "precision:     0.765\n",
            "recall:        0.765\n",
            "f1:            0.765\n",
            "val loss: 49.0815372467041\n",
            "accuracy:      0.757\n",
            "precision:     0.759\n",
            "recall:        0.759\n",
            "f1:            0.757\n",
            "===== Start training: epoch 18 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.477282762527466, Epoch: 18, training loss: 362.92742908000946, current learning rate 1e-05\n",
            "val loss: 52.688533902168274\n",
            "accuracy:      0.757\n",
            "precision:     0.757\n",
            "recall:        0.757\n",
            "f1:            0.757\n",
            "val loss: 50.77815538644791\n",
            "accuracy:      0.752\n",
            "precision:     0.752\n",
            "recall:        0.752\n",
            "f1:            0.752\n",
            "===== Start training: epoch 19 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.52867031097412, Epoch: 19, training loss: 367.243399977684, current learning rate 1e-05\n",
            "val loss: 61.44211196899414\n",
            "accuracy:      0.755\n",
            "precision:     0.757\n",
            "recall:        0.755\n",
            "f1:            0.754\n",
            "val loss: 61.92078483104706\n",
            "accuracy:      0.745\n",
            "precision:     0.751\n",
            "recall:        0.748\n",
            "f1:            0.745\n",
            "===== Start training: epoch 20 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.53798246383667, Epoch: 20, training loss: 390.48461830616, current learning rate 1e-05\n",
            "val loss: 60.569376051425934\n",
            "accuracy:      0.750\n",
            "precision:     0.750\n",
            "recall:        0.751\n",
            "f1:            0.751\n",
            "val loss: 57.42693477869034\n",
            "accuracy:      0.753\n",
            "precision:     0.753\n",
            "recall:        0.754\n",
            "f1:            0.753\n",
            "===== Start training: epoch 21 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.54728436470032, Epoch: 21, training loss: 415.2327892780304, current learning rate 1e-05\n",
            "val loss: 65.35932910442352\n",
            "accuracy:      0.758\n",
            "precision:     0.764\n",
            "recall:        0.758\n",
            "f1:            0.757\n",
            "val loss: 69.15567195415497\n",
            "accuracy:      0.751\n",
            "precision:     0.763\n",
            "recall:        0.755\n",
            "f1:            0.750\n",
            "===== Start training: epoch 22 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.566463232040405, Epoch: 22, training loss: 401.2509434223175, current learning rate 1e-05\n",
            "val loss: 60.837488770484924\n",
            "accuracy:      0.750\n",
            "precision:     0.750\n",
            "recall:        0.750\n",
            "f1:            0.750\n",
            "val loss: 61.03949296474457\n",
            "accuracy:      0.749\n",
            "precision:     0.749\n",
            "recall:        0.749\n",
            "f1:            0.749\n",
            "===== Start training: epoch 23 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.63506317138672, Epoch: 23, training loss: 364.1362683773041, current learning rate 1e-05\n",
            "val loss: 62.33855438232422\n",
            "accuracy:      0.750\n",
            "precision:     0.752\n",
            "recall:        0.750\n",
            "f1:            0.749\n",
            "val loss: 65.07115435600281\n",
            "accuracy:      0.740\n",
            "precision:     0.743\n",
            "recall:        0.742\n",
            "f1:            0.740\n",
            "===== Start training: epoch 24 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.490641355514526, Epoch: 24, training loss: 346.7735129594803, current learning rate 1e-05\n",
            "val loss: 63.071951508522034\n",
            "accuracy:      0.750\n",
            "precision:     0.750\n",
            "recall:        0.750\n",
            "f1:            0.749\n",
            "val loss: 62.64676773548126\n",
            "accuracy:      0.744\n",
            "precision:     0.747\n",
            "recall:        0.746\n",
            "f1:            0.744\n",
            "===== Start training: epoch 25 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.51219701766968, Epoch: 25, training loss: 336.52222216129303, current learning rate 1e-05\n",
            "val loss: 70.7518869638443\n",
            "accuracy:      0.750\n",
            "precision:     0.751\n",
            "recall:        0.751\n",
            "f1:            0.750\n",
            "val loss: 71.82979321479797\n",
            "accuracy:      0.749\n",
            "precision:     0.751\n",
            "recall:        0.751\n",
            "f1:            0.749\n",
            "===== Start training: epoch 26 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.49013876914978, Epoch: 26, training loss: 323.4825506210327, current learning rate 1e-05\n",
            "val loss: 66.03355073928833\n",
            "accuracy:      0.755\n",
            "precision:     0.755\n",
            "recall:        0.756\n",
            "f1:            0.755\n",
            "val loss: 62.145106077194214\n",
            "accuracy:      0.745\n",
            "precision:     0.744\n",
            "recall:        0.744\n",
            "f1:            0.744\n",
            "===== Start training: epoch 27 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.49454975128174, Epoch: 27, training loss: 320.59063494205475, current learning rate 1e-05\n",
            "val loss: 80.49789929389954\n",
            "accuracy:      0.750\n",
            "precision:     0.751\n",
            "recall:        0.750\n",
            "f1:            0.749\n",
            "val loss: 79.70471000671387\n",
            "accuracy:      0.749\n",
            "precision:     0.751\n",
            "recall:        0.751\n",
            "f1:            0.749\n",
            "===== Start training: epoch 28 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.50009083747864, Epoch: 28, training loss: 318.0156384706497, current learning rate 1e-05\n",
            "val loss: 77.02517688274384\n",
            "accuracy:      0.746\n",
            "precision:     0.746\n",
            "recall:        0.747\n",
            "f1:            0.746\n",
            "val loss: 71.8615357875824\n",
            "accuracy:      0.739\n",
            "precision:     0.739\n",
            "recall:        0.739\n",
            "f1:            0.739\n",
            "===== Start training: epoch 29 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.535706996917725, Epoch: 29, training loss: 317.09832322597504, current learning rate 1e-05\n",
            "val loss: 61.580339550971985\n",
            "accuracy:      0.752\n",
            "precision:     0.752\n",
            "recall:        0.752\n",
            "f1:            0.752\n",
            "val loss: 59.21432065963745\n",
            "accuracy:      0.751\n",
            "precision:     0.751\n",
            "recall:        0.752\n",
            "f1:            0.751\n",
            "===== Start training: epoch 30 =====\n",
            "*** trying with discovery_weight = 0.4, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.53923940658569, Epoch: 30, training loss: 315.1682758331299, current learning rate 1e-05\n",
            "val loss: 69.18211448192596\n",
            "accuracy:      0.752\n",
            "precision:     0.756\n",
            "recall:        0.752\n",
            "f1:            0.751\n",
            "val loss: 72.67264592647552\n",
            "accuracy:      0.739\n",
            "precision:     0.749\n",
            "recall:        0.743\n",
            "f1:            0.738\n",
            "best result:\n",
            "0.7571692876965772\n",
            "0.7587490136882913\n",
            "0.7586414275855269\n",
            "0.7571679889196463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Start training: epoch 1 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.5846049785614, Epoch: 1, training loss: 745.6758553981781, current learning rate 1e-05\n",
            "val loss: 23.39602839946747\n",
            "accuracy:      0.604\n",
            "precision:     0.606\n",
            "recall:        0.603\n",
            "f1:            0.601\n",
            "val loss: 23.4333193898201\n",
            "accuracy:      0.562\n",
            "precision:     0.570\n",
            "recall:        0.567\n",
            "f1:            0.560\n",
            "===== Start training: epoch 2 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.62767434120178, Epoch: 2, training loss: 985.0405230522156, current learning rate 1e-05\n",
            "val loss: 19.117981255054474\n",
            "accuracy:      0.713\n",
            "precision:     0.720\n",
            "recall:        0.712\n",
            "f1:            0.710\n",
            "val loss: 19.61071425676346\n",
            "accuracy:      0.692\n",
            "precision:     0.699\n",
            "recall:        0.696\n",
            "f1:            0.692\n",
            "===== Start training: epoch 3 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<15:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.704472064971924, Epoch: 3, training loss: 1017.4648056030273, current learning rate 1e-05\n",
            "val loss: 19.171209752559662\n",
            "accuracy:      0.739\n",
            "precision:     0.750\n",
            "recall:        0.739\n",
            "f1:            0.736\n",
            "val loss: 19.61482399702072\n",
            "accuracy:      0.718\n",
            "precision:     0.729\n",
            "recall:        0.722\n",
            "f1:            0.717\n",
            "===== Start training: epoch 4 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.66987109184265, Epoch: 4, training loss: 983.6247086524963, current learning rate 1e-05\n",
            "val loss: 20.296704351902008\n",
            "accuracy:      0.755\n",
            "precision:     0.755\n",
            "recall:        0.755\n",
            "f1:            0.755\n",
            "val loss: 20.79804766178131\n",
            "accuracy:      0.733\n",
            "precision:     0.733\n",
            "recall:        0.733\n",
            "f1:            0.733\n",
            "===== Start training: epoch 5 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.682297229766846, Epoch: 5, training loss: 938.0372519493103, current learning rate 1e-05\n",
            "val loss: 20.243574619293213\n",
            "accuracy:      0.756\n",
            "precision:     0.757\n",
            "recall:        0.757\n",
            "f1:            0.757\n",
            "val loss: 20.665845811367035\n",
            "accuracy:      0.745\n",
            "precision:     0.744\n",
            "recall:        0.744\n",
            "f1:            0.744\n",
            "===== Start training: epoch 6 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.64846420288086, Epoch: 6, training loss: 876.5712282657623, current learning rate 1e-05\n",
            "val loss: 21.312838450074196\n",
            "accuracy:      0.755\n",
            "precision:     0.758\n",
            "recall:        0.755\n",
            "f1:            0.754\n",
            "val loss: 21.713946133852005\n",
            "accuracy:      0.741\n",
            "precision:     0.743\n",
            "recall:        0.742\n",
            "f1:            0.740\n",
            "===== Start training: epoch 7 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.65790915489197, Epoch: 7, training loss: 804.2242949008942, current learning rate 1e-05\n",
            "val loss: 23.647664487361908\n",
            "accuracy:      0.763\n",
            "precision:     0.763\n",
            "recall:        0.763\n",
            "f1:            0.763\n",
            "val loss: 23.858400106430054\n",
            "accuracy:      0.747\n",
            "precision:     0.747\n",
            "recall:        0.747\n",
            "f1:            0.747\n",
            "===== Start training: epoch 8 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.60695433616638, Epoch: 8, training loss: 721.084876537323, current learning rate 1e-05\n",
            "val loss: 30.583832383155823\n",
            "accuracy:      0.758\n",
            "precision:     0.758\n",
            "recall:        0.759\n",
            "f1:            0.758\n",
            "val loss: 31.288708716630936\n",
            "accuracy:      0.764\n",
            "precision:     0.764\n",
            "recall:        0.764\n",
            "f1:            0.764\n",
            "===== Start training: epoch 9 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.58468151092529, Epoch: 9, training loss: 650.5548386573792, current learning rate 1e-05\n",
            "val loss: 31.899199783802032\n",
            "accuracy:      0.756\n",
            "precision:     0.757\n",
            "recall:        0.757\n",
            "f1:            0.756\n",
            "val loss: 33.152389883995056\n",
            "accuracy:      0.751\n",
            "precision:     0.752\n",
            "recall:        0.752\n",
            "f1:            0.751\n",
            "===== Start training: epoch 10 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.68052959442139, Epoch: 10, training loss: 588.0866384506226, current learning rate 1e-05\n",
            "val loss: 32.839112401008606\n",
            "accuracy:      0.757\n",
            "precision:     0.758\n",
            "recall:        0.758\n",
            "f1:            0.757\n",
            "val loss: 33.900289714336395\n",
            "accuracy:      0.750\n",
            "precision:     0.750\n",
            "recall:        0.750\n",
            "f1:            0.750\n",
            "===== Start training: epoch 11 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.664698123931885, Epoch: 11, training loss: 521.5217685699463, current learning rate 1e-05\n",
            "val loss: 30.856267541646957\n",
            "accuracy:      0.752\n",
            "precision:     0.754\n",
            "recall:        0.752\n",
            "f1:            0.752\n",
            "val loss: 31.12409943342209\n",
            "accuracy:      0.746\n",
            "precision:     0.749\n",
            "recall:        0.748\n",
            "f1:            0.746\n",
            "===== Start training: epoch 12 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.52035117149353, Epoch: 12, training loss: 465.64895951747894, current learning rate 1e-05\n",
            "val loss: 37.30590897798538\n",
            "accuracy:      0.758\n",
            "precision:     0.759\n",
            "recall:        0.759\n",
            "f1:            0.758\n",
            "val loss: 38.173861145973206\n",
            "accuracy:      0.747\n",
            "precision:     0.747\n",
            "recall:        0.747\n",
            "f1:            0.747\n",
            "===== Start training: epoch 13 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.55959677696228, Epoch: 13, training loss: 415.83609199523926, current learning rate 1e-05\n",
            "val loss: 36.159988939762115\n",
            "accuracy:      0.760\n",
            "precision:     0.764\n",
            "recall:        0.760\n",
            "f1:            0.759\n",
            "val loss: 39.690974205732346\n",
            "accuracy:      0.742\n",
            "precision:     0.747\n",
            "recall:        0.745\n",
            "f1:            0.742\n",
            "===== Start training: epoch 14 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.552778482437134, Epoch: 14, training loss: 381.202236533165, current learning rate 1e-05\n",
            "val loss: 39.15243625640869\n",
            "accuracy:      0.752\n",
            "precision:     0.758\n",
            "recall:        0.752\n",
            "f1:            0.750\n",
            "val loss: 41.5619056224823\n",
            "accuracy:      0.739\n",
            "precision:     0.747\n",
            "recall:        0.743\n",
            "f1:            0.739\n",
            "===== Start training: epoch 15 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.54235243797302, Epoch: 15, training loss: 378.2116963863373, current learning rate 1e-05\n",
            "val loss: 40.5145189166069\n",
            "accuracy:      0.751\n",
            "precision:     0.758\n",
            "recall:        0.752\n",
            "f1:            0.750\n",
            "val loss: 40.6754384636879\n",
            "accuracy:      0.753\n",
            "precision:     0.758\n",
            "recall:        0.750\n",
            "f1:            0.750\n",
            "===== Start training: epoch 16 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.54120063781738, Epoch: 16, training loss: 359.0336960554123, current learning rate 1e-05\n",
            "val loss: 37.955035507678986\n",
            "accuracy:      0.768\n",
            "precision:     0.769\n",
            "recall:        0.768\n",
            "f1:            0.767\n",
            "val loss: 40.54343235492706\n",
            "accuracy:      0.747\n",
            "precision:     0.750\n",
            "recall:        0.749\n",
            "f1:            0.747\n",
            "===== Start training: epoch 17 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.54241991043091, Epoch: 17, training loss: 344.66686618328094, current learning rate 1e-05\n",
            "val loss: 38.969040274620056\n",
            "accuracy:      0.765\n",
            "precision:     0.765\n",
            "recall:        0.765\n",
            "f1:            0.765\n",
            "val loss: 40.51101487874985\n",
            "accuracy:      0.753\n",
            "precision:     0.752\n",
            "recall:        0.753\n",
            "f1:            0.752\n",
            "===== Start training: epoch 18 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.53993272781372, Epoch: 18, training loss: 338.5660058259964, current learning rate 1e-05\n",
            "val loss: 44.3079269528389\n",
            "accuracy:      0.769\n",
            "precision:     0.774\n",
            "recall:        0.769\n",
            "f1:            0.768\n",
            "val loss: 48.19252812862396\n",
            "accuracy:      0.744\n",
            "precision:     0.751\n",
            "recall:        0.747\n",
            "f1:            0.744\n",
            "===== Start training: epoch 19 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.58129024505615, Epoch: 19, training loss: 343.4204765558243, current learning rate 1e-05\n",
            "val loss: 43.2140976190567\n",
            "accuracy:      0.760\n",
            "precision:     0.760\n",
            "recall:        0.760\n",
            "f1:            0.760\n",
            "val loss: 44.50768458843231\n",
            "accuracy:      0.745\n",
            "precision:     0.745\n",
            "recall:        0.744\n",
            "f1:            0.744\n",
            "===== Start training: epoch 20 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.5781466960907, Epoch: 20, training loss: 342.3836201429367, current learning rate 1e-05\n",
            "val loss: 58.62011784315109\n",
            "accuracy:      0.756\n",
            "precision:     0.756\n",
            "recall:        0.757\n",
            "f1:            0.757\n",
            "val loss: 59.82228875160217\n",
            "accuracy:      0.744\n",
            "precision:     0.744\n",
            "recall:        0.744\n",
            "f1:            0.744\n",
            "===== Start training: epoch 21 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.50552010536194, Epoch: 21, training loss: 345.23149251937866, current learning rate 1e-05\n",
            "val loss: 55.78522968292236\n",
            "accuracy:      0.774\n",
            "precision:     0.775\n",
            "recall:        0.774\n",
            "f1:            0.774\n",
            "val loss: 58.82238733768463\n",
            "accuracy:      0.746\n",
            "precision:     0.746\n",
            "recall:        0.747\n",
            "f1:            0.746\n",
            "===== Start training: epoch 22 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.495704650878906, Epoch: 22, training loss: 359.29779171943665, current learning rate 1e-05\n",
            "val loss: 55.01399791240692\n",
            "accuracy:      0.760\n",
            "precision:     0.760\n",
            "recall:        0.760\n",
            "f1:            0.760\n",
            "val loss: 56.268001556396484\n",
            "accuracy:      0.754\n",
            "precision:     0.754\n",
            "recall:        0.752\n",
            "f1:            0.753\n",
            "===== Start training: epoch 23 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.59161639213562, Epoch: 23, training loss: 376.4508892297745, current learning rate 1e-05\n",
            "val loss: 52.2637796998024\n",
            "accuracy:      0.767\n",
            "precision:     0.769\n",
            "recall:        0.767\n",
            "f1:            0.766\n",
            "val loss: 54.476704359054565\n",
            "accuracy:      0.748\n",
            "precision:     0.750\n",
            "recall:        0.750\n",
            "f1:            0.748\n",
            "===== Start training: epoch 24 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.58967447280884, Epoch: 24, training loss: 373.6571537256241, current learning rate 1e-05\n",
            "val loss: 56.71202754974365\n",
            "accuracy:      0.767\n",
            "precision:     0.769\n",
            "recall:        0.767\n",
            "f1:            0.766\n",
            "val loss: 58.203116059303284\n",
            "accuracy:      0.756\n",
            "precision:     0.758\n",
            "recall:        0.758\n",
            "f1:            0.756\n",
            "===== Start training: epoch 25 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.582351207733154, Epoch: 25, training loss: 381.0236862897873, current learning rate 1e-05\n",
            "val loss: 59.80287754535675\n",
            "accuracy:      0.771\n",
            "precision:     0.772\n",
            "recall:        0.772\n",
            "f1:            0.771\n",
            "val loss: 60.913376450538635\n",
            "accuracy:      0.757\n",
            "precision:     0.757\n",
            "recall:        0.756\n",
            "f1:            0.756\n",
            "===== Start training: epoch 26 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.541598320007324, Epoch: 26, training loss: 402.4168554544449, current learning rate 1e-05\n",
            "val loss: 48.80085128545761\n",
            "accuracy:      0.757\n",
            "precision:     0.758\n",
            "recall:        0.758\n",
            "f1:            0.757\n",
            "val loss: 50.693869948387146\n",
            "accuracy:      0.750\n",
            "precision:     0.750\n",
            "recall:        0.751\n",
            "f1:            0.750\n",
            "===== Start training: epoch 27 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.58156967163086, Epoch: 27, training loss: 414.2177355289459, current learning rate 1e-05\n",
            "val loss: 60.77896320819855\n",
            "accuracy:      0.760\n",
            "precision:     0.762\n",
            "recall:        0.760\n",
            "f1:            0.760\n",
            "val loss: 61.96638739109039\n",
            "accuracy:      0.746\n",
            "precision:     0.747\n",
            "recall:        0.747\n",
            "f1:            0.746\n",
            "===== Start training: epoch 28 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.542906045913696, Epoch: 28, training loss: 392.68401062488556, current learning rate 1e-05\n",
            "val loss: 64.7345050573349\n",
            "accuracy:      0.756\n",
            "precision:     0.759\n",
            "recall:        0.756\n",
            "f1:            0.755\n",
            "val loss: 67.86134707927704\n",
            "accuracy:      0.748\n",
            "precision:     0.751\n",
            "recall:        0.750\n",
            "f1:            0.748\n",
            "===== Start training: epoch 29 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.52761483192444, Epoch: 29, training loss: 381.28628838062286, current learning rate 1e-05\n",
            "val loss: 54.628896594047546\n",
            "accuracy:      0.759\n",
            "precision:     0.759\n",
            "recall:        0.759\n",
            "f1:            0.759\n",
            "val loss: 56.52535080909729\n",
            "accuracy:      0.746\n",
            "precision:     0.746\n",
            "recall:        0.745\n",
            "f1:            0.745\n",
            "===== Start training: epoch 30 =====\n",
            "*** trying with discovery_weight = 0.6000000000000001, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.58952569961548, Epoch: 30, training loss: 360.41795325279236, current learning rate 1e-05\n",
            "val loss: 82.63597333431244\n",
            "accuracy:      0.762\n",
            "precision:     0.767\n",
            "recall:        0.762\n",
            "f1:            0.762\n",
            "val loss: 84.5760428905487\n",
            "accuracy:      0.748\n",
            "precision:     0.752\n",
            "recall:        0.750\n",
            "f1:            0.748\n",
            "best result:\n",
            "0.7460684551341351\n",
            "0.7464640083816098\n",
            "0.7468500443655723\n",
            "0.7460227590045199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Start training: epoch 1 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.58169484138489, Epoch: 1, training loss: 776.9551615715027, current learning rate 1e-05\n",
            "val loss: 23.27283775806427\n",
            "accuracy:      0.609\n",
            "precision:     0.613\n",
            "recall:        0.609\n",
            "f1:            0.605\n",
            "val loss: 23.29669064283371\n",
            "accuracy:      0.608\n",
            "precision:     0.621\n",
            "recall:        0.613\n",
            "f1:            0.603\n",
            "===== Start training: epoch 2 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.63593816757202, Epoch: 2, training loss: 981.4992480278015, current learning rate 1e-05\n",
            "val loss: 19.548210561275482\n",
            "accuracy:      0.695\n",
            "precision:     0.700\n",
            "recall:        0.695\n",
            "f1:            0.693\n",
            "val loss: 19.67784383893013\n",
            "accuracy:      0.690\n",
            "precision:     0.696\n",
            "recall:        0.693\n",
            "f1:            0.689\n",
            "===== Start training: epoch 3 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<15:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.72159123420715, Epoch: 3, training loss: 1010.9114928245544, current learning rate 1e-05\n",
            "val loss: 19.789527356624603\n",
            "accuracy:      0.729\n",
            "precision:     0.737\n",
            "recall:        0.729\n",
            "f1:            0.727\n",
            "val loss: 19.532495617866516\n",
            "accuracy:      0.724\n",
            "precision:     0.734\n",
            "recall:        0.728\n",
            "f1:            0.723\n",
            "===== Start training: epoch 4 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<15:01,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.73681139945984, Epoch: 4, training loss: 989.4476599693298, current learning rate 1e-05\n",
            "val loss: 20.183599889278412\n",
            "accuracy:      0.747\n",
            "precision:     0.747\n",
            "recall:        0.747\n",
            "f1:            0.747\n",
            "val loss: 20.078083336353302\n",
            "accuracy:      0.737\n",
            "precision:     0.737\n",
            "recall:        0.737\n",
            "f1:            0.737\n",
            "===== Start training: epoch 5 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<15:00,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.69969081878662, Epoch: 5, training loss: 964.7888898849487, current learning rate 1e-05\n",
            "val loss: 19.030315458774567\n",
            "accuracy:      0.755\n",
            "precision:     0.759\n",
            "recall:        0.755\n",
            "f1:            0.754\n",
            "val loss: 19.40459167957306\n",
            "accuracy:      0.735\n",
            "precision:     0.741\n",
            "recall:        0.738\n",
            "f1:            0.735\n",
            "===== Start training: epoch 6 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.69162034988403, Epoch: 6, training loss: 913.4136323928833, current learning rate 1e-05\n",
            "val loss: 20.643157571554184\n",
            "accuracy:      0.760\n",
            "precision:     0.762\n",
            "recall:        0.760\n",
            "f1:            0.759\n",
            "val loss: 20.536016702651978\n",
            "accuracy:      0.741\n",
            "precision:     0.745\n",
            "recall:        0.743\n",
            "f1:            0.740\n",
            "===== Start training: epoch 7 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.59757852554321, Epoch: 7, training loss: 847.3762743473053, current learning rate 1e-05\n",
            "val loss: 22.779261469841003\n",
            "accuracy:      0.753\n",
            "precision:     0.754\n",
            "recall:        0.753\n",
            "f1:            0.753\n",
            "val loss: 22.25959664583206\n",
            "accuracy:      0.746\n",
            "precision:     0.747\n",
            "recall:        0.747\n",
            "f1:            0.746\n",
            "===== Start training: epoch 8 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.611034631729126, Epoch: 8, training loss: 762.1324162483215, current learning rate 1e-05\n",
            "val loss: 28.55449253320694\n",
            "accuracy:      0.767\n",
            "precision:     0.767\n",
            "recall:        0.767\n",
            "f1:            0.767\n",
            "val loss: 28.146027147769928\n",
            "accuracy:      0.755\n",
            "precision:     0.756\n",
            "recall:        0.756\n",
            "f1:            0.755\n",
            "===== Start training: epoch 9 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.60307312011719, Epoch: 9, training loss: 685.8607938289642, current learning rate 1e-05\n",
            "val loss: 29.965814739465714\n",
            "accuracy:      0.751\n",
            "precision:     0.753\n",
            "recall:        0.752\n",
            "f1:            0.751\n",
            "val loss: 29.269800543785095\n",
            "accuracy:      0.752\n",
            "precision:     0.752\n",
            "recall:        0.750\n",
            "f1:            0.751\n",
            "===== Start training: epoch 10 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.6269314289093, Epoch: 10, training loss: 617.3899350166321, current learning rate 1e-05\n",
            "val loss: 29.09792497754097\n",
            "accuracy:      0.764\n",
            "precision:     0.765\n",
            "recall:        0.765\n",
            "f1:            0.764\n",
            "val loss: 29.830738455057144\n",
            "accuracy:      0.750\n",
            "precision:     0.751\n",
            "recall:        0.751\n",
            "f1:            0.750\n",
            "===== Start training: epoch 11 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.58712029457092, Epoch: 11, training loss: 564.1342163085938, current learning rate 1e-05\n",
            "val loss: 30.99210387468338\n",
            "accuracy:      0.762\n",
            "precision:     0.762\n",
            "recall:        0.762\n",
            "f1:            0.762\n",
            "val loss: 31.22626042366028\n",
            "accuracy:      0.755\n",
            "precision:     0.755\n",
            "recall:        0.756\n",
            "f1:            0.755\n",
            "===== Start training: epoch 12 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.6434121131897, Epoch: 12, training loss: 508.6970615386963, current learning rate 1e-05\n",
            "val loss: 31.83509075641632\n",
            "accuracy:      0.757\n",
            "precision:     0.758\n",
            "recall:        0.757\n",
            "f1:            0.757\n",
            "val loss: 32.98519027233124\n",
            "accuracy:      0.747\n",
            "precision:     0.749\n",
            "recall:        0.749\n",
            "f1:            0.747\n",
            "===== Start training: epoch 13 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.600069522857666, Epoch: 13, training loss: 470.1034218072891, current learning rate 1e-05\n",
            "val loss: 31.732024013996124\n",
            "accuracy:      0.763\n",
            "precision:     0.766\n",
            "recall:        0.763\n",
            "f1:            0.762\n",
            "val loss: 34.225687474012375\n",
            "accuracy:      0.748\n",
            "precision:     0.753\n",
            "recall:        0.751\n",
            "f1:            0.748\n",
            "===== Start training: epoch 14 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.57576036453247, Epoch: 14, training loss: 436.12249505519867, current learning rate 1e-05\n",
            "val loss: 39.909330666065216\n",
            "accuracy:      0.756\n",
            "precision:     0.758\n",
            "recall:        0.756\n",
            "f1:            0.756\n",
            "val loss: 39.96632182598114\n",
            "accuracy:      0.755\n",
            "precision:     0.758\n",
            "recall:        0.757\n",
            "f1:            0.755\n",
            "===== Start training: epoch 15 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.57497429847717, Epoch: 15, training loss: 415.3737713098526, current learning rate 1e-05\n",
            "val loss: 40.354135036468506\n",
            "accuracy:      0.753\n",
            "precision:     0.754\n",
            "recall:        0.754\n",
            "f1:            0.753\n",
            "val loss: 40.1488521695137\n",
            "accuracy:      0.761\n",
            "precision:     0.761\n",
            "recall:        0.760\n",
            "f1:            0.760\n",
            "===== Start training: epoch 16 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.50029635429382, Epoch: 16, training loss: 393.7576028108597, current learning rate 1e-05\n",
            "val loss: 39.664475321769714\n",
            "accuracy:      0.772\n",
            "precision:     0.773\n",
            "recall:        0.772\n",
            "f1:            0.772\n",
            "val loss: 40.964826822280884\n",
            "accuracy:      0.763\n",
            "precision:     0.764\n",
            "recall:        0.764\n",
            "f1:            0.763\n",
            "===== Start training: epoch 17 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:52,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.4033887386322, Epoch: 17, training loss: 377.3322925567627, current learning rate 1e-05\n",
            "val loss: 41.80260193347931\n",
            "accuracy:      0.781\n",
            "precision:     0.782\n",
            "recall:        0.782\n",
            "f1:            0.781\n",
            "val loss: 44.65494638681412\n",
            "accuracy:      0.756\n",
            "precision:     0.758\n",
            "recall:        0.758\n",
            "f1:            0.756\n",
            "===== Start training: epoch 18 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:52,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.422611474990845, Epoch: 18, training loss: 357.48032307624817, current learning rate 1e-05\n",
            "val loss: 41.54589915275574\n",
            "accuracy:      0.761\n",
            "precision:     0.765\n",
            "recall:        0.761\n",
            "f1:            0.760\n",
            "val loss: 42.241420209407806\n",
            "accuracy:      0.751\n",
            "precision:     0.755\n",
            "recall:        0.753\n",
            "f1:            0.751\n",
            "===== Start training: epoch 19 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:53,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.42708897590637, Epoch: 19, training loss: 354.85506641864777, current learning rate 1e-05\n",
            "val loss: 37.29274374246597\n",
            "accuracy:      0.761\n",
            "precision:     0.761\n",
            "recall:        0.761\n",
            "f1:            0.761\n",
            "val loss: 37.16743981838226\n",
            "accuracy:      0.753\n",
            "precision:     0.752\n",
            "recall:        0.753\n",
            "f1:            0.752\n",
            "===== Start training: epoch 20 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:53,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.42570781707764, Epoch: 20, training loss: 346.72759318351746, current learning rate 1e-05\n",
            "val loss: 43.395164132118225\n",
            "accuracy:      0.766\n",
            "precision:     0.766\n",
            "recall:        0.767\n",
            "f1:            0.766\n",
            "val loss: 44.212180614471436\n",
            "accuracy:      0.753\n",
            "precision:     0.752\n",
            "recall:        0.753\n",
            "f1:            0.752\n",
            "===== Start training: epoch 21 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:52,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.400700092315674, Epoch: 21, training loss: 334.65778827667236, current learning rate 1e-05\n",
            "val loss: 53.66778516769409\n",
            "accuracy:      0.760\n",
            "precision:     0.772\n",
            "recall:        0.759\n",
            "f1:            0.757\n",
            "val loss: 57.35310173034668\n",
            "accuracy:      0.744\n",
            "precision:     0.759\n",
            "recall:        0.749\n",
            "f1:            0.743\n",
            "===== Start training: epoch 22 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:51,  5.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.36580491065979, Epoch: 22, training loss: 334.57115495204926, current learning rate 1e-05\n",
            "val loss: 45.61753636598587\n",
            "accuracy:      0.772\n",
            "precision:     0.772\n",
            "recall:        0.773\n",
            "f1:            0.772\n",
            "val loss: 47.277304887771606\n",
            "accuracy:      0.757\n",
            "precision:     0.757\n",
            "recall:        0.757\n",
            "f1:            0.757\n",
            "===== Start training: epoch 23 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:52,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.393845558166504, Epoch: 23, training loss: 333.21394753456116, current learning rate 1e-05\n",
            "val loss: 50.298639476299286\n",
            "accuracy:      0.763\n",
            "precision:     0.766\n",
            "recall:        0.763\n",
            "f1:            0.763\n",
            "val loss: 51.40104657411575\n",
            "accuracy:      0.751\n",
            "precision:     0.754\n",
            "recall:        0.753\n",
            "f1:            0.751\n",
            "===== Start training: epoch 24 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:52,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.41515016555786, Epoch: 24, training loss: 325.81412649154663, current learning rate 1e-05\n",
            "val loss: 50.23270732164383\n",
            "accuracy:      0.761\n",
            "precision:     0.766\n",
            "recall:        0.761\n",
            "f1:            0.760\n",
            "val loss: 51.73282665014267\n",
            "accuracy:      0.751\n",
            "precision:     0.758\n",
            "recall:        0.754\n",
            "f1:            0.751\n",
            "===== Start training: epoch 25 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.46918535232544, Epoch: 25, training loss: 323.4536807537079, current learning rate 1e-05\n",
            "val loss: 51.77542692422867\n",
            "accuracy:      0.772\n",
            "precision:     0.773\n",
            "recall:        0.772\n",
            "f1:            0.772\n",
            "val loss: 53.767977356910706\n",
            "accuracy:      0.754\n",
            "precision:     0.756\n",
            "recall:        0.756\n",
            "f1:            0.754\n",
            "===== Start training: epoch 26 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.513314962387085, Epoch: 26, training loss: 317.16034412384033, current learning rate 1e-05\n",
            "val loss: 50.107664465904236\n",
            "accuracy:      0.745\n",
            "precision:     0.745\n",
            "recall:        0.746\n",
            "f1:            0.746\n",
            "val loss: 50.49868094921112\n",
            "accuracy:      0.755\n",
            "precision:     0.755\n",
            "recall:        0.755\n",
            "f1:            0.755\n",
            "===== Start training: epoch 27 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.54192519187927, Epoch: 27, training loss: 312.75253760814667, current learning rate 1e-05\n",
            "val loss: 54.057975232601166\n",
            "accuracy:      0.766\n",
            "precision:     0.766\n",
            "recall:        0.766\n",
            "f1:            0.766\n",
            "val loss: 54.615280747413635\n",
            "accuracy:      0.760\n",
            "precision:     0.760\n",
            "recall:        0.760\n",
            "f1:            0.760\n",
            "===== Start training: epoch 28 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:53,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.44005608558655, Epoch: 28, training loss: 309.3173403739929, current learning rate 1e-05\n",
            "val loss: 55.42140477895737\n",
            "accuracy:      0.766\n",
            "precision:     0.770\n",
            "recall:        0.766\n",
            "f1:            0.765\n",
            "val loss: 56.883325815200806\n",
            "accuracy:      0.753\n",
            "precision:     0.756\n",
            "recall:        0.755\n",
            "f1:            0.752\n",
            "===== Start training: epoch 29 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.48869180679321, Epoch: 29, training loss: 309.7609544992447, current learning rate 1e-05\n",
            "val loss: 51.87077462673187\n",
            "accuracy:      0.771\n",
            "precision:     0.772\n",
            "recall:        0.771\n",
            "f1:            0.771\n",
            "val loss: 54.74948972463608\n",
            "accuracy:      0.751\n",
            "precision:     0.752\n",
            "recall:        0.752\n",
            "f1:            0.751\n",
            "===== Start training: epoch 30 =====\n",
            "*** trying with discovery_weight = 0.8000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:52,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.42312955856323, Epoch: 30, training loss: 306.4924006462097, current learning rate 1e-05\n",
            "val loss: 54.7752240896225\n",
            "accuracy:      0.765\n",
            "precision:     0.772\n",
            "recall:        0.765\n",
            "f1:            0.764\n",
            "val loss: 59.41555881500244\n",
            "accuracy:      0.749\n",
            "precision:     0.757\n",
            "recall:        0.753\n",
            "f1:            0.749\n",
            "best result:\n",
            "0.7562442183163737\n",
            "0.7578218806820132\n",
            "0.7577146800749285\n",
            "0.7562429145917211\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Start training: epoch 1 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.52583289146423, Epoch: 1, training loss: 806.9848856925964, current learning rate 1e-05\n",
            "val loss: 23.363463819026947\n",
            "accuracy:      0.581\n",
            "precision:     0.582\n",
            "recall:        0.581\n",
            "f1:            0.580\n",
            "val loss: 23.413636445999146\n",
            "accuracy:      0.553\n",
            "precision:     0.557\n",
            "recall:        0.556\n",
            "f1:            0.552\n",
            "===== Start training: epoch 2 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.551971197128296, Epoch: 2, training loss: 984.9677476882935, current learning rate 1e-05\n",
            "val loss: 19.70379811525345\n",
            "accuracy:      0.695\n",
            "precision:     0.711\n",
            "recall:        0.694\n",
            "f1:            0.688\n",
            "val loss: 20.208464920520782\n",
            "accuracy:      0.679\n",
            "precision:     0.700\n",
            "recall:        0.685\n",
            "f1:            0.675\n",
            "===== Start training: epoch 3 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.58060646057129, Epoch: 3, training loss: 1024.1378173828125, current learning rate 1e-05\n",
            "val loss: 18.917897582054138\n",
            "accuracy:      0.731\n",
            "precision:     0.746\n",
            "recall:        0.731\n",
            "f1:            0.727\n",
            "val loss: 19.295509040355682\n",
            "accuracy:      0.721\n",
            "precision:     0.739\n",
            "recall:        0.726\n",
            "f1:            0.719\n",
            "===== Start training: epoch 4 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.59348106384277, Epoch: 4, training loss: 1011.7829337120056, current learning rate 1e-05\n",
            "val loss: 19.363670885562897\n",
            "accuracy:      0.749\n",
            "precision:     0.751\n",
            "recall:        0.749\n",
            "f1:            0.748\n",
            "val loss: 19.734048187732697\n",
            "accuracy:      0.733\n",
            "precision:     0.736\n",
            "recall:        0.735\n",
            "f1:            0.733\n",
            "===== Start training: epoch 5 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.5975444316864, Epoch: 5, training loss: 976.0372748374939, current learning rate 1e-05\n",
            "val loss: 18.875591158866882\n",
            "accuracy:      0.744\n",
            "precision:     0.744\n",
            "recall:        0.745\n",
            "f1:            0.745\n",
            "val loss: 19.218562841415405\n",
            "accuracy:      0.738\n",
            "precision:     0.737\n",
            "recall:        0.737\n",
            "f1:            0.737\n",
            "===== Start training: epoch 6 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:59,  5.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.67339515686035, Epoch: 6, training loss: 924.4159553050995, current learning rate 1e-05\n",
            "val loss: 20.523599684238434\n",
            "accuracy:      0.758\n",
            "precision:     0.761\n",
            "recall:        0.758\n",
            "f1:            0.757\n",
            "val loss: 21.441590309143066\n",
            "accuracy:      0.743\n",
            "precision:     0.747\n",
            "recall:        0.745\n",
            "f1:            0.743\n",
            "===== Start training: epoch 7 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:57,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.60766530036926, Epoch: 7, training loss: 856.9075198173523, current learning rate 1e-05\n",
            "val loss: 20.111783266067505\n",
            "accuracy:      0.751\n",
            "precision:     0.751\n",
            "recall:        0.751\n",
            "f1:            0.751\n",
            "val loss: 20.468111366033554\n",
            "accuracy:      0.745\n",
            "precision:     0.745\n",
            "recall:        0.746\n",
            "f1:            0.745\n",
            "===== Start training: epoch 8 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.56163454055786, Epoch: 8, training loss: 786.2003753185272, current learning rate 1e-05\n",
            "val loss: 24.722757399082184\n",
            "accuracy:      0.767\n",
            "precision:     0.767\n",
            "recall:        0.767\n",
            "f1:            0.767\n",
            "val loss: 24.689374685287476\n",
            "accuracy:      0.760\n",
            "precision:     0.760\n",
            "recall:        0.761\n",
            "f1:            0.760\n",
            "===== Start training: epoch 9 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.56877541542053, Epoch: 9, training loss: 711.1799986362457, current learning rate 1e-05\n",
            "val loss: 26.955925434827805\n",
            "accuracy:      0.750\n",
            "precision:     0.751\n",
            "recall:        0.750\n",
            "f1:            0.750\n",
            "val loss: 26.859581351280212\n",
            "accuracy:      0.755\n",
            "precision:     0.756\n",
            "recall:        0.754\n",
            "f1:            0.754\n",
            "===== Start training: epoch 10 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.570103883743286, Epoch: 10, training loss: 641.4690961837769, current learning rate 1e-05\n",
            "val loss: 28.953776955604553\n",
            "accuracy:      0.763\n",
            "precision:     0.763\n",
            "recall:        0.764\n",
            "f1:            0.764\n",
            "val loss: 29.166455179452896\n",
            "accuracy:      0.750\n",
            "precision:     0.750\n",
            "recall:        0.750\n",
            "f1:            0.750\n",
            "===== Start training: epoch 11 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.51372814178467, Epoch: 11, training loss: 589.4551401138306, current learning rate 1e-05\n",
            "val loss: 29.516445070505142\n",
            "accuracy:      0.753\n",
            "precision:     0.756\n",
            "recall:        0.753\n",
            "f1:            0.753\n",
            "val loss: 29.256931722164154\n",
            "accuracy:      0.754\n",
            "precision:     0.758\n",
            "recall:        0.757\n",
            "f1:            0.754\n",
            "===== Start training: epoch 12 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.55319118499756, Epoch: 12, training loss: 533.6349632740021, current learning rate 1e-05\n",
            "val loss: 33.46657782793045\n",
            "accuracy:      0.762\n",
            "precision:     0.763\n",
            "recall:        0.762\n",
            "f1:            0.761\n",
            "val loss: 33.78527891635895\n",
            "accuracy:      0.754\n",
            "precision:     0.755\n",
            "recall:        0.755\n",
            "f1:            0.754\n",
            "===== Start training: epoch 13 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.55090069770813, Epoch: 13, training loss: 502.6188452243805, current learning rate 1e-05\n",
            "val loss: 34.785595297813416\n",
            "accuracy:      0.762\n",
            "precision:     0.774\n",
            "recall:        0.761\n",
            "f1:            0.759\n",
            "val loss: 37.449611842632294\n",
            "accuracy:      0.736\n",
            "precision:     0.750\n",
            "recall:        0.741\n",
            "f1:            0.735\n",
            "===== Start training: epoch 14 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:53,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.43342137336731, Epoch: 14, training loss: 473.3060041666031, current learning rate 1e-05\n",
            "val loss: 36.73263669013977\n",
            "accuracy:      0.764\n",
            "precision:     0.765\n",
            "recall:        0.765\n",
            "f1:            0.764\n",
            "val loss: 37.3768065571785\n",
            "accuracy:      0.759\n",
            "precision:     0.759\n",
            "recall:        0.760\n",
            "f1:            0.759\n",
            "===== Start training: epoch 15 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:58,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.625982999801636, Epoch: 15, training loss: 451.92617678642273, current learning rate 1e-05\n",
            "val loss: 39.20532160997391\n",
            "accuracy:      0.762\n",
            "precision:     0.762\n",
            "recall:        0.762\n",
            "f1:            0.762\n",
            "val loss: 38.945604741573334\n",
            "accuracy:      0.758\n",
            "precision:     0.758\n",
            "recall:        0.758\n",
            "f1:            0.758\n",
            "===== Start training: epoch 16 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.57334518432617, Epoch: 16, training loss: 430.03714776039124, current learning rate 1e-05\n",
            "val loss: 37.523957550525665\n",
            "accuracy:      0.771\n",
            "precision:     0.772\n",
            "recall:        0.771\n",
            "f1:            0.771\n",
            "val loss: 38.48769557476044\n",
            "accuracy:      0.756\n",
            "precision:     0.757\n",
            "recall:        0.758\n",
            "f1:            0.756\n",
            "===== Start training: epoch 17 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.56658983230591, Epoch: 17, training loss: 425.41096663475037, current learning rate 1e-05\n",
            "val loss: 40.81888508796692\n",
            "accuracy:      0.762\n",
            "precision:     0.762\n",
            "recall:        0.763\n",
            "f1:            0.763\n",
            "val loss: 40.9998260140419\n",
            "accuracy:      0.761\n",
            "precision:     0.761\n",
            "recall:        0.761\n",
            "f1:            0.761\n",
            "===== Start training: epoch 18 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.495816230773926, Epoch: 18, training loss: 405.98467242717743, current learning rate 1e-05\n",
            "val loss: 42.83191579580307\n",
            "accuracy:      0.757\n",
            "precision:     0.757\n",
            "recall:        0.757\n",
            "f1:            0.757\n",
            "val loss: 43.07012528181076\n",
            "accuracy:      0.746\n",
            "precision:     0.746\n",
            "recall:        0.746\n",
            "f1:            0.746\n",
            "===== Start training: epoch 19 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.467386960983276, Epoch: 19, training loss: 398.9103444814682, current learning rate 1e-05\n",
            "val loss: 37.92085200548172\n",
            "accuracy:      0.766\n",
            "precision:     0.766\n",
            "recall:        0.766\n",
            "f1:            0.766\n",
            "val loss: 38.376400113105774\n",
            "accuracy:      0.760\n",
            "precision:     0.760\n",
            "recall:        0.759\n",
            "f1:            0.759\n",
            "===== Start training: epoch 20 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.577805042266846, Epoch: 20, training loss: 389.75825130939484, current learning rate 1e-05\n",
            "val loss: 42.240751564502716\n",
            "accuracy:      0.764\n",
            "precision:     0.764\n",
            "recall:        0.765\n",
            "f1:            0.764\n",
            "val loss: 44.13083863258362\n",
            "accuracy:      0.747\n",
            "precision:     0.747\n",
            "recall:        0.747\n",
            "f1:            0.747\n",
            "===== Start training: epoch 21 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.46473932266235, Epoch: 21, training loss: 383.72288036346436, current learning rate 1e-05\n",
            "val loss: 48.76641380786896\n",
            "accuracy:      0.773\n",
            "precision:     0.777\n",
            "recall:        0.773\n",
            "f1:            0.772\n",
            "val loss: 52.71045571565628\n",
            "accuracy:      0.752\n",
            "precision:     0.759\n",
            "recall:        0.755\n",
            "f1:            0.752\n",
            "===== Start training: epoch 22 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.5427622795105, Epoch: 22, training loss: 384.9201135635376, current learning rate 1e-05\n",
            "val loss: 43.73174077272415\n",
            "accuracy:      0.773\n",
            "precision:     0.775\n",
            "recall:        0.773\n",
            "f1:            0.772\n",
            "val loss: 45.35509133338928\n",
            "accuracy:      0.757\n",
            "precision:     0.758\n",
            "recall:        0.756\n",
            "f1:            0.756\n",
            "===== Start training: epoch 23 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.52764821052551, Epoch: 23, training loss: 384.32727801799774, current learning rate 1e-05\n",
            "val loss: 40.28625202178955\n",
            "accuracy:      0.769\n",
            "precision:     0.770\n",
            "recall:        0.770\n",
            "f1:            0.769\n",
            "val loss: 41.83689108490944\n",
            "accuracy:      0.757\n",
            "precision:     0.758\n",
            "recall:        0.758\n",
            "f1:            0.757\n",
            "===== Start training: epoch 24 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:55,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.50801420211792, Epoch: 24, training loss: 378.70354425907135, current learning rate 1e-05\n",
            "val loss: 38.315489679574966\n",
            "accuracy:      0.770\n",
            "precision:     0.773\n",
            "recall:        0.770\n",
            "f1:            0.769\n",
            "val loss: 39.42047417163849\n",
            "accuracy:      0.754\n",
            "precision:     0.757\n",
            "recall:        0.756\n",
            "f1:            0.754\n",
            "===== Start training: epoch 25 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:54,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.474698305130005, Epoch: 25, training loss: 363.5864671468735, current learning rate 1e-05\n",
            "val loss: 42.65453678369522\n",
            "accuracy:      0.768\n",
            "precision:     0.769\n",
            "recall:        0.768\n",
            "f1:            0.768\n",
            "val loss: 44.783642411231995\n",
            "accuracy:      0.752\n",
            "precision:     0.754\n",
            "recall:        0.754\n",
            "f1:            0.752\n",
            "===== Start training: epoch 26 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.54640293121338, Epoch: 26, training loss: 350.4692507982254, current learning rate 1e-05\n",
            "val loss: 40.161914706230164\n",
            "accuracy:      0.761\n",
            "precision:     0.761\n",
            "recall:        0.761\n",
            "f1:            0.761\n",
            "val loss: 41.678820848464966\n",
            "accuracy:      0.758\n",
            "precision:     0.758\n",
            "recall:        0.758\n",
            "f1:            0.758\n",
            "===== Start training: epoch 27 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:56,  5.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.56043529510498, Epoch: 27, training loss: 354.1883648633957, current learning rate 1e-05\n",
            "val loss: 43.42564219236374\n",
            "accuracy:      0.768\n",
            "precision:     0.768\n",
            "recall:        0.768\n",
            "f1:            0.768\n",
            "val loss: 45.65847051143646\n",
            "accuracy:      0.755\n",
            "precision:     0.755\n",
            "recall:        0.756\n",
            "f1:            0.755\n",
            "===== Start training: epoch 28 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:53,  5.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.451722621917725, Epoch: 28, training loss: 357.8649271726608, current learning rate 1e-05\n",
            "val loss: 45.54308992624283\n",
            "accuracy:      0.766\n",
            "precision:     0.766\n",
            "recall:        0.767\n",
            "f1:            0.766\n",
            "val loss: 48.61475372314453\n",
            "accuracy:      0.750\n",
            "precision:     0.750\n",
            "recall:        0.751\n",
            "f1:            0.750\n",
            "===== Start training: epoch 29 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:53,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.4326491355896, Epoch: 29, training loss: 367.76402175426483, current learning rate 1e-05\n",
            "val loss: 45.41219866275787\n",
            "accuracy:      0.765\n",
            "precision:     0.766\n",
            "recall:        0.765\n",
            "f1:            0.765\n",
            "val loss: 48.90185070037842\n",
            "accuracy:      0.753\n",
            "precision:     0.756\n",
            "recall:        0.755\n",
            "f1:            0.753\n",
            "===== Start training: epoch 30 =====\n",
            "*** trying with discovery_weight = 1.0000000000000002, adv_weight = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration:   4%|         | 202/5443 [00:34<14:53,  5.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 34.44231986999512, Epoch: 30, training loss: 368.35818445682526, current learning rate 1e-05\n",
            "val loss: 46.75881069898605\n",
            "accuracy:      0.765\n",
            "precision:     0.765\n",
            "recall:        0.765\n",
            "f1:            0.765\n",
            "val loss: 50.52084118127823\n",
            "accuracy:      0.752\n",
            "precision:     0.753\n",
            "recall:        0.753\n",
            "f1:            0.752\n",
            "best result:\n",
            "0.7571692876965772\n",
            "0.7575869924432552\n",
            "0.7555259785073449\n",
            "0.7559470503683747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.7571692876965772, 0.7587490136882913, 0.7586414275855269, 0.7571679889196463], [0.7460684551341351, 0.7464640083816098, 0.7468500443655723, 0.7460227590045199], [0.7562442183163737, 0.7578218806820132, 0.7577146800749285, 0.7562429145917211], [0.7571692876965772, 0.7575869924432552, 0.7555259785073449, 0.7559470503683747]]\n",
            "tensor([0.7590, 0.7596, 0.7595, 0.7588], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "import time\n",
        "import datasets\n",
        "import pickle\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.optim.lr_scheduler import LinearLR\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "args = {\n",
        "    \"model_name\": \"roberta-base\",\n",
        "    \"num_classes\": 2, #3, #2,\n",
        "    \"num_classes_adv\": 3, #174,\n",
        "    \"embed_size\": 768,\n",
        "    \"first_last_avg\": True,\n",
        "    \"seed\": [0,1,2],\n",
        "    \"batch_size\": 64,\n",
        "    \"epochs\": 30,\n",
        "    \"class_weight\": 1, #[9.375, 30, 1], #10 [2.071, 1.933, 1]\n",
        "    \"lr\": 1e-5\n",
        "}\n",
        "\n",
        "config = {\n",
        "    \"dataset\": \"debate\", #\"student_essay\", #debate, m-arg\n",
        "    \"adversarial\": False,\n",
        "    \"double_adversarial\": True,\n",
        "    \"dataset_from_saved\": True,\n",
        "    \"injection\": False,\n",
        "    \"grid_search\": True,\n",
        "    \"visualize\": True,\n",
        "    \"train\": True,\n",
        "    \"scheduler\": False,\n",
        "    \"attention\": True,\n",
        "    \"cue_gating\": False\n",
        "}\n",
        "\n",
        "def train(epoch, model, loss_fn, optimizer, train_loader, scheduler=None, discovery_weight=0.3, adv_weight=0.3):\n",
        "    epoch_start_time = time.time()\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    loss_fn2 = nn.CrossEntropyLoss()\n",
        "\n",
        "    for step, batch in enumerate(tqdm(train_loader, desc='Iteration')):\n",
        "        if config[\"adversarial\"]:\n",
        "          batch = tuple(t.to(device) if not isinstance(t, list) else t for t in batch)\n",
        "        else:\n",
        "          batch = tuple(t.to(device) if not isinstance(t, list) else t for t in batch) #tuple(t.to(device) for t in batch)\n",
        "\n",
        "        ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels = batch\n",
        "\n",
        "        if config[\"adversarial\"]:\n",
        "          pred, pred_adv, task_pred = model(ids_sent1, segs_sent1, att_mask_sent1, position_sep)\n",
        "          try:\n",
        "            half_batch_size = len(labels) // 2\n",
        "            targets, targets_adv, targets_task = labels[:half_batch_size], labels[half_batch_size:], [[0, 1]] * half_batch_size + [[1, 0]] * half_batch_size\n",
        "            targets, targets_adv, targets_task = torch.tensor(np.array(targets)).to(device), \\\n",
        "                                                 torch.tensor(np.array(targets_adv)).to(device), \\\n",
        "                                                 torch.tensor(np.array(targets_task)).to(device)\n",
        "          except:\n",
        "            print(\"error\")\n",
        "\n",
        "          loss1 = loss_fn(pred, targets.float())\n",
        "          loss2 = loss_fn2(pred_adv, targets_adv.float())\n",
        "          loss3 = loss_fn2(task_pred, targets_task.float())\n",
        "          loss = loss1 + discovery_weight*loss2 + adv_weight*loss3\n",
        "        elif config[\"double_adversarial\"]:\n",
        "          pred, pred_adv, task_pred, attack_pred, support_pred = model(ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels)\n",
        "          try:\n",
        "            half_batch_size = len(labels) // 2\n",
        "            targets, targets_adv, targets_task = labels[:half_batch_size], labels[half_batch_size:], [[0, 1]] * half_batch_size + [[1, 0]] * half_batch_size\n",
        "            targets, targets_adv, targets_task = torch.tensor(np.array(targets)).to(device), \\\n",
        "                                                 torch.tensor(np.array(targets_adv)).to(device), \\\n",
        "                                                 torch.tensor(np.array(targets_task)).to(device)\n",
        "            \"\"\"print(targets)\n",
        "            print((targets == torch.tensor([0,1]).to(device)).all(dim=1))\n",
        "            print(torch.sum((targets == torch.tensor([0,1]).to(device)).all(dim=1)).item())\"\"\"\n",
        "\n",
        "            attack_len = torch.sum((targets == torch.tensor([0,1]).to(device)).all(dim=1)).item()\n",
        "            support_len = torch.sum((targets == torch.tensor([1,0]).to(device)).all(dim=1)).item()\n",
        "            contr_len = torch.sum((targets_adv == torch.tensor([1,0,0]).to(device)).all(dim=1)).item()\n",
        "            other_len = torch.sum((targets_adv == torch.tensor([0,1,0]).to(device)).all(dim=1) | (targets_adv == torch.tensor([0,0,1]).to(device)).all(dim=1)).item()\n",
        "\n",
        "            \"\"\"print(attack_len)\n",
        "            print(contr_len)\n",
        "            print(support_len)\n",
        "            print(other_len)\"\"\"\n",
        "\n",
        "            attack_target = [[0,1]] * attack_len + [[1,0]] * contr_len\n",
        "            support_target = [[0,1]] * support_len + [[1,0]] * other_len\n",
        "            attack_target, support_target = torch.tensor(np.array(attack_target)).to(device), torch.tensor(np.array(support_target)).to(device)\n",
        "          except:\n",
        "            print(\"error\")\n",
        "\n",
        "          loss1 = loss_fn(pred, targets.float())\n",
        "          loss2 = loss_fn2(pred_adv, targets_adv.float())\n",
        "          loss3 = loss_fn2(task_pred, targets_task.float())\n",
        "          loss4 = loss_fn2(attack_pred, attack_target.float())\n",
        "          loss5 = loss_fn2(support_pred, support_target.float())\n",
        "          loss = loss1 + discovery_weight*loss2 + adv_weight*loss3 + loss4 + loss5\n",
        "        else:\n",
        "          out = model(ids_sent1, segs_sent1, att_mask_sent1, position_sep)\n",
        "          if isinstance(labels, list):\n",
        "            labels = torch.tensor(np.array(labels)).to(device)\n",
        "          loss = loss_fn(out, labels.float())\n",
        "\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    timing = time.time() - epoch_start_time\n",
        "    cur_lr = optimizer.param_groups[0][\"lr\"]\n",
        "    print(f\"Timing: {timing}, Epoch: {epoch + 1}, training loss: {tr_loss}, current learning rate {cur_lr}\")\n",
        "\n",
        "def val(model, val_loader):\n",
        "    model.eval()\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    val_loss = 0\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "    for batch in val_loader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "          if config[\"double_adversarial\"]:\n",
        "            out = model(ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels)\n",
        "          else:\n",
        "            out = model(ids_sent1, segs_sent1, att_mask_sent1, position_sep)\n",
        "          preds = torch.max(out.data, 1)[1].cpu().numpy().tolist()\n",
        "          loss = loss_fn(out, labels.float())\n",
        "          val_loss += loss.item()\n",
        "\n",
        "          labels = labels.cpu().numpy().tolist()\n",
        "\n",
        "          val_labels.extend(labels)\n",
        "          if len(labels[0]) != 2:\n",
        "            for pred in preds:\n",
        "              if pred == 0:\n",
        "                val_preds.append([1,0,0])\n",
        "              elif pred == 1:\n",
        "                val_preds.append([0,1,0])\n",
        "              else:\n",
        "                val_preds.append([0,0,1])\n",
        "          else:\n",
        "            val_preds.extend([[1,0] if pred == 0 else [0,1] for pred in preds])\n",
        "\n",
        "    print(f\"val loss: {val_loss}\")\n",
        "\n",
        "    val_acc, val_prec, val_recall, val_f1 = output_metrics(val_labels, val_preds)\n",
        "    return val_acc, val_prec, val_recall, val_f1\n",
        "\n",
        "def visualize(epoch, model, test_dataloader, train_adv_dataloader, discovery_weight = 0.2, adv_weight = 0.2):\n",
        "  if not config[\"adversarial\"]:\n",
        "    return\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "  tot_labels = None\n",
        "  embeddings = None\n",
        "\n",
        "  tot_labels_adv = None\n",
        "  embeddings_adv = None\n",
        "\n",
        "  print(\"Visualizing...\")\n",
        "  for batch in tqdm(test_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels = batch\n",
        "    labels = torch.argmax(labels, dim=-1)\n",
        "    if tot_labels is None:\n",
        "      tot_labels = labels\n",
        "    else:\n",
        "      tot_labels = torch.cat([tot_labels, labels], dim=0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      out = model(ids_sent1, segs_sent1, att_mask_sent1, position_sep, visualize=True)\n",
        "      if embeddings is None:\n",
        "        embeddings = out\n",
        "      else:\n",
        "        embeddings = torch.cat([embeddings, out], dim=0)\n",
        "\n",
        "  for i, batch in tqdm(enumerate(train_adv_dataloader)):\n",
        "    if i == 20: break\n",
        "    batch = tuple(t.to(device) if not isinstance(t, list) else t for t in batch)\n",
        "    ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels = batch\n",
        "    labels = torch.tensor(np.array(labels)).to(device)\n",
        "    labels = torch.argmax(labels, dim=-1)+2\n",
        "\n",
        "    if tot_labels_adv is None:\n",
        "      tot_labels_adv = labels\n",
        "    else:\n",
        "      tot_labels_adv = torch.cat([tot_labels_adv, labels], dim=0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      out = model(ids_sent1, segs_sent1, att_mask_sent1, position_sep, visualize=True)\n",
        "      if embeddings_adv is None:\n",
        "        embeddings_adv = out\n",
        "      else:\n",
        "        embeddings_adv = torch.cat([embeddings_adv, out], dim=0)\n",
        "\n",
        "  tsne = TSNE(random_state=0)\n",
        "  tsne_results = tsne.fit_transform(embeddings.cpu().numpy())\n",
        "  tsne_results_adv = tsne.fit_transform(embeddings_adv.cpu().numpy())\n",
        "\n",
        "  df_tsne = pd.DataFrame(tsne_results, columns=[\"x\",\"y\"])\n",
        "  df_tsne_adv = pd.DataFrame(tsne_results_adv, columns=[\"x\",\"y\"])\n",
        "\n",
        "  df_tsne[\"label\"] = tot_labels.cpu().numpy()\n",
        "  df_tsne_adv[\"label\"] = tot_labels_adv.cpu().numpy()\n",
        "\n",
        "  print(df_tsne_adv[\"label\"].unique())\n",
        "\n",
        "  fig1, ax1 = plt.subplots(figsize=(8,6))\n",
        "  sns.set_style('darkgrid', {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\n",
        "  sns.scatterplot(data=df_tsne, x='x', y='y', hue='label', palette='deep')\n",
        "  sns.move_legend(ax1, \"upper left\", bbox_to_anchor=(1, 1))\n",
        "  plt.title(f'Scatter plot of embeddings trained with  = {discovery_weight} and  = {adv_weight}');\n",
        "  plt.xlabel('x');\n",
        "  plt.ylabel('y');\n",
        "  plt.axis('equal')\n",
        "  plt.show()\n",
        "\n",
        "  fig2, ax2 = plt.subplots(figsize=(8,6))\n",
        "  sns.set_style('darkgrid', {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\n",
        "  sns.scatterplot(data=df_tsne_adv, x='x', y='y', hue='label', palette='deep')\n",
        "  sns.move_legend(ax2, \"upper left\", bbox_to_anchor=(1, 1))\n",
        "  plt.title(f'Scatter plot of embeddings trained with  = {discovery_weight} and  = {adv_weight}');\n",
        "  plt.xlabel('x');\n",
        "  plt.ylabel('y');\n",
        "  plt.axis('equal')\n",
        "  plt.show()\n",
        "\n",
        "def run(seed):\n",
        "  set_random_seeds(seed)\n",
        "\n",
        "  if config[\"dataset\"] == \"student_essay\":\n",
        "    if config[\"injection\"]:\n",
        "      processor = StudentEssayWithDiscourseInjectionProcessor()\n",
        "    else:\n",
        "      processor = StudentEssayProcessor()\n",
        "\n",
        "    path_train = \"./data/student_essay/train_essay.txt\"\n",
        "    path_dev = \"./data/student_essay/dev_essay.txt\"\n",
        "    path_test = \"./data/student_essay/test_essay.txt\"\n",
        "  elif config[\"dataset\"] == \"debate\":\n",
        "    if config[\"injection\"]:\n",
        "      processor = DebateWithDiscourseInjectionProcessor()\n",
        "    else:\n",
        "      processor = DebateProcessor()\n",
        "\n",
        "    path_train = \"./data/debate/train_debate_concept.txt\"\n",
        "    path_dev = \"./data/debate/dev_debate_concept.txt\"\n",
        "    path_test = \"./data/debate/test_debate_concept.txt\"\n",
        "  elif config[\"dataset\"] == \"m-arg\":\n",
        "    if config[\"injection\"]:\n",
        "      processor = MARGWithDiscourseInjectionProcessor()\n",
        "    else:\n",
        "      processor = MARGProcessor()\n",
        "\n",
        "    path_train = \"./data/m-arg/presidential_final.csv\"\n",
        "    path_dev = path_train\n",
        "    path_test = path_train\n",
        "  elif config[\"dataset\"] == \"nk\":\n",
        "    if config[\"injection\"]:\n",
        "      processor = NKWithDiscourseInjectionProcessor()\n",
        "    else:\n",
        "      processor = NKProcessor()\n",
        "\n",
        "    path_train = \"./data/nk/balanced_dataset.tsv\"\n",
        "  else:\n",
        "    raise ValueError(f\"{config['dataset']} is not a valid database name (choose from 'student_essay' and 'debate')\")\n",
        "\n",
        "  max_sent_length = -1\n",
        "\n",
        "  data_train = processor.read_input_files(path_train, max_sent_length, name=\"train\")\n",
        "\n",
        "  if config[\"dataset\"] == \"nk\":\n",
        "    data_dev = data_train[:len(data_train) // 10]\n",
        "    data_test = data_train[-(len(data_train) // 10):]\n",
        "    data_train = data_train[(len(data_train) // 10) : -(len(data_train) // 10)]\n",
        "  else:\n",
        "    data_dev = processor.read_input_files(path_dev, max_sent_length, name=\"dev\")\n",
        "    data_test = processor.read_input_files(path_test, max_sent_length, name=\"test\")\n",
        "\n",
        "  if config[\"adversarial\"] or config[\"double_adversarial\"]:\n",
        "    df = datasets.load_dataset(\"discovery\",\"discovery\")\n",
        "    adv_processor = DiscourseMarkerProcessor()\n",
        "    if not config[\"dataset_from_saved\"]:\n",
        "      print(\"processing discourse marker dataset...\")\n",
        "      train_adv = adv_processor.process_dataset(df[\"train\"])\n",
        "      with open(\"./adv_dataset.pkl\", \"wb\") as writer:\n",
        "        pickle.dump(train_adv, writer)\n",
        "    else:\n",
        "      with open(\"./adv_dataset.pkl\", \"rb\") as reader:\n",
        "        train_adv = pickle.load(reader)\n",
        "\n",
        "    data_train_tot = data_train + train_adv\n",
        "    train_set_adv = dataset(train_adv)\n",
        "  else:\n",
        "    data_train_tot = data_train\n",
        "\n",
        "  train_set = dataset(data_train_tot)\n",
        "  dev_set = dataset(data_dev)\n",
        "  test_set = dataset(data_test)\n",
        "\n",
        "  if config[\"double_adversarial\"]:\n",
        "    sampler_train = BalancedSampler(data_train, train_adv, args[\"batch_size\"])\n",
        "    train_dataloader = DataLoader(train_set, batch_sampler=sampler_train, collate_fn=collate_fn_concatenated_adv)\n",
        "    train_adv_dataloader = DataLoader(train_set_adv, batch_size=args[\"batch_size\"], shuffle=True, collate_fn=collate_fn_concatenated_adv)\n",
        "\n",
        "    model = DoubleAdversarialNet()\n",
        "\n",
        "  elif not config[\"adversarial\"]:\n",
        "    #sampler_train = BalancedSampler(data_train, train_adv, args[\"batch_size\"])\n",
        "    #train_dataloader = DataLoader(train_set, batch_sampler=sampler_train, collate_fn=collate_fn_concatenated_adv)\n",
        "    train_dataloader = DataLoader(train_set, batch_size=args[\"batch_size\"], shuffle=True, collate_fn=collate_fn_concatenated)\n",
        "    if not config[\"cue_gating\"]:\n",
        "      model = BaselineModelWithSentenceComparison(attention=config[\"attention\"])\n",
        "    else:\n",
        "      model = BaselineModelWithSentenceComparisonAndCue(attention=config[\"attention\"])\n",
        "  else:\n",
        "    sampler_train = BalancedSampler(data_train, train_adv, args[\"batch_size\"])\n",
        "    train_dataloader = DataLoader(train_set, batch_sampler=sampler_train, collate_fn=collate_fn_concatenated_adv)\n",
        "    train_adv_dataloader = DataLoader(train_set_adv, batch_size=args[\"batch_size\"], shuffle=True, collate_fn=collate_fn_concatenated_adv)\n",
        "\n",
        "    model = AdversarialNet()\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  dev_dataloader = DataLoader(dev_set, batch_size=args[\"batch_size\"], shuffle=True, collate_fn=collate_fn_concatenated)\n",
        "  test_dataloader = DataLoader(test_set, batch_size=args[\"batch_size\"], shuffle=True, collate_fn=collate_fn_concatenated)\n",
        "\n",
        "  no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "  optimizer_grouped_parameters = [\n",
        "    {\n",
        "      \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "      \"weight_decay\": 0.01,\n",
        "    },\n",
        "    {\n",
        "      \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "      \"weight_decay\": 0.0\n",
        "    },\n",
        "  ]\n",
        "  optimizer = AdamW(optimizer_grouped_parameters, lr=args[\"lr\"])\n",
        "\n",
        "  if config[\"dataset\"] in [\"m-arg\",\"nk\"]:\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(args[\"class_weight\"]).to(device))\n",
        "  else:\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=torch.Tensor([1, args[\"class_weight\"]]).to(device))\n",
        "\n",
        "  best_acc = -1\n",
        "  best_pre = -1\n",
        "  best_rec = -1\n",
        "  best_f1 = -1\n",
        "  best_dev_acc, best_dev_pre, best_dev_rec, best_dev_f1 = -1, -1, -1, -1\n",
        "\n",
        "  result_metrics = []\n",
        "\n",
        "  if config[\"grid_search\"]:\n",
        "    range_disc = np.arange(0.4,1.2,0.2)\n",
        "    range_adv = np.arange(0,1.2,0.2)\n",
        "\n",
        "    for discovery_weight in range_disc:\n",
        "      for adv_weight in [1]: #range_adv:\n",
        "        for epoch in range(args[\"epochs\"]):\n",
        "          print('===== Start training: epoch {} ====='.format(epoch + 1))\n",
        "          print(f\"*** trying with discovery_weight = {discovery_weight}, adv_weight = {adv_weight}\")\n",
        "          train(epoch, model, loss_fn, optimizer, train_dataloader, discovery_weight=discovery_weight, adv_weight=adv_weight)\n",
        "          dev_a, dev_p, dev_r, dev_f1 = val(model, dev_dataloader)\n",
        "          test_a, test_p, test_r, test_f1 = val(model, test_dataloader)\n",
        "          if dev_f1 > best_dev_f1:\n",
        "            best_dev_acc, best_dev_pre, best_dev_rec, best_dev_f1 = dev_a, dev_p, dev_r, dev_f1\n",
        "            best_test_acc, best_test_pre, best_test_rec, best_test_f1 = test_a, test_p, test_r, test_f1\n",
        "            #save model\n",
        "\n",
        "        print('best result:')\n",
        "        print(best_test_acc)\n",
        "        print(best_test_pre)\n",
        "        print(best_test_rec)\n",
        "        print(best_test_f1)\n",
        "        result_metrics.append([best_test_acc, best_test_pre, best_test_rec, best_test_f1])\n",
        "        del model\n",
        "        del optimizer\n",
        "\n",
        "        set_random_seeds(seed)\n",
        "        model = DoubleAdversarialNet()\n",
        "        model = model.to(device)\n",
        "\n",
        "        optimizer_grouped_parameters = [\n",
        "          {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": 0.01,\n",
        "          },\n",
        "          {\n",
        "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": 0.0\n",
        "          },\n",
        "        ]\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, lr=args[\"lr\"])\n",
        "\n",
        "        best_acc = -1\n",
        "        best_pre = -1\n",
        "        best_rec = -1\n",
        "        best_f1 = -1\n",
        "        best_dev_acc, best_dev_pre, best_dev_rec, best_dev_f1 = -1, -1, -1, -1\n",
        "  else:\n",
        "    if config[\"scheduler\"]:\n",
        "      scheduler = LinearLR(optimizer, start_factor=1, end_factor=1e-1, total_iters = 30)\n",
        "    for epoch in range(args[\"epochs\"]):\n",
        "      if config[\"train\"]:\n",
        "        print('===== Start training: epoch {} ====='.format(epoch + 1))\n",
        "        train(epoch, model, loss_fn, optimizer, train_dataloader, discovery_weight=0.6, adv_weight=0.6)\n",
        "        dev_a, dev_p, dev_r, dev_f1 = val(model, dev_dataloader)\n",
        "        test_a, test_p, test_r, test_f1 = val(model, test_dataloader)\n",
        "        if config[\"scheduler\"]:\n",
        "          scheduler.step()\n",
        "        if dev_f1 > best_dev_f1:\n",
        "          best_dev_acc, best_dev_pre, best_dev_rec, best_dev_f1 = dev_a, dev_p, dev_r, dev_f1\n",
        "          best_test_acc, best_test_pre, best_test_rec, best_test_f1 = test_a, test_p, test_r, test_f1\n",
        "          torch.save(model.state_dict(), f\"./{config['dataset']}_model.pt\")\n",
        "\n",
        "    if config[\"visualize\"] and config[\"adversarial\"]:\n",
        "      model.load_state_dict(torch.load(f\"./{config['dataset']}_model.pt\"))\n",
        "      visualize(epoch, model, test_dataloader, train_adv_dataloader, 0.6, 0.6)\n",
        "\n",
        "        #save model\n",
        "\n",
        "    print('best result:')\n",
        "    print(best_test_acc)\n",
        "    print(best_test_pre)\n",
        "    print(best_test_rec)\n",
        "    print(best_test_f1)\n",
        "    result_metrics.append([best_test_acc, best_test_pre, best_test_rec, best_test_f1])\n",
        "\n",
        "  print(result_metrics)\n",
        "  return result_metrics[0]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  results = []\n",
        "  for seed in args[\"seed\"]:\n",
        "    if seed == 0: continue\n",
        "    print(f\"**** trying with seed {seed} ****\")\n",
        "    result_metrics = run(seed)\n",
        "    results.append(result_metrics)\n",
        "  avg = torch.mean(torch.tensor(results), dim=0)\n",
        "  print(avg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w7siPoLeqiKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "3HwOo-fjjQpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DPCKGHFDeHpO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}