{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucacontalbo/ArgumentRelation/blob/main/ArgumentRelation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky2et35Vyxhs",
        "outputId": "ac26e5ea-89af-4952-c6c7-f90360b83e4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFwY-xBMq1dR",
        "outputId": "0e69e428-346d-4e3c-e1cb-9a98370b831b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMNLyzTly41e",
        "outputId": "b2a6cecb-da4e-46f1-e3b5-e2d1435b5b7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1anU-7aAYPfQ-YWIA0AJDKz_AqkD19g_x/AttackSupport\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/AttackSupport/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tePLdrxvDTib",
        "outputId": "877d96f5-37b6-4283-adea-a44e003daeda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "   print(\"Training on GPU\")\n",
        "   device = torch.device(\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CfqTHh1L6dA0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class dataset(Dataset):\n",
        "    \"\"\"wrap in PyTorch Dataset\"\"\"\n",
        "    def __init__(self, examples):\n",
        "        super(dataset, self).__init__()\n",
        "        self.examples = examples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.examples[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "\n",
        "def collate_fn(examples):\n",
        "    ids_sent1, segs_sent1, att_mask_sent1, ids_sent2, segs_sent2, att_mask_sent2, labels = map(list, zip(*examples))\n",
        "\n",
        "    ids_sent1 = torch.tensor(ids_sent1, dtype=torch.long)\n",
        "    segs_sent1 = torch.tensor(segs_sent1, dtype=torch.long)\n",
        "    att_mask_sent1 = torch.tensor(att_mask_sent1, dtype=torch.long)\n",
        "    ids_sent2 = torch.tensor(ids_sent2, dtype=torch.long)\n",
        "    segs_sent2 = torch.tensor(segs_sent2, dtype=torch.long)\n",
        "    att_mask_sent2 = torch.tensor(att_mask_sent2, dtype=torch.long)\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    return ids_sent1, segs_sent1, att_mask_sent1, ids_sent2, segs_sent2, att_mask_sent2, labels\n",
        "\n",
        "def collate_fn_concatenated(examples):\n",
        "    ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels = map(list, zip(*examples))\n",
        "\n",
        "    ids_sent1 = torch.tensor(ids_sent1, dtype=torch.long)\n",
        "    segs_sent1 = torch.tensor(segs_sent1, dtype=torch.long)\n",
        "    att_mask_sent1 = torch.tensor(att_mask_sent1, dtype=torch.long)\n",
        "    position_sep = torch.tensor(position_sep, dtype=torch.long)\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    return ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels\n",
        "\n",
        "def collate_fn_concatenated_adv(examples):\n",
        "    ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels = map(list, zip(*examples))\n",
        "\n",
        "    ids_sent1 = torch.tensor(ids_sent1, dtype=torch.long)\n",
        "    segs_sent1 = torch.tensor(segs_sent1, dtype=torch.long)\n",
        "    att_mask_sent1 = torch.tensor(att_mask_sent1, dtype=torch.long)\n",
        "    position_sep = torch.tensor(position_sep, dtype=torch.long)\n",
        "    #labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    return ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "U4y_C5W0r0Bl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import collections\n",
        "import codecs\n",
        "from transformers import AutoTokenizer, pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "\n",
        "class DataProcessor:\n",
        "\n",
        "  def __init__(self,):\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(args[\"model_name\"])\n",
        "    self.max_sent_len = 150\n",
        "\n",
        "  def __str__(self,):\n",
        "    pattern = \"\"\"General data processor: \\n\\n Tokenizer: {}\\n\\nMax sentence length: {}\"\"\".format(args[\"model_name\"], self.max_sent_len)\n",
        "    return pattern\n",
        "\n",
        "  def _get_examples(self, dataset, dataset_type=\"train\"):\n",
        "    examples = []\n",
        "\n",
        "    for row in dataset:\n",
        "      id, sentence1, sentence2, _, _, _, label = row\n",
        "\n",
        "      \"\"\"\n",
        "      for the first sentence\n",
        "      \"\"\"\n",
        "\n",
        "      ids_sent1 = self.tokenizer.encode(sentence1)\n",
        "      segs_sent1 = [0] * len(ids_sent1)\n",
        "      segs_sent1[1:-1] = [1] * (len(ids_sent1)-2)\n",
        "\n",
        "      \"\"\"\n",
        "      for the second sentence\n",
        "      \"\"\"\n",
        "\n",
        "      ids_sent2 = self.tokenizer.encode(sentence2)\n",
        "      segs_sent2 = [0] * len(ids_sent2)\n",
        "      segs_sent2[1:-1] = [1] * (len(ids_sent2)-2)\n",
        "\n",
        "      assert len(ids_sent1) == len(segs_sent1)\n",
        "      assert len(ids_sent2) == len(segs_sent2)\n",
        "\n",
        "      pad_id = self.tokenizer.encode(self.tokenizer.pad_token, add_special_tokens=False)[0]\n",
        "\n",
        "      if len(ids_sent1) < self.max_sent_len:\n",
        "        res = self.max_sent_len - len(ids_sent1)\n",
        "        att_mask_sent1 = [1] * len(ids_sent1) + [0] * res\n",
        "        ids_sent1 += [pad_id] * res\n",
        "        segs_sent1 += [0] * res\n",
        "      else:\n",
        "        ids_sent1 = ids_sent1[:self.max_sent_len]\n",
        "        segs_sent1 = segs_sent1[:self.max_sent_len]\n",
        "        att_mask_sent1 = [1] * self.max_sent_len\n",
        "\n",
        "      if len(ids_sent2) < self.max_sent_len:\n",
        "        res = self.max_sent_len - len(ids_sent2)\n",
        "        att_mask_sent2 = [1] * len(ids_sent2) + [0] * res\n",
        "        ids_sent2 += [pad_id] * res\n",
        "        segs_sent2 += [0] * res\n",
        "      else:\n",
        "        ids_sent2 = ids_sent2[:self.max_sent_len]\n",
        "        segs_sent2 = segs_sent2[:self.max_sent_len]\n",
        "        att_mask_sent2 = [1] * self.max_sent_len\n",
        "\n",
        "      example = [ids_sent1, segs_sent1, att_mask_sent1, ids_sent2, segs_sent2, att_mask_sent2, label]\n",
        "\n",
        "      examples.append(example)\n",
        "\n",
        "    print(f\"finished preprocessing examples in {dataset_type}\")\n",
        "\n",
        "    return examples\n",
        "\n",
        "  def _get_examples_concatenated(self, dataset, dataset_type=\"train\"):\n",
        "    examples = []\n",
        "\n",
        "    for row in tqdm(dataset, desc=\"tokenizing...\"):\n",
        "      id, sentence1, sentence2, _, _, _, label = row\n",
        "\n",
        "      \"\"\"\n",
        "      for the first sentence\n",
        "      \"\"\"\n",
        "\n",
        "      sentence1_length = len(self.tokenizer.encode(sentence1))\n",
        "      sentence2_length = len(self.tokenizer.encode(sentence2))\n",
        "      #sentence1 += \" </s> \"+sentence2\n",
        "\n",
        "      ids_sent1 = self.tokenizer.encode(sentence1, sentence2)\n",
        "      segs_sent1 = [0] * sentence1_length + [1] * (sentence2_length)\n",
        "      position_sep = [1] * len(ids_sent1)\n",
        "      position_sep[sentence1_length] = 1\n",
        "      position_sep[0] = 0\n",
        "      position_sep[1] = 1\n",
        "\n",
        "      assert len(ids_sent1) == len(position_sep)\n",
        "      assert len(ids_sent1) == len(segs_sent1)\n",
        "\n",
        "      pad_id = self.tokenizer.encode(self.tokenizer.pad_token, add_special_tokens=False)[0]\n",
        "\n",
        "      if len(ids_sent1) < self.max_sent_len:\n",
        "        res = self.max_sent_len - len(ids_sent1)\n",
        "        att_mask_sent1 = [1] * len(ids_sent1) + [0] * res\n",
        "        ids_sent1 += [pad_id] * res\n",
        "        segs_sent1 += [0] * res\n",
        "        position_sep += [0] * res\n",
        "      else:\n",
        "        ids_sent1 = ids_sent1[:self.max_sent_len]\n",
        "        segs_sent1 = segs_sent1[:self.max_sent_len]\n",
        "        att_mask_sent1 = [1] * self.max_sent_len\n",
        "        position_sep = position_sep[:self.max_sent_len]\n",
        "\n",
        "      example = [ids_sent1, segs_sent1, att_mask_sent1, position_sep, label]\n",
        "\n",
        "      examples.append(example)\n",
        "\n",
        "    print(f\"finished preprocessing examples in {dataset_type}\")\n",
        "\n",
        "    return examples\n",
        "\n",
        "class DiscourseMarkerProcessor(DataProcessor):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(DiscourseMarkerProcessor, self).__init__()\n",
        "    #https://pdf.sciencedirectassets.com/271806/1-s2.0-S0378216600X00549/1-s2.0-S0378216698001015/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGgaCXVzLWVhc3QtMSJIMEYCIQCiYMlVmna%2BTaXH5hqdwfhEBWd2VPRNoAHlQLGxzvNEqAIhAO3TVTA51qn13kKQp2bTlzGkaKnf6NhMYtr7laU%2Byy0vKrwFCMH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQBRoMMDU5MDAzNTQ2ODY1Igzyz%2F2NAMoW0RbAZ%2BMqkAWG017si0y%2FOokz5T44gGpNBL07jup8MAQjv8iwoi4XGALwCP0nf%2FgHD1ZE%2B%2BQGuaLPuShgLg7Y3%2Fcsv2VjkbfrNBSdZPYhqpzpAClSmP2Zs0DszX0zXdmnx4uFyls6d9jCG4TQkhqTsNCGsnKjU89G7z9NMutpaWqEGcUWT6MVMXpxILGQfeu5zLM0ILcft20VXs2dnMMIjWXA5jd0pG8HnAXdils2AmfgTqt%2B9cHn5BXhv%2FaSXX9a7lwR7EbIoUqZVLo%2BDJR2JLtaLYdoZR01FI3FhNAk7Hx1ZLd3RSWWQrRy3ovGKbKnTYC8Jn%2Bs1w1tkF4OJzCy7EZg578HFrPsvxQrUGwtkXfY1BIralzc9JmYZ%2FS1VPIVSvZSM6E3sUUIND14uQDKhQyTQh6WBbG1djkU8M9bW%2ByVDRj8CKEoWdN4ofK3WuRD87QQEAJQ8jwnl0rCtVIYecZyfQzTnpdO0jafDlritW%2BlfSDqyd8ob%2F%2BkljgtN1m8IFKNQ9lopVjvwCzDa5R%2F0WvchF%2BqNMzImVtUHTgXgJOcGC6y9OSVqRGFgQtPhy6W26WodWQxaFsBMTn49dM6rzsyNhd301U4SYL5vTLrLhjmm3%2Ft5JqKHS7JaAbmKYa4DvabWH4Qs2WHsZMxVd8L3KU%2FIeyaQwATOf3TZVCVPWUriUg%2FAKFcuceC1AaUE5MKWB8Qe2Cb5%2FpagPPYTztfNluPar21xLpY7cayKABv%2FkyIa2N9MsaPm8VEvSb90Sl1EkJAxXP3kVU2XTtZqcYPuHgdSyUwh%2FDC%2F0Y1FlLyZW%2BLrnVmL9sqtORiZcZU20jVgXM8HoLIG2vvo0er4qyok9ZxzykuzhClN6ZULz%2FTja1y%2FdhF2UR89jCk%2BuOxBjqwARYSDjyJE7HksxP39FMsgAM0RH2Us2vj22eV6lkbG1n1%2BZm%2B4a4UeUfzibr4B6BdF%2BB3i%2FHsJ3QF1AnxdSS%2F0x5HnBmGCct1etAdyP60bbBH8p1dCgNQL7kb%2BqKINd78nYfrM0D0a4U%2Fxm2FUNln3swIdVpXtLtz0qY2QSaHbc6Ir6BCR8Kqm0FKQyhv1JSMkKfIdFQ9pYCVy8VAr%2BLBA9uSXfFDz6N67ruhh%2BzJWFn1&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20240506T173714Z&X-Amz-SignedHeaders=host&X-Amz-Expires=299&X-Amz-Credential=ASIAQ3PHCVTYUU54IYV3%2F20240506%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=7303563def203481e9802185fa8eab7dd21d58c841cd92621bbbdb18e253f595&hash=62697dff1cc869850b2d38305ff2ad1a35ad33938dbb92466663bdb1bf67d069&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0378216698001015&tid=spdf-c2371d97-52db-456d-a333-31d65dde09f3&sid=c8e761cb3c79f3499a2a90d699ea19871d47gxrqb&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=091359520307070d01&rr=87fabcafde0b0e1b&cc=it\n",
        "    # TODO: refactor\n",
        "    self.mapping = elements_dict = {\n",
        "      \"accordingly\": 0,\n",
        "      \"also\": 1,\n",
        "      \"although\": 2,\n",
        "      \"and\": 1,\n",
        "      \"as_a_result\": 0,\n",
        "      \"because_of_that\": 0,\n",
        "      \"because_of_this\": 0,\n",
        "      \"besides\": 0,\n",
        "      \"but\": 2,\n",
        "      \"by_comparison\": 2,\n",
        "      \"by_contrast\": 2,\n",
        "      \"consequently\": 0,\n",
        "      \"conversely\": 0,\n",
        "      \"especially\": 1,\n",
        "      \"further\": 1,\n",
        "      \"furthermore\": 1,\n",
        "      \"hence\": 0,\n",
        "      \"however\": 2,\n",
        "      \"in_contrast\": 2,\n",
        "      \"instead\": 2,\n",
        "      \"likewise\": 1,\n",
        "      \"moreover\": 1,\n",
        "      \"namely\": 1,\n",
        "      \"nevertheless\": 2,\n",
        "      \"nonetheless\": 2,\n",
        "      \"on_the_contrary\": 2,\n",
        "      \"on_the_other_hand\": 2,\n",
        "      \"otherwise\": 1,\n",
        "      \"rather\": 2,\n",
        "      \"similarly\": 1,\n",
        "      \"so\": 0,\n",
        "      \"still\": 2,\n",
        "      \"then\": 0,\n",
        "      \"therefore\": 0,\n",
        "      \"though\": 2,\n",
        "      \"thus\": 0,\n",
        "      \"well\": 1,\n",
        "      \"yet\": 2\n",
        "    }\n",
        "\n",
        "    \"\"\"self.mapping = elements_dict = {\n",
        "      \"accordingly\": 0,\n",
        "      \"also\": 0,\n",
        "      \"although\": 1,\n",
        "      \"and\": 0,\n",
        "      \"as_a_result\": 0,\n",
        "      \"because_of_that\": 0,\n",
        "      \"because_of_this\": 0,\n",
        "      \"besides\": 0,\n",
        "      \"but\": 1,\n",
        "      \"by_comparison\": 1,\n",
        "      \"by_contrast\": 1,\n",
        "      \"consequently\": 0,\n",
        "      \"conversely\": 0,\n",
        "      \"especially\": 0,\n",
        "      \"further\": 0,\n",
        "      \"furthermore\": 0,\n",
        "      \"hence\": 0,\n",
        "      \"however\": 1,\n",
        "      \"in_contrast\": 1,\n",
        "      \"instead\": 1,\n",
        "      \"likewise\": 0,\n",
        "      \"moreover\": 0,\n",
        "      \"namely\": 0,\n",
        "      \"nevertheless\": 1,\n",
        "      \"nonetheless\": 1,\n",
        "      \"on_the_contrary\": 1,\n",
        "      \"on_the_other_hand\": 1,\n",
        "      \"otherwise\": 0,\n",
        "      \"rather\": 1,\n",
        "      \"similarly\": 0,\n",
        "      \"so\": 0,\n",
        "      \"still\": 1,\n",
        "      \"then\": 0,\n",
        "      \"therefore\": 0,\n",
        "      \"though\": 1,\n",
        "      \"thus\": 0,\n",
        "      \"well\": 0,\n",
        "      \"yet\": 1\n",
        "    }\"\"\"\n",
        "\n",
        "    self.id_to_word = {\n",
        "      0: 'no-conn',\n",
        "      1: 'absolutely',\n",
        "      2: 'accordingly',\n",
        "      3: 'actually',\n",
        "      4: 'additionally',\n",
        "      5: 'admittedly',\n",
        "      6: 'afterward',\n",
        "      7: 'again',\n",
        "      8: 'already',\n",
        "      9: 'also',\n",
        "      10: 'alternately',\n",
        "      11: 'alternatively',\n",
        "      12: 'although',\n",
        "      13: 'altogether',\n",
        "      14: 'amazingly',\n",
        "      15: 'and',\n",
        "      16: 'anyway',\n",
        "      17: 'apparently',\n",
        "      18: 'arguably',\n",
        "      19: 'as_a_result',\n",
        "      20: 'basically',\n",
        "      21: 'because_of_that',\n",
        "      22: 'because_of_this',\n",
        "      23: 'besides',\n",
        "      24: 'but',\n",
        "      25: 'by_comparison',\n",
        "      26: 'by_contrast',\n",
        "      27: 'by_doing_this',\n",
        "      28: 'by_then',\n",
        "      29: 'certainly',\n",
        "      30: 'clearly',\n",
        "      31: 'coincidentally',\n",
        "      32: 'collectively',\n",
        "      33: 'consequently',\n",
        "      34: 'conversely',\n",
        "      35: 'curiously',\n",
        "      36: 'currently',\n",
        "      37: 'elsewhere',\n",
        "      38: 'especially',\n",
        "      39: 'essentially',\n",
        "      40: 'eventually',\n",
        "      41: 'evidently',\n",
        "      42: 'finally',\n",
        "      43: 'first',\n",
        "      44: 'firstly',\n",
        "      45: 'for_example',\n",
        "      46: 'for_instance',\n",
        "      47: 'fortunately',\n",
        "      48: 'frankly',\n",
        "      49: 'frequently',\n",
        "      50: 'further',\n",
        "      51: 'furthermore',\n",
        "      52: 'generally',\n",
        "      53: 'gradually',\n",
        "      54: 'happily',\n",
        "      55: 'hence',\n",
        "      56: 'here',\n",
        "      57: 'historically',\n",
        "      58: 'honestly',\n",
        "      59: 'hopefully',\n",
        "      60: 'however',\n",
        "      61: 'ideally',\n",
        "      62: 'immediately',\n",
        "      63: 'importantly',\n",
        "      64: 'in_contrast',\n",
        "      65: 'in_fact',\n",
        "      66: 'in_other_words',\n",
        "      67: 'in_particular',\n",
        "      68: 'in_short',\n",
        "      69: 'in_sum',\n",
        "      70: 'in_the_end',\n",
        "      71: 'in_the_meantime',\n",
        "      72: 'in_turn',\n",
        "      73: 'incidentally',\n",
        "      74: 'increasingly',\n",
        "      75: 'indeed',\n",
        "      76: 'inevitably',\n",
        "      77: 'initially',\n",
        "      78: 'instead',\n",
        "      79: 'interestingly',\n",
        "      80: 'ironically',\n",
        "      81: 'lastly',\n",
        "      82: 'lately',\n",
        "      83: 'later',\n",
        "      84: 'likewise',\n",
        "      85: 'locally',\n",
        "      86: 'luckily',\n",
        "      87: 'maybe',\n",
        "      88: 'meaning',\n",
        "      89: 'meantime',\n",
        "      90: 'meanwhile',\n",
        "      91: 'moreover',\n",
        "      92: 'mostly',\n",
        "      93: 'namely',\n",
        "      94: 'nationally',\n",
        "      95: 'naturally',\n",
        "      96: 'nevertheless',\n",
        "      97: 'next',\n",
        "      98: 'nonetheless',\n",
        "      99: 'normally',\n",
        "      100: 'notably',\n",
        "      101: 'now',\n",
        "      102: 'obviously',\n",
        "      103: 'occasionally',\n",
        "      104: 'oddly',\n",
        "      105: 'often',\n",
        "      106: 'on_the_contrary',\n",
        "      107: 'on_the_other_hand',\n",
        "      108: 'once',\n",
        "      109: 'only',\n",
        "      110: 'optionally',\n",
        "      111: 'or',\n",
        "      112: 'originally',\n",
        "      113: 'otherwise',\n",
        "      114: 'overall',\n",
        "      115: 'particularly',\n",
        "      116: 'perhaps',\n",
        "      117: 'personally',\n",
        "      118: 'plus',\n",
        "      119: 'preferably',\n",
        "      120: 'presently',\n",
        "      121: 'presumably',\n",
        "      122: 'previously',\n",
        "      123: 'probably',\n",
        "      124: 'rather',\n",
        "      125: 'realistically',\n",
        "      126: 'really',\n",
        "      127: 'recently',\n",
        "      128: 'regardless',\n",
        "      129: 'remarkably',\n",
        "      130: 'sadly',\n",
        "      131: 'second',\n",
        "      132: 'secondly',\n",
        "      133: 'separately',\n",
        "      134: 'seriously',\n",
        "      135: 'significantly',\n",
        "      136: 'similarly',\n",
        "      137: 'simultaneously',\n",
        "      138: 'slowly',\n",
        "      139: 'so',\n",
        "      140: 'sometimes',\n",
        "      141: 'soon',\n",
        "      142: 'specifically',\n",
        "      143: 'still',\n",
        "      144: 'strangely',\n",
        "      145: 'subsequently',\n",
        "      146: 'suddenly',\n",
        "      147: 'supposedly',\n",
        "      148: 'surely',\n",
        "      149: 'surprisingly',\n",
        "      150: 'technically',\n",
        "      151: 'thankfully',\n",
        "      152: 'then',\n",
        "      153: 'theoretically',\n",
        "      154: 'thereafter',\n",
        "      155: 'thereby',\n",
        "      156: 'therefore',\n",
        "      157: 'third',\n",
        "      158: 'thirdly',\n",
        "      159: 'this',\n",
        "      160: 'though',\n",
        "      161: 'thus',\n",
        "      162: 'together',\n",
        "      163: 'traditionally',\n",
        "      164: 'truly',\n",
        "      165: 'truthfully',\n",
        "      166: 'typically',\n",
        "      167: 'ultimately',\n",
        "      168: 'undoubtedly',\n",
        "      169: 'unfortunately',\n",
        "      170: 'unsurprisingly',\n",
        "      171: 'usually',\n",
        "      172: 'well',\n",
        "      173: 'yet'\n",
        "    }\n",
        "\n",
        "\n",
        "  def process_dataset(self, dataset, name=\"train\"):\n",
        "    result = []\n",
        "    new_dataset = []\n",
        "\n",
        "    for sample in dataset:\n",
        "      if self.id_to_word[sample[\"label\"]] not in self.mapping.keys():\n",
        "        continue\n",
        "\n",
        "      new_dataset.append([sample[\"sentence1\"], sample[\"sentence2\"], self.mapping[self.id_to_word[sample[\"label\"]]]])\n",
        "\n",
        "    one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "    labels = []\n",
        "\n",
        "    for i, sample in tqdm(enumerate(new_dataset), desc=\"processing labels...\"):\n",
        "      labels.append([sample[-1]])\n",
        "\n",
        "    print(\"one hot encoding...\")\n",
        "    labels = one_hot_encoder.fit_transform(labels)\n",
        "\n",
        "    for i, (sample, label) in tqdm(enumerate(zip(new_dataset, labels)), desc=\"creating results...\"):\n",
        "      result.append([f\"{name}_{i}\", sample[0], sample[1], [], [], [], label])\n",
        "\n",
        "    examples = self._get_examples_concatenated(result, name)\n",
        "    return examples\n",
        "\n",
        "\n",
        "class StudentEssayProcessor(DataProcessor):\n",
        "\n",
        "  def __init__(self,):\n",
        "    super(StudentEssayProcessor,self).__init__()\n",
        "\n",
        "  def padding(self, input, maxlen):\n",
        "      \"\"\"\n",
        "      Padding the input sequence\n",
        "      \"\"\"\n",
        "\n",
        "      id, sentences, target, source_sentiment, target_sentiment, knowledge, label_distribution = zip(*input)\n",
        "\n",
        "      sentences = torch.nn.utils.rnn.pad_sequence([torch.tensor(s) for s in sentences], batch_first=True, padding_value=0)\n",
        "      knowledge = torch.nn.utils.rnn.pad_sequence([torch.tensor(k) for k in knowledge], batch_first=True, padding_value=0)\n",
        "      target = torch.nn.utils.rnn.pad_sequence([torch.tensor(t) for t in target], batch_first=True, padding_value=0)\n",
        "\n",
        "      return list(zip(sentences, knowledge, target, label_distribution))\n",
        "\n",
        "\n",
        "  def create_batches_of_sentence_ids(self, sentences, batch_equal_size, max_batch_size):\n",
        "      \"\"\"\n",
        "      Groups together sentences into batches\n",
        "      If max_batch_size is positive, this value determines the maximum number of sentences in each batch.\n",
        "      If max_batch_size has a negative value, the function dynamically creates the batches such that each batch contains abs(max_batch_size) words.\n",
        "      Returns a list of lists with sentences ids.\n",
        "      \"\"\"\n",
        "      batches_of_sentence_ids = []\n",
        "      if batch_equal_size == True:\n",
        "          sentence_ids_by_length = collections.OrderedDict()\n",
        "          sentence_length_sum = 0.0\n",
        "          for i in range(len(sentences)):\n",
        "              length = len(sentences[i])\n",
        "              if length not in sentence_ids_by_length:\n",
        "                  sentence_ids_by_length[length] = []\n",
        "              sentence_ids_by_length[length].append(i)\n",
        "\n",
        "          for sentence_length in sentence_ids_by_length:\n",
        "              if max_batch_size > 0:\n",
        "                  batch_size = max_batch_size\n",
        "              else:\n",
        "                  batch_size = int((-1 * max_batch_size) / sentence_length)\n",
        "\n",
        "              for i in range(0, len(sentence_ids_by_length[sentence_length]), batch_size):\n",
        "                  batches_of_sentence_ids.append(sentence_ids_by_length[sentence_length][i:i + batch_size])\n",
        "      else:\n",
        "          current_batch = []\n",
        "          max_sentence_length = 0\n",
        "          for i in range(len(sentences)):\n",
        "              current_batch.append(i)\n",
        "              if len(sentences[i]) > max_sentence_length:\n",
        "                  max_sentence_length = len(sentences[i])\n",
        "              if (max_batch_size > 0 and len(current_batch) >= max_batch_size) \\\n",
        "                or (max_batch_size <= 0 and len(current_batch)*max_sentence_length >= (-1 * max_batch_size)):\n",
        "                  batches_of_sentence_ids.append(current_batch)\n",
        "                  current_batch = []\n",
        "                  max_sentence_length = 0\n",
        "          if len(current_batch) > 0:\n",
        "              batches_of_sentence_ids.append(current_batch)\n",
        "      return batches_of_sentence_ids\n",
        "\n",
        "\n",
        "  def read_input_files(self, file_path, max_sentence_length=-1, name=\"train\"):\n",
        "      \"\"\"\n",
        "      Reads input files in tab-separated format.\n",
        "      Will split file_paths on comma, reading from multiple files.\n",
        "      \"\"\"\n",
        "\n",
        "      # Code copied from https://aclanthology.org/2023.eacl-main.182.pdf\n",
        "      # TODO: refactor, several objects are not needed\n",
        "\n",
        "      sentences = []\n",
        "      labels = []\n",
        "      label_distribution=[]\n",
        "      target = []\n",
        "      knowledge = []\n",
        "      story_id_know=[]\n",
        "      lst2=[]\n",
        "      target_sentences = []\n",
        "      source_senti = []\n",
        "      target_senti = []\n",
        "      id=[]\n",
        "      count = 0\n",
        "\n",
        "      with codecs.open(file_path, encoding=\"ISO-8859-1\", mode=\"r\") as f:\n",
        "        for line in f:\n",
        "              know =[]\n",
        "              #print(line)\n",
        "              count +=1\n",
        "              #print(count)\n",
        "              line = line.replace(\"\\n\",\"\")\n",
        "              line = line.split(\"\\t\")\n",
        "\n",
        "              if line == ['\\r']:\n",
        "                      continue\n",
        "              count +=1\n",
        "              story_id = line[0]\n",
        "              sent = line[1].strip()\n",
        "              target = line[3].strip()\n",
        "              #print(target)\n",
        "              label = line[-1].strip()\n",
        "              facts = line[-2].strip()\n",
        "\n",
        "              facts = facts.replace(\"_\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"(\", \"\").replace(\"(\", \"\")\n",
        "\n",
        "              lst2.append(facts)\n",
        "\n",
        "              sentences.append(sent)\n",
        "              target_sentences.append(target)\n",
        "              id.append(story_id)\n",
        "\n",
        "              l=[0,0]\n",
        "              if label == 'supports' or label == 'support' or label == 'because':\n",
        "                    l=[1,0]\n",
        "              elif label == 'attacks' or label == 'attack' or label == 'but':\n",
        "                    l=[0,1]\n",
        "              label_distribution.append(l)\n",
        "\n",
        "      result = []\n",
        "      for i in range(len(label_distribution)):\n",
        "        result.append([id[i],sentences[i],target_sentences[i], [], [], lst2[i], label_distribution[i]])\n",
        "\n",
        "      examples = self._get_examples_concatenated(result, name)\n",
        "\n",
        "      return examples\n",
        "\n",
        "class DebateProcessor(DataProcessor):\n",
        "\n",
        "  def __init__(self,):\n",
        "    super(DebateProcessor,self).__init__()\n",
        "\n",
        "  def padding(self, input, maxlen):\n",
        "      \"\"\"\n",
        "      Padding the input sequence.....\n",
        "      \"\"\"\n",
        "\n",
        "      id, sentences, target, source_sentiment, target_sentiment, knowledge, label_distribution = zip(*input)\n",
        "\n",
        "      sentences = torch.nn.utils.rnn.pad_sequence([torch.tensor(s) for s in sentences], batch_first=True, padding_value=0)\n",
        "      knowledge = torch.nn.utils.rnn.pad_sequence([torch.tensor(k) for k in knowledge], batch_first=True, padding_value=0)\n",
        "      target = torch.nn.utils.rnn.pad_sequence([torch.tensor(t) for t in target], batch_first=True, padding_value=0)\n",
        "\n",
        "      return list(zip(sentences, knowledge, target, label_distribution))\n",
        "\n",
        "\n",
        "  def create_batches_of_sentence_ids(self, sentences, batch_equal_size, max_batch_size):\n",
        "      \"\"\"\n",
        "      Groups together sentences into batches\n",
        "      If max_batch_size is positive, this value determines the maximum number of sentences in each batch.\n",
        "      If max_batch_size has a negative value, the function dynamically creates the batches such that each batch contains abs(max_batch_size) words.\n",
        "      Returns a list of lists with sentences ids.\n",
        "      \"\"\"\n",
        "      batches_of_sentence_ids = []\n",
        "      if batch_equal_size == True:\n",
        "          sentence_ids_by_length = collections.OrderedDict()\n",
        "          sentence_length_sum = 0.0\n",
        "          for i in range(len(sentences)):\n",
        "              length = len(sentences[i])\n",
        "              if length not in sentence_ids_by_length:\n",
        "                  sentence_ids_by_length[length] = []\n",
        "              sentence_ids_by_length[length].append(i)\n",
        "\n",
        "          for sentence_length in sentence_ids_by_length:\n",
        "              if max_batch_size > 0:\n",
        "                  batch_size = max_batch_size\n",
        "              else:\n",
        "                  batch_size = int((-1 * max_batch_size) / sentence_length)\n",
        "\n",
        "              for i in range(0, len(sentence_ids_by_length[sentence_length]), batch_size):\n",
        "                  batches_of_sentence_ids.append(sentence_ids_by_length[sentence_length][i:i + batch_size])\n",
        "      else:\n",
        "          current_batch = []\n",
        "          max_sentence_length = 0\n",
        "          for i in range(len(sentences)):\n",
        "              current_batch.append(i)\n",
        "              if len(sentences[i]) > max_sentence_length:\n",
        "                  max_sentence_length = len(sentences[i])\n",
        "              if (max_batch_size > 0 and len(current_batch) >= max_batch_size) \\\n",
        "                or (max_batch_size <= 0 and len(current_batch)*max_sentence_length >= (-1 * max_batch_size)):\n",
        "                  batches_of_sentence_ids.append(current_batch)\n",
        "                  current_batch = []\n",
        "                  max_sentence_length = 0\n",
        "          if len(current_batch) > 0:\n",
        "              batches_of_sentence_ids.append(current_batch)\n",
        "      return batches_of_sentence_ids\n",
        "\n",
        "\n",
        "  def read_input_files(self, file_path, max_sentence_length=-1, name=\"train\"):\n",
        "      \"\"\"\n",
        "      Reads input files in tab-separated format.\n",
        "      Will split file_paths on comma, reading from multiple files.\n",
        "      \"\"\"\n",
        "      sentences = []\n",
        "      labels = []\n",
        "      label_distribution=[]\n",
        "      target = []\n",
        "      knowledge = []\n",
        "      story_id_know=[]\n",
        "      lst2=[]\n",
        "      target_sentences = []\n",
        "      source_senti = []\n",
        "      target_senti = []\n",
        "      id=[]\n",
        "      count = 0\n",
        "\n",
        "      with codecs.open(file_path, encoding=\"ISO-8859-1\", mode=\"r\") as f:\n",
        "        for line in f:\n",
        "              know =[]\n",
        "              #print(line)\n",
        "              count +=1\n",
        "              #print(count)\n",
        "              line = line.replace(\"\\n\",\"\")\n",
        "              line = line.split(\"\\t\")\n",
        "\n",
        "              if line == ['\\r']:\n",
        "                      continue\n",
        "              count +=1\n",
        "              story_id = line[0]\n",
        "              sent = line[1].strip()\n",
        "              target = line[3].strip()\n",
        "              #print(target)\n",
        "              label = line[-1].strip()\n",
        "              facts = line[-2].strip()\n",
        "\n",
        "              facts = facts.replace(\"_\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"(\", \"\").replace(\"(\", \"\")\n",
        "\n",
        "              lst2.append(facts)\n",
        "\n",
        "              sentences.append(sent)\n",
        "              target_sentences.append(target)\n",
        "              id.append(story_id)\n",
        "\n",
        "              l=[0,0]\n",
        "              if label == 'supports' or label == 'support' or label == 'because':\n",
        "                    l=[1,0]\n",
        "              elif label == 'attacks' or label == 'attack' or label == 'but':\n",
        "                    l=[0,1]\n",
        "              label_distribution.append(l)\n",
        "              #print(label_distribution)\n",
        "\n",
        "      result = []\n",
        "      for i in range(len(label_distribution)):\n",
        "        result.append([id[i],sentences[i],target_sentences[i], [], [], lst2[i], label_distribution[i]])\n",
        "\n",
        "      examples = self._get_examples_concatenated(result, name)\n",
        "\n",
        "      return examples\n",
        "\n",
        "\n",
        "class MARGProcessor(DataProcessor):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MARGProcessor, self).__init__()\n",
        "    self.pipe = pipeline(\"text-classification\", model=\"sileod/roberta-base-discourse-marker-prediction\")\n",
        "\n",
        "  def read_input_files(self, file_path, max_sent_length=-1, name=\"train\"):\n",
        "      \"\"\"\n",
        "      Reads input files in tab-separated format.\n",
        "      Will split file_paths on comma, reading from multiple files.\n",
        "      \"\"\"\n",
        "\n",
        "      # Code copied from https://aclanthology.org/2023.eacl-main.182.pdf\n",
        "      # TODO: refactor, several objects are not needed\n",
        "\n",
        "      sentences = []\n",
        "      labels = []\n",
        "      label_distribution=[]\n",
        "      target = []\n",
        "      knowledge = []\n",
        "      story_id_know=[]\n",
        "      lst2=[]\n",
        "      target_sentences = []\n",
        "      source_senti = []\n",
        "      target_senti = []\n",
        "      id=[]\n",
        "      count = 0\n",
        "\n",
        "      df = pd.read_csv(file_path)\n",
        "      for i,row in df.iterrows():\n",
        "              if row[-1] != name:\n",
        "                continue\n",
        "              know =[]\n",
        "              #print(line)\n",
        "              count +=1\n",
        "              #print(count)\n",
        "\n",
        "              count +=1\n",
        "              story_id = row[0]\n",
        "              sent = row[1].strip()\n",
        "              target = row[2].strip()\n",
        "\n",
        "              ds_marker = self.pipe(f\"{sent}</s></s>{target}\")[0][\"label\"]\n",
        "              ds_marker = ds_marker.replace(\"_\", \" \")\n",
        "              ds_marker = ds_marker[0].upper() + ds_marker[1:]\n",
        "              target = target[0].lower() + target[1:]\n",
        "              target = ds_marker + \" \" + target\n",
        "\n",
        "              #print(target)\n",
        "              label = row[3].strip()\n",
        "              facts = row[-3].strip()\n",
        "\n",
        "              facts = facts.replace(\"_\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"(\", \"\").replace(\"(\", \"\")\n",
        "\n",
        "              lst2.append(facts)\n",
        "\n",
        "              sentences.append(sent)\n",
        "              target_sentences.append(target)\n",
        "              id.append(story_id)\n",
        "\n",
        "              l=[0,0,0]\n",
        "              if label == 'supports' or label == 'support' or label == 'because':\n",
        "                l = [1,0,0]\n",
        "              elif label == 'attacks' or label == 'attack' or label == 'but':\n",
        "                l = [0,1,0]\n",
        "              elif label == 'neither':\n",
        "                l = [0,0,1]\n",
        "\n",
        "              label_distribution.append(l)\n",
        "\n",
        "      result = []\n",
        "      for i in range(len(label_distribution)):\n",
        "        result.append([id[i],sentences[i],target_sentences[i], [], [], lst2[i], label_distribution[i]])\n",
        "\n",
        "      examples = self._get_examples_concatenated(result, name)\n",
        "\n",
        "      return examples\n",
        "\n",
        "class NKProcessor(DataProcessor):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(NKProcessor, self).__init__()\n",
        "\n",
        "  def read_input_files(self, file_path, max_sent_length=-1, name=\"train\"):\n",
        "      \"\"\"\n",
        "      Reads input files in tab-separated format.\n",
        "      Will split file_paths on comma, reading from multiple files.\n",
        "      \"\"\"\n",
        "\n",
        "      sentences = []\n",
        "      label_distribution=[]\n",
        "      target = []\n",
        "      target_sentences = []\n",
        "      id=[]\n",
        "\n",
        "      df = pd.read_csv(file_path, sep=\"\\t\")\n",
        "      for i,row in df.iterrows():\n",
        "              id_sample = row[0]\n",
        "              label = row[2]\n",
        "\n",
        "              sent = row[3].strip()\n",
        "              target = row[4].strip()\n",
        "\n",
        "              sentences.append(sent)\n",
        "              target_sentences.append(target)\n",
        "              id.append(id_sample)\n",
        "\n",
        "              l=[0,0,0]\n",
        "              if label == 'supports' or label == 'support' or label == 'because':\n",
        "                l = [1,0,0]\n",
        "              elif label == 'attacks' or label == 'attack' or label == 'but':\n",
        "                l = [0,1,0]\n",
        "              elif label == 'no_relation':\n",
        "                l = [0,0,1]\n",
        "\n",
        "              label_distribution.append(l)\n",
        "\n",
        "      result = []\n",
        "      for i in range(len(label_distribution)):\n",
        "        result.append([id[i],sentences[i],target_sentences[i], [], [], [], label_distribution[i]])\n",
        "\n",
        "      examples = self._get_examples_concatenated(result, name)\n",
        "\n",
        "      return examples\n",
        "\n",
        "class StudentEssayWithDiscourseInjectionProcessor(DataProcessor):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(StudentEssayWithDiscourseInjectionProcessor, self).__init__()\n",
        "    self.pipe = pipeline(\"text-classification\", model=\"sileod/roberta-base-discourse-marker-prediction\")\n",
        "\n",
        "  def padding(self, input, maxlen):\n",
        "      \"\"\"\n",
        "      Padding the input sequence\n",
        "      \"\"\"\n",
        "\n",
        "      id, sentences, target, source_sentiment, target_sentiment, knowledge, label_distribution = zip(*input)\n",
        "\n",
        "      sentences = torch.nn.utils.rnn.pad_sequence([torch.tensor(s) for s in sentences], batch_first=True, padding_value=0)\n",
        "      knowledge = torch.nn.utils.rnn.pad_sequence([torch.tensor(k) for k in knowledge], batch_first=True, padding_value=0)\n",
        "      target = torch.nn.utils.rnn.pad_sequence([torch.tensor(t) for t in target], batch_first=True, padding_value=0)\n",
        "\n",
        "      return list(zip(sentences, knowledge, target, label_distribution))\n",
        "\n",
        "\n",
        "  def create_batches_of_sentence_ids(self, sentences, batch_equal_size, max_batch_size):\n",
        "      \"\"\"\n",
        "      Groups together sentences into batches\n",
        "      If max_batch_size is positive, this value determines the maximum number of sentences in each batch.\n",
        "      If max_batch_size has a negative value, the function dynamically creates the batches such that each batch contains abs(max_batch_size) words.\n",
        "      Returns a list of lists with sentences ids.\n",
        "      \"\"\"\n",
        "      batches_of_sentence_ids = []\n",
        "      if batch_equal_size == True:\n",
        "          sentence_ids_by_length = collections.OrderedDict()\n",
        "          sentence_length_sum = 0.0\n",
        "          for i in range(len(sentences)):\n",
        "              length = len(sentences[i])\n",
        "              if length not in sentence_ids_by_length:\n",
        "                  sentence_ids_by_length[length] = []\n",
        "              sentence_ids_by_length[length].append(i)\n",
        "\n",
        "          for sentence_length in sentence_ids_by_length:\n",
        "              if max_batch_size > 0:\n",
        "                  batch_size = max_batch_size\n",
        "              else:\n",
        "                  batch_size = int((-1 * max_batch_size) / sentence_length)\n",
        "\n",
        "              for i in range(0, len(sentence_ids_by_length[sentence_length]), batch_size):\n",
        "                  batches_of_sentence_ids.append(sentence_ids_by_length[sentence_length][i:i + batch_size])\n",
        "      else:\n",
        "          current_batch = []\n",
        "          max_sentence_length = 0\n",
        "          for i in range(len(sentences)):\n",
        "              current_batch.append(i)\n",
        "              if len(sentences[i]) > max_sentence_length:\n",
        "                  max_sentence_length = len(sentences[i])\n",
        "              if (max_batch_size > 0 and len(current_batch) >= max_batch_size) \\\n",
        "                or (max_batch_size <= 0 and len(current_batch)*max_sentence_length >= (-1 * max_batch_size)):\n",
        "                  batches_of_sentence_ids.append(current_batch)\n",
        "                  current_batch = []\n",
        "                  max_sentence_length = 0\n",
        "          if len(current_batch) > 0:\n",
        "              batches_of_sentence_ids.append(current_batch)\n",
        "      return batches_of_sentence_ids\n",
        "\n",
        "\n",
        "  def read_input_files(self, file_path, max_sentence_length=-1, name=\"train\"):\n",
        "      \"\"\"\n",
        "      Reads input files in tab-separated format.\n",
        "      Will split file_paths on comma, reading from multiple files.\n",
        "      \"\"\"\n",
        "\n",
        "      # Code copied from https://aclanthology.org/2023.eacl-main.182.pdf\n",
        "      # TODO: refactor, several objects are not needed\n",
        "\n",
        "      sentences = []\n",
        "      labels = []\n",
        "      label_distribution=[]\n",
        "      target = []\n",
        "      knowledge = []\n",
        "      story_id_know=[]\n",
        "      lst2=[]\n",
        "      target_sentences = []\n",
        "      source_senti = []\n",
        "      target_senti = []\n",
        "      id=[]\n",
        "      count = 0\n",
        "\n",
        "      with codecs.open(file_path, encoding=\"ISO-8859-1\", mode=\"r\") as f:\n",
        "        for line in f:\n",
        "              know =[]\n",
        "              #print(line)\n",
        "              count +=1\n",
        "              #print(count)\n",
        "              line = line.replace(\"\\n\",\"\")\n",
        "              line = line.split(\"\\t\")\n",
        "\n",
        "              if line == ['\\r']:\n",
        "                      continue\n",
        "              count +=1\n",
        "              story_id = line[0]\n",
        "              sent = line[1].strip()\n",
        "              target = line[3].strip()\n",
        "              ds_marker = self.pipe(f\"{sent}</s></s>{target}\")[0][\"label\"]\n",
        "              ds_marker = ds_marker.replace(\"_\", \" \")\n",
        "              ds_marker = ds_marker[0].upper() + ds_marker[1:]\n",
        "              target = target[0].lower() + target[1:]\n",
        "              target = ds_marker + \" \" + target\n",
        "              #print(target)\n",
        "              label = line[-1].strip()\n",
        "              facts = line[-2].strip()\n",
        "\n",
        "              facts = facts.replace(\"_\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"(\", \"\").replace(\"(\", \"\")\n",
        "\n",
        "              lst2.append(facts)\n",
        "\n",
        "              sentences.append(sent)\n",
        "              target_sentences.append(target)\n",
        "              id.append(story_id)\n",
        "\n",
        "              l=[0,0]\n",
        "              if label == 'supports' or label == 'support' or label == 'because':\n",
        "                    l=[1,0]\n",
        "              elif label == 'attacks' or label == 'attack' or label == 'but':\n",
        "                    l=[0,1]\n",
        "              label_distribution.append(l)\n",
        "\n",
        "      result = []\n",
        "      for i in range(len(label_distribution)):\n",
        "        result.append([id[i],sentences[i],target_sentences[i], [], [], lst2[i], label_distribution[i]])\n",
        "\n",
        "      examples = self._get_examples_concatenated(result, name)\n",
        "\n",
        "      return examples\n",
        "\n",
        "\n",
        "class DebateWithDiscourseInjectionProcessor(DataProcessor):\n",
        "\n",
        "  def __init__(self,):\n",
        "    super(DebateWithDiscourseInjectionProcessor,self).__init__()\n",
        "    self.pipe = pipeline(\"text-classification\", model=\"sileod/roberta-base-discourse-marker-prediction\")\n",
        "\n",
        "  def padding(self, input, maxlen):\n",
        "      \"\"\"\n",
        "      Padding the input sequence.....\n",
        "      \"\"\"\n",
        "\n",
        "      id, sentences, target, source_sentiment, target_sentiment, knowledge, label_distribution = zip(*input)\n",
        "\n",
        "      sentences = torch.nn.utils.rnn.pad_sequence([torch.tensor(s) for s in sentences], batch_first=True, padding_value=0)\n",
        "      knowledge = torch.nn.utils.rnn.pad_sequence([torch.tensor(k) for k in knowledge], batch_first=True, padding_value=0)\n",
        "      target = torch.nn.utils.rnn.pad_sequence([torch.tensor(t) for t in target], batch_first=True, padding_value=0)\n",
        "\n",
        "      return list(zip(sentences, knowledge, target, label_distribution))\n",
        "\n",
        "\n",
        "  def create_batches_of_sentence_ids(self, sentences, batch_equal_size, max_batch_size):\n",
        "      \"\"\"\n",
        "      Groups together sentences into batches\n",
        "      If max_batch_size is positive, this value determines the maximum number of sentences in each batch.\n",
        "      If max_batch_size has a negative value, the function dynamically creates the batches such that each batch contains abs(max_batch_size) words.\n",
        "      Returns a list of lists with sentences ids.\n",
        "      \"\"\"\n",
        "      batches_of_sentence_ids = []\n",
        "      if batch_equal_size == True:\n",
        "          sentence_ids_by_length = collections.OrderedDict()\n",
        "          sentence_length_sum = 0.0\n",
        "          for i in range(len(sentences)):\n",
        "              length = len(sentences[i])\n",
        "              if length not in sentence_ids_by_length:\n",
        "                  sentence_ids_by_length[length] = []\n",
        "              sentence_ids_by_length[length].append(i)\n",
        "\n",
        "          for sentence_length in sentence_ids_by_length:\n",
        "              if max_batch_size > 0:\n",
        "                  batch_size = max_batch_size\n",
        "              else:\n",
        "                  batch_size = int((-1 * max_batch_size) / sentence_length)\n",
        "\n",
        "              for i in range(0, len(sentence_ids_by_length[sentence_length]), batch_size):\n",
        "                  batches_of_sentence_ids.append(sentence_ids_by_length[sentence_length][i:i + batch_size])\n",
        "      else:\n",
        "          current_batch = []\n",
        "          max_sentence_length = 0\n",
        "          for i in range(len(sentences)):\n",
        "              current_batch.append(i)\n",
        "              if len(sentences[i]) > max_sentence_length:\n",
        "                  max_sentence_length = len(sentences[i])\n",
        "              if (max_batch_size > 0 and len(current_batch) >= max_batch_size) \\\n",
        "                or (max_batch_size <= 0 and len(current_batch)*max_sentence_length >= (-1 * max_batch_size)):\n",
        "                  batches_of_sentence_ids.append(current_batch)\n",
        "                  current_batch = []\n",
        "                  max_sentence_length = 0\n",
        "          if len(current_batch) > 0:\n",
        "              batches_of_sentence_ids.append(current_batch)\n",
        "      return batches_of_sentence_ids\n",
        "\n",
        "\n",
        "  def read_input_files(self, file_path, max_sentence_length=-1, name=\"train\"):\n",
        "      \"\"\"\n",
        "      Reads input files in tab-separated format.\n",
        "      Will split file_paths on comma, reading from multiple files.\n",
        "      \"\"\"\n",
        "      sentences = []\n",
        "      labels = []\n",
        "      label_distribution=[]\n",
        "      target = []\n",
        "      knowledge = []\n",
        "      story_id_know=[]\n",
        "      lst2=[]\n",
        "      target_sentences = []\n",
        "      source_senti = []\n",
        "      target_senti = []\n",
        "      id=[]\n",
        "      count = 0\n",
        "\n",
        "      with codecs.open(file_path, encoding=\"ISO-8859-1\", mode=\"r\") as f:\n",
        "        for line in f:\n",
        "              know =[]\n",
        "              #print(line)\n",
        "              count +=1\n",
        "              #print(count)\n",
        "              line = line.replace(\"\\n\",\"\")\n",
        "              line = line.split(\"\\t\")\n",
        "\n",
        "              if line == ['\\r']:\n",
        "                      continue\n",
        "              count +=1\n",
        "              story_id = line[0]\n",
        "              sent = line[1].strip()\n",
        "              target = line[3].strip()\n",
        "              ds_marker = self.pipe(f\"{sent}</s></s>{target}\")[0][\"label\"]\n",
        "              ds_marker = ds_marker.replace(\"_\", \" \")\n",
        "              ds_marker = ds_marker[0].upper() + ds_marker[1:]\n",
        "              target = target[0].lower() + target[1:]\n",
        "              target = ds_marker + \" \" + target\n",
        "              #print(target)\n",
        "              label = line[-1].strip()\n",
        "              facts = line[-2].strip()\n",
        "\n",
        "              facts = facts.replace(\"_\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"(\", \"\").replace(\"(\", \"\")\n",
        "\n",
        "              lst2.append(facts)\n",
        "\n",
        "              sentences.append(sent)\n",
        "              target_sentences.append(target)\n",
        "              id.append(story_id)\n",
        "\n",
        "              l=[0,0]\n",
        "              if label == 'supports' or label == 'support' or label == 'because':\n",
        "                    l=[1,0]\n",
        "              elif label == 'attacks' or label == 'attack' or label == 'but':\n",
        "                    l=[0,1]\n",
        "              label_distribution.append(l)\n",
        "              #print(label_distribution)\n",
        "\n",
        "      result = []\n",
        "      for i in range(len(label_distribution)):\n",
        "        result.append([id[i],sentences[i],target_sentences[i], [], [], lst2[i], label_distribution[i]])\n",
        "\n",
        "      examples = self._get_examples_concatenated(result, name)\n",
        "\n",
        "      return examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ArK77n3-_k82"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "from torch import nn\n",
        "\n",
        "class GRLayer(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, lmbd=0.01):\n",
        "        ctx.lmbd = torch.tensor(lmbd)\n",
        "        return x.reshape_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        grad_input = grad_output.clone()\n",
        "        return ctx.lmbd * grad_input.neg(), None\n",
        "\n",
        "class DoubleAdversarialNet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DoubleAdversarialNet, self).__init__()\n",
        "\n",
        "    self.plm = AutoModel.from_pretrained(args[\"model_name\"])\n",
        "    config = self.plm.config\n",
        "    config.type_vocab_size = 4\n",
        "    self.plm.embeddings.token_type_embeddings = nn.Embedding(\n",
        "      config.type_vocab_size, config.hidden_size\n",
        "    )\n",
        "    self.plm._init_weights(self.plm.embeddings.token_type_embeddings)\n",
        "\n",
        "    self.num_classes = args[\"num_classes\"]\n",
        "    self.num_classes_adv = args[\"num_classes_adv\"]\n",
        "    self.embed_size = args[\"embed_size\"]\n",
        "\n",
        "    self.first_last_avg = args[\"first_last_avg\"]\n",
        "\n",
        "    for param in self.plm.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    self.linear_layer = torch.nn.Linear(in_features=self.embed_size, out_features=self.num_classes)\n",
        "    self.linear_layer_adv = torch.nn.Linear(in_features=self.embed_size, out_features=self.num_classes_adv)\n",
        "    self.task_linear = torch.nn.Linear(in_features=self.embed_size, out_features=self.num_classes)\n",
        "    self.attack_linear = torch.nn.Linear(in_features=self.embed_size, out_features=self.num_classes)\n",
        "    self.support_linear = torch.nn.Linear(in_features=self.embed_size, out_features=self.num_classes)\n",
        "\n",
        "    self.multi_head_att = torch.nn.MultiheadAttention(self.embed_size, 8, batch_first=True)\n",
        "    self.Q = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.K = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.V = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "\n",
        "    self._init_weights(self.linear_layer)\n",
        "    self._init_weights(self.linear_layer_adv)\n",
        "    self._init_weights(self.Q)\n",
        "    self._init_weights(self.K)\n",
        "    self._init_weights(self.V)\n",
        "    self._init_weights(self.multi_head_att)\n",
        "    self._init_weights(self.task_linear)\n",
        "    self._init_weights(self.attack_linear)\n",
        "    self._init_weights(self.support_linear)\n",
        "\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "    \"\"\"Initialize the weights\"\"\"\n",
        "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "      module.weight.data.normal_(mean=0.0, std=self.plm.config.initializer_range)\n",
        "    elif isinstance(module, nn.LayerNorm):\n",
        "      module.bias.data.zero_()\n",
        "      module.weight.data.fill_(1.0)\n",
        "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "      module.bias.data.zero_()\n",
        "\n",
        "  @torch.autocast(device_type=\"cuda\")\n",
        "  def forward(self, ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels):\n",
        "    out_sent1 = self.plm(ids_sent1, token_type_ids=segs_sent1, attention_mask=att_mask_sent1, output_hidden_states=True)\n",
        "\n",
        "    last_sent1, first_sent1 = out_sent1.hidden_states[-1], out_sent1.hidden_states[1]\n",
        "\n",
        "    if self.first_last_avg:\n",
        "      embed_sent1 = torch.div((last_sent1 + first_sent1), 2)\n",
        "    else:\n",
        "      embed_sent1 = last_sent1\n",
        "\n",
        "    tar_mask_sent1 = (segs_sent1 == 0).long()\n",
        "    tar_mask_sent2 = (segs_sent1 == 1).long()\n",
        "\n",
        "    H_sent1 = torch.mul(tar_mask_sent1.unsqueeze(2), embed_sent1)\n",
        "    H_sent2 = torch.mul(tar_mask_sent2.unsqueeze(2), embed_sent1)\n",
        "\n",
        "    K_sent1 = self.K(H_sent1)\n",
        "    V_sent1 = self.V(H_sent1)\n",
        "    Q_sent2 = self.Q(H_sent2)\n",
        "\n",
        "    att_output = self.multi_head_att(Q_sent2, K_sent1, V_sent1)\n",
        "\n",
        "    H_sent = torch.mean(att_output[0], dim=1)\n",
        "\n",
        "    if self.training:\n",
        "      batch_size = H_sent.shape[0]\n",
        "      samples = H_sent[:batch_size // 2, :]\n",
        "      labels_std = labels[:batch_size // 2, :]\n",
        "\n",
        "      emb_attack = samples[labels_std == [0,1]]\n",
        "      emb_support = samples[labels_std == [1,0]]\n",
        "\n",
        "      samples_adv = H_sent[batch_size // 2:, ]\n",
        "      labels_adv = labels[batch_size // 2:, :]\n",
        "\n",
        "      emb_caus = samples_adv[labels_adv == [1,0,0]]\n",
        "      emb_other = samples_adv[labels_adv == [0,1,0] or labels_adv == [0,0,1]]\n",
        "\n",
        "      predictions = self.linear_layer(samples)\n",
        "      predictions_adv = self.linear_layer_adv(samples_adv)\n",
        "\n",
        "      mean_grl = GRLayer.apply(torch.mean(embed_sent1, dim=1), .01)\n",
        "      task_prediction = self.task_linear(mean_grl)\n",
        "      attack_prediction = self.attack_linear(mean_grl)\n",
        "      support_prediction = self.support_linear(mean_grl)\n",
        "\n",
        "      return predictions, predictions_adv, task_prediction, attack_prediction, support_prediction\n",
        "    else:\n",
        "      predictions = self.linear_layer(H_sent)\n",
        "\n",
        "      return predictions\n",
        "\n",
        "class AdversarialNet(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(AdversarialNet, self).__init__()\n",
        "\n",
        "    self.plm = AutoModel.from_pretrained(args[\"model_name\"])\n",
        "    config = self.plm.config\n",
        "    config.type_vocab_size = 4\n",
        "    self.plm.embeddings.token_type_embeddings = nn.Embedding(\n",
        "      config.type_vocab_size, config.hidden_size\n",
        "    )\n",
        "    self.plm._init_weights(self.plm.embeddings.token_type_embeddings)\n",
        "\n",
        "    self.num_classes = args[\"num_classes\"]\n",
        "    self.num_classes_adv = args[\"num_classes_adv\"]\n",
        "    self.embed_size = args[\"embed_size\"]\n",
        "\n",
        "    self.first_last_avg = args[\"first_last_avg\"]\n",
        "\n",
        "    for param in self.plm.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    self.linear_layer = torch.nn.Linear(in_features=self.embed_size, out_features=self.num_classes)\n",
        "    self.linear_layer_adv = torch.nn.Linear(in_features=self.embed_size, out_features=self.num_classes_adv)\n",
        "    self.task_linear = torch.nn.Linear(in_features=self.embed_size, out_features=2)\n",
        "\n",
        "    self.multi_head_att = torch.nn.MultiheadAttention(self.embed_size, 8, batch_first=True)\n",
        "    self.Q = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.K = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.V = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "\n",
        "    self._init_weights(self.linear_layer)\n",
        "    self._init_weights(self.linear_layer_adv)\n",
        "    self._init_weights(self.Q)\n",
        "    self._init_weights(self.K)\n",
        "    self._init_weights(self.V)\n",
        "    self._init_weights(self.multi_head_att)\n",
        "    self._init_weights(self.task_linear)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "    \"\"\"Initialize the weights\"\"\"\n",
        "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "      module.weight.data.normal_(mean=0.0, std=self.plm.config.initializer_range)\n",
        "    elif isinstance(module, nn.LayerNorm):\n",
        "      module.bias.data.zero_()\n",
        "      module.weight.data.fill_(1.0)\n",
        "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "      module.bias.data.zero_()\n",
        "\n",
        "  @torch.autocast(device_type=\"cuda\")\n",
        "  def forward(self, ids_sent1, segs_sent1, att_mask_sent1, position_sep, visualize=False):\n",
        "    out_sent1 = self.plm(ids_sent1, token_type_ids=segs_sent1, attention_mask=att_mask_sent1, output_hidden_states=True)\n",
        "\n",
        "    last_sent1, first_sent1 = out_sent1.hidden_states[-1], out_sent1.hidden_states[1]\n",
        "\n",
        "    if self.first_last_avg:\n",
        "      embed_sent1 = torch.div((last_sent1 + first_sent1), 2)\n",
        "    else:\n",
        "      embed_sent1 = last_sent1\n",
        "\n",
        "    tar_mask_sent1 = (segs_sent1 == 0).long()\n",
        "    tar_mask_sent2 = (segs_sent1 == 1).long()\n",
        "\n",
        "    H_sent1 = torch.mul(tar_mask_sent1.unsqueeze(2), embed_sent1)\n",
        "    H_sent2 = torch.mul(tar_mask_sent2.unsqueeze(2), embed_sent1)\n",
        "\n",
        "    K_sent1 = self.K(H_sent1)\n",
        "    V_sent1 = self.V(H_sent1)\n",
        "    Q_sent2 = self.Q(H_sent2)\n",
        "\n",
        "    att_output = self.multi_head_att(Q_sent2, K_sent1, V_sent1)\n",
        "\n",
        "    H_sent = torch.mean(att_output[0], dim=1)\n",
        "\n",
        "    if visualize:\n",
        "      return H_sent\n",
        "    if self.training:\n",
        "      batch_size = H_sent.shape[0]\n",
        "      samples = H_sent[:batch_size // 2, :]\n",
        "      samples_adv = H_sent[batch_size // 2:, ]\n",
        "\n",
        "      predictions = self.linear_layer(samples)\n",
        "      predictions_adv = self.linear_layer_adv(samples_adv)\n",
        "\n",
        "      mean_grl = GRLayer.apply(torch.mean(embed_sent1, dim=1), .01)\n",
        "      task_prediction = self.task_linear(mean_grl)\n",
        "\n",
        "      return predictions, predictions_adv, task_prediction\n",
        "    else:\n",
        "      predictions = self.linear_layer(H_sent)\n",
        "\n",
        "      return predictions\n",
        "\n",
        "class BaselineModelWithSentenceComparisonAndCue(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BaselineModelWithSentenceComparisonAndCue, self).__init__()\n",
        "\n",
        "    self.plm = AutoModel.from_pretrained(args[\"model_name\"])\n",
        "    config = self.plm.config\n",
        "    config.type_vocab_size = 4\n",
        "    self.plm.embeddings.token_type_embeddings = nn.Embedding(\n",
        "      config.type_vocab_size, config.hidden_size\n",
        "    )\n",
        "    self.plm._init_weights(self.plm.embeddings.token_type_embeddings)\n",
        "\n",
        "    self.num_classes = args[\"num_classes\"]\n",
        "    self.embed_size = args[\"embed_size\"]\n",
        "\n",
        "    self.first_last_avg = args[\"first_last_avg\"]\n",
        "\n",
        "    for param in self.plm.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    self.linear_layer = torch.nn.Linear(in_features=self.embed_size, out_features=args[\"num_classes\"])\n",
        "    self.multi_head_att = torch.nn.MultiheadAttention(self.embed_size, 8, batch_first=True)\n",
        "    self.Q = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.K = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.V = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.linear_initial_sent = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.linear_end_sent = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    self._init_weights(self.linear_layer)\n",
        "    self._init_weights(self.Q)\n",
        "    self._init_weights(self.K)\n",
        "    self._init_weights(self.V)\n",
        "    self._init_weights(self.multi_head_att)\n",
        "    self._init_weights(self.linear_initial_sent)\n",
        "    self._init_weights(self.linear_end_sent)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "    \"\"\"Initialize the weights\"\"\"\n",
        "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "      module.weight.data.normal_(mean=0.0, std=self.plm.config.initializer_range)\n",
        "    elif isinstance(module, nn.LayerNorm):\n",
        "      module.bias.data.zero_()\n",
        "      module.weight.data.fill_(1.0)\n",
        "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "      module.bias.data.zero_()\n",
        "\n",
        "  @torch.autocast(device_type=\"cuda\")\n",
        "  def forward(self, ids_sent1, segs_sent1, att_mask_sent1, position_sep):\n",
        "    out_sent1 = self.plm(ids_sent1, token_type_ids=segs_sent1, attention_mask=att_mask_sent1, output_hidden_states=True)\n",
        "\n",
        "    last_sent1, first_sent1 = out_sent1.hidden_states[-1], out_sent1.hidden_states[1]\n",
        "\n",
        "    if self.first_last_avg:\n",
        "      embed_sent1 = torch.div((last_sent1 + first_sent1), 2)\n",
        "    else:\n",
        "      embed_sent1 = last_sent1\n",
        "\n",
        "    tar_mask_sent1 = (segs_sent1 == 0).long()\n",
        "    tar_mask_sent2 = (segs_sent1 == 1).long()\n",
        "\n",
        "    H_sent1 = torch.mul(tar_mask_sent1.unsqueeze(2), embed_sent1)\n",
        "    H_sent2 = torch.mul(tar_mask_sent2.unsqueeze(2), embed_sent1)\n",
        "\n",
        "    K_sent1 = self.K(H_sent1)\n",
        "    V_sent1 = self.V(H_sent1)\n",
        "    Q_sent2 = self.Q(H_sent2)\n",
        "\n",
        "    att_output = self.multi_head_att(Q_sent2, K_sent1, V_sent1)[0]\n",
        "\n",
        "    initial_sent1 = att_output[:,0,:]\n",
        "    initial_sent2 = att_output[torch.arange(att_output.shape[0]), torch.sum((segs_sent1 == 0).long(), dim=-1)]\n",
        "    end_sent2 = att_output[:,-1,:]\n",
        "\n",
        "    initial_sent1 = self.linear_initial_sent(initial_sent1)\n",
        "    end_sent2 = self.linear_end_sent(end_sent2)\n",
        "    gate = self.sigmoid(initial_sent1 + end_sent2)\n",
        "\n",
        "    final_emb = initial_sent2 * gate\n",
        "\n",
        "    predictions = self.linear_layer(final_emb)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "class BaselineModelWithSentenceComparison(torch.nn.Module):\n",
        "  def __init__(self, attention):\n",
        "    super(BaselineModelWithSentenceComparison, self).__init__()\n",
        "\n",
        "    self.plm = AutoModel.from_pretrained(args[\"model_name\"])\n",
        "    config = self.plm.config\n",
        "    config.type_vocab_size = 4\n",
        "    self.plm.embeddings.token_type_embeddings = nn.Embedding(\n",
        "      config.type_vocab_size, config.hidden_size\n",
        "    )\n",
        "    self.plm._init_weights(self.plm.embeddings.token_type_embeddings)\n",
        "\n",
        "    self.num_classes = args[\"num_classes\"]\n",
        "    self.embed_size = args[\"embed_size\"]\n",
        "    self.attention = attention\n",
        "\n",
        "    self.first_last_avg = args[\"first_last_avg\"]\n",
        "\n",
        "    for param in self.plm.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    self.linear_layer = torch.nn.Linear(in_features=self.embed_size, out_features=args[\"num_classes\"])\n",
        "    self.multi_head_att = torch.nn.MultiheadAttention(self.embed_size, 8, batch_first=True)\n",
        "    self.Q = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.K = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "    self.V = torch.nn.Linear(in_features=self.embed_size, out_features=self.embed_size)\n",
        "\n",
        "    self._init_weights(self.linear_layer)\n",
        "    self._init_weights(self.Q)\n",
        "    self._init_weights(self.K)\n",
        "    self._init_weights(self.V)\n",
        "    self._init_weights(self.multi_head_att)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "    \"\"\"Initialize the weights\"\"\"\n",
        "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "      module.weight.data.normal_(mean=0.0, std=self.plm.config.initializer_range)\n",
        "    elif isinstance(module, nn.LayerNorm):\n",
        "      module.bias.data.zero_()\n",
        "      module.weight.data.fill_(1.0)\n",
        "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "      module.bias.data.zero_()\n",
        "\n",
        "  @torch.autocast(device_type=\"cuda\")\n",
        "  def forward(self, ids_sent1, segs_sent1, att_mask_sent1, position_sep):\n",
        "    out_sent1 = self.plm(ids_sent1, token_type_ids=segs_sent1, attention_mask=att_mask_sent1, output_hidden_states=True)\n",
        "\n",
        "    last_sent1, first_sent1 = out_sent1.hidden_states[-1], out_sent1.hidden_states[1]\n",
        "\n",
        "    if self.first_last_avg:\n",
        "      embed_sent1 = torch.div((last_sent1 + first_sent1), 2)\n",
        "    else:\n",
        "      embed_sent1 = last_sent1\n",
        "\n",
        "    if self.attention:\n",
        "      tar_mask_sent1 = (segs_sent1 == 0).long()\n",
        "      tar_mask_sent2 = (segs_sent1 == 1).long()\n",
        "\n",
        "      H_sent1 = torch.mul(tar_mask_sent1.unsqueeze(2), embed_sent1)\n",
        "      H_sent2 = torch.mul(tar_mask_sent2.unsqueeze(2), embed_sent1)\n",
        "\n",
        "      K_sent1 = self.K(H_sent1)\n",
        "      V_sent1 = self.V(H_sent1)\n",
        "      Q_sent2 = self.Q(H_sent2)\n",
        "\n",
        "      att_output = self.multi_head_att(Q_sent2, K_sent1, V_sent1)\n",
        "\n",
        "      H_sent = torch.mean(att_output[0], dim=1)\n",
        "    else:\n",
        "      H_sent = torch.mean(embed_sent1, dim=1)\n",
        "\n",
        "    predictions = self.linear_layer(H_sent)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "class BaselineModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BaselineModel, self).__init__()\n",
        "\n",
        "    self.plm = AutoModel.from_pretrained(args[\"model_name\"])\n",
        "    config = self.plm.config\n",
        "    config.type_vocab_size = 4\n",
        "    self.plm.embeddings.token_type_embeddings = nn.Embedding(\n",
        "      config.type_vocab_size, config.hidden_size\n",
        "    )\n",
        "    self.plm._init_weights(self.plm.embeddings.token_type_embeddings)\n",
        "\n",
        "    self.num_classes = args[\"num_classes\"]\n",
        "    self.embed_size = args[\"embed_size\"]\n",
        "\n",
        "    self.first_last_avg = args[\"first_last_avg\"]\n",
        "\n",
        "    for param in self.plm.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    self.linear_layer = torch.nn.Linear(in_features=self.embed_size, out_features=args[\"num_classes\"])\n",
        "\n",
        "    self._init_weights(self.linear_layer)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "    \"\"\"Initialize the weights\"\"\"\n",
        "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "      module.weight.data.normal_(mean=0.0, std=self.plm.config.initializer_range)\n",
        "    elif isinstance(module, nn.LayerNorm):\n",
        "      module.bias.data.zero_()\n",
        "      module.weight.data.fill_(1.0)\n",
        "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "      module.bias.data.zero_()\n",
        "\n",
        "  @torch.autocast(device_type=\"cuda\")\n",
        "  def forward(self, ids_sent1, segs_sent1, att_mask_sent1, position_sep):\n",
        "    out_sent1 = self.plm(ids_sent1, token_type_ids=segs_sent1, attention_mask=att_mask_sent1, output_hidden_states=True)\n",
        "\n",
        "    last_sent1, first_sent1 = out_sent1.hidden_states[-1], out_sent1.hidden_states[1]\n",
        "\n",
        "    if self.first_last_avg:\n",
        "      embed_sent1 = torch.div((last_sent1 + first_sent1), 2)\n",
        "    else:\n",
        "      embed_sent1 = last_sent1\n",
        "\n",
        "    tar_mask_sent1 = (position_sep == 1).long()\n",
        "\n",
        "    H_sent1 = torch.mul(tar_mask_sent1.unsqueeze(2), embed_sent1)\n",
        "\n",
        "    H_mean1 = torch.mean(embed_sent1, dim=1)\n",
        "\n",
        "    predictions = self.linear_layer(H_mean1)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "class SiameseBaselineModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SiameseBaselineModel, self).__init__()\n",
        "\n",
        "    self.plm = AutoModel.from_pretrained(args[\"model_name\"])\n",
        "    config = self.plm.config\n",
        "    config.type_vocab_size = 4\n",
        "    self.plm.embeddings.token_type_embeddings = nn.Embedding(\n",
        "      config.type_vocab_size, config.hidden_size\n",
        "    )\n",
        "    self.plm._init_weights(self.plm.embeddings.token_type_embeddings)\n",
        "\n",
        "    self.num_classes = args[\"num_classes\"]\n",
        "    self.embed_size = args[\"embed_size\"]\n",
        "\n",
        "    self.first_last_avg = args[\"first_last_avg\"]\n",
        "\n",
        "    for param in self.plm.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "    self.linear_layer = torch.nn.Linear(in_features=self.embed_size*2, out_features=args[\"num_classes\"])\n",
        "\n",
        "    self._init_weights(self.linear_layer)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "    \"\"\"Initialize the weights\"\"\"\n",
        "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
        "      module.weight.data.normal_(mean=0.0, std=self.plm.config.initializer_range)\n",
        "    elif isinstance(module, nn.LayerNorm):\n",
        "      module.bias.data.zero_()\n",
        "      module.weight.data.fill_(1.0)\n",
        "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "      module.bias.data.zero_()\n",
        "\n",
        "  @torch.autocast(device_type=\"cuda\")\n",
        "  def forward(self, ids_sent1, segs_sent1, att_mask_sent1, ids_sent2, segs_sent2, att_mask_sent2):\n",
        "    out_sent1 = self.plm(ids_sent1, token_type_ids=segs_sent1, attention_mask=att_mask_sent1, output_hidden_states=True)\n",
        "    out_sent2 = self.plm(ids_sent2, token_type_ids=segs_sent2, attention_mask=att_mask_sent2, output_hidden_states=True)\n",
        "\n",
        "    last_sent1, first_sent1 = out_sent1.hidden_states[-1], out_sent1.hidden_states[1]\n",
        "    last_sent2, first_sent2 = out_sent2.hidden_states[-1], out_sent2.hidden_states[1]\n",
        "\n",
        "    if self.first_last_avg:\n",
        "      embed_sent1 = torch.div((last_sent1 + first_sent1), 2)\n",
        "      embed_sent2 = torch.div((last_sent2 + first_sent2), 2)\n",
        "    else:\n",
        "      embed_sent1 = last_sent1\n",
        "      embed_sent2 = last_sent2\n",
        "\n",
        "    tar_mask_sent1 = (segs_sent1 == 1).long()\n",
        "    tar_mask_sent2 = (segs_sent2 == 1).long()\n",
        "\n",
        "    H_sent1 = torch.mul(tar_mask_sent1.unsqueeze(2), embed_sent1)\n",
        "    H_sent2 = torch.mul(tar_mask_sent2.unsqueeze(2), embed_sent2)\n",
        "\n",
        "    H_mean1 = torch.mean(embed_sent1, dim=1)\n",
        "    H_mean2 = torch.mean(embed_sent2, dim=1)\n",
        "\n",
        "    H_cat = torch.cat((H_mean1, H_mean2), dim=-1)\n",
        "\n",
        "    predictions = self.linear_layer(H_cat)\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JtBDFwz4Ban5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "def set_random_seeds(seed):\n",
        "    \"\"\"\n",
        "    set random seed\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "\n",
        "def output_metrics(labels, preds):\n",
        "    \"\"\"\n",
        "\n",
        "    :param labels: ground truth labels\n",
        "    :param preds: prediction labels\n",
        "    :return: accuracy, precision, recall, f1\n",
        "    \"\"\"\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    precision = precision_score(labels, preds, average=\"macro\")\n",
        "    recall = recall_score(labels, preds, average=\"macro\")\n",
        "    f1 = f1_score(labels, preds, average=\"macro\")\n",
        "\n",
        "    print(\"{:15}{:<.3f}\".format('accuracy:', accuracy))\n",
        "    print(\"{:15}{:<.3f}\".format('precision:', precision))\n",
        "    print(\"{:15}{:<.3f}\".format('recall:', recall))\n",
        "    print(\"{:15}{:<.3f}\".format('f1:', f1))\n",
        "\n",
        "    return accuracy, precision, recall, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nOgUyIFcKg4W"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Sampler\n",
        "\n",
        "class BalancedSampler(Sampler):\n",
        "    def __init__(self, dataset1, dataset2, batch_size):\n",
        "        self.dataset1 = dataset1\n",
        "        self.dataset2 = dataset2\n",
        "        self.batch_size = batch_size\n",
        "        self.total_size = len(dataset1) + len(dataset2)\n",
        "        self.indices1 = list(range(len(dataset1)))\n",
        "        self.indices2 = list(range(len(dataset2)))\n",
        "        self.epoch = 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.epoch += 1\n",
        "        batch = []\n",
        "        indices1 = self.indices1.copy()\n",
        "        indices2 = self.indices2.copy()\n",
        "\n",
        "        indices1 = torch.randperm(len(self.dataset1)).cpu().tolist()\n",
        "        indices2 = torch.randperm(len(self.dataset2)) +len(indices1)\n",
        "        indices2 = indices2.cpu().tolist()\n",
        "\n",
        "        for i in range(self.total_size // self.batch_size):\n",
        "            batch_size1 = min(self.batch_size // 2, len(indices1))\n",
        "            if batch_size1 < (self.batch_size // 2):\n",
        "              break\n",
        "            batch_size2 = self.batch_size - batch_size1\n",
        "            batch.extend([indices1.pop() for _ in range(batch_size1)])\n",
        "            batch.extend([indices2.pop() for _ in range(batch_size2)])\n",
        "\n",
        "            yield batch\n",
        "            batch = []\n",
        "            if len(indices1) == 0:\n",
        "              break\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.total_size + self.batch_size - 1) // self.batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c18eedc7abe7424ab703825e852ee540",
            "8a42235236d440a8a73fbfb886fefef3",
            "bc4fb44404974a2798968b45319a9461",
            "2a819d509f7d4c2f9a8dc17253b62d4f",
            "d5ba67e64d334ee3878bf917c5736964",
            "a26382d7e4bd4fa7bd2d92b57c56da2c",
            "443e5c11611a48efb2f0f790a5164d09",
            "9a42d6a5c2f44148bb2d3f29f8fc0752",
            "5500233fb32543a88d7f3e06e636da13",
            "bcde457264604e928234b6a0b824a062",
            "8b5f66b5a2ec406f9dbfdd42d2cdf08b",
            "937cf0697d894a0381f308f317fc176a",
            "a626e023c7f8467f8ebb4cbb11253760",
            "d9c3e79097c64de98bc393ca3ecb0b8f",
            "edd0b6c222c54ee9a6772c5d8dff9a67",
            "ddf7064f0db5416eae0a0146cb9479d7",
            "0852a96548904af3916603ccd67b06ed",
            "e18ad21ec9a54b2eaa7875e5c3b7bb1f",
            "62939053da3b4d98bd83413af5d5f8ad",
            "5f5830d36e9243389481448487555adc",
            "f86827dd09954244a45160e465ff5c0d",
            "1f4505324bf341dc80b4fef6d75b6b12",
            "6aa45c0dc01f496281bb4d602682e1b8",
            "7f3fddbad5e84e1cbfc5273c7d3c8c25",
            "dc016f6b60f84fbb9c252044b9d31be5",
            "6c57b4e578b54488b28e99ab44ad99e2",
            "0d3ca5e7768e49bdb687402fa0d7445a",
            "0b74f56e2dd44aef846e78d7706ac625",
            "db6e6f823abd4f8b8af25bbfa33cd9ba",
            "98b4cc46b42d484caaad86f22ab8fb02",
            "cbaba3897d694cf4a33d70c3a1079f84",
            "1a7d9db330e74d62afce40d26f239423",
            "6ec90dbbc6a3412997de64184d7234b9",
            "6022dfe94450439ab2c23b6076f45d6e",
            "f29e2ba39f5646c8b757cca20135f3fd",
            "84febb5759b4421a8d67b93657202e22",
            "ff3cff3c67e94a8f9a4de646ec34acc1",
            "fae60483c8c74b4db6243361c04c7187",
            "cf93a134d8a146a5aaa837876a1f0945",
            "44c65138cc74423398458dbc711a4318",
            "a4d20be069bf451b9a38429f8fef93be",
            "bb6d08e88eff4a238a86d514c62a6578",
            "1259e88cfe644fd1a9e6b002b0c3cf43",
            "8f893b90291347e2a8d4242279a064af",
            "a2dfe438d2594a2ab596465409488b27",
            "1b264ffb18204b77a849cd41b2ab65ee",
            "5678de3798d1404c97aaa5b5bf2033e9",
            "e15b1749e0c34688a84d4a1b7e287621",
            "fbe30515e3e54cefa059ec01f25073be",
            "685fb6c2e161458ab6941e475d80a7e5",
            "22a1f72bd9294448826e66fc498525cb",
            "d515e206ec9049f1bd963968d4a6588c",
            "1d1ba4fb1679403690e5ecf350ef42a5",
            "362080a3b8e54fc6b5c2de71445db3a8",
            "97b80e7fe60a47609e3d35ab285fcedb",
            "6a7cf1577fca49c6a54a215cd0b1d643",
            "1e22a92431e746709792868d3f7eae29",
            "1b48457ed6de413ba0249fd72300635b",
            "1909ab51eca44001ab9c5e1356cde704",
            "eca92145a54a495e81c5e3bfefe42676",
            "44cb560bbd3247bcb4d5e53ffe4d1f29",
            "69171f81e70740de9703b0a3cfb0b088",
            "fc4815d494d4441b9c5dcda2c50f7910",
            "1965161496c34f5ea8b5bbb3b1989f4a",
            "f940e68c7c964291ab0a1c40f67d7097",
            "b2471e210623410f8f7292a269b79fdd"
          ]
        },
        "id": "8XNhht6HtmJ6",
        "outputId": "335ed3af-fde6-4e02-8085-35f5a2d1b9d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**** trying with seed 0 ****\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c18eedc7abe7424ab703825e852ee540"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "937cf0697d894a0381f308f317fc176a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6aa45c0dc01f496281bb4d602682e1b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6022dfe94450439ab2c23b6076f45d6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2dfe438d2594a2ab596465409488b27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing...: 100%|██████████| 3070/3070 [00:01<00:00, 2327.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished preprocessing examples in train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing...: 100%|██████████| 1142/1142 [00:00<00:00, 2771.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished preprocessing examples in dev\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing...: 100%|██████████| 1100/1100 [00:00<00:00, 2944.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished preprocessing examples in test\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a7cf1577fca49c6a54a215cd0b1d643"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Start training: epoch 1 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:09<00:00,  5.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 9.379853010177612, Epoch: 1, training loss: 59.89092302322388, current learning rate 1e-05\n",
            "val loss: 13.23507010936737\n",
            "accuracy:      0.206\n",
            "precision:     0.515\n",
            "recall:        0.515\n",
            "f1:            0.206\n",
            "val loss: 13.363810241222382\n",
            "accuracy:      0.161\n",
            "precision:     0.533\n",
            "recall:        0.533\n",
            "f1:            0.161\n",
            "===== Start training: epoch 2 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.796911716461182, Epoch: 2, training loss: 56.2201201915741, current learning rate 1e-05\n",
            "val loss: 14.324878931045532\n",
            "accuracy:      0.456\n",
            "precision:     0.548\n",
            "recall:        0.613\n",
            "f1:            0.413\n",
            "val loss: 13.595343947410583\n",
            "accuracy:      0.528\n",
            "precision:     0.559\n",
            "recall:        0.693\n",
            "f1:            0.448\n",
            "===== Start training: epoch 3 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.737089395523071, Epoch: 3, training loss: 43.83421570062637, current learning rate 1e-05\n",
            "val loss: 9.595166146755219\n",
            "accuracy:      0.757\n",
            "precision:     0.606\n",
            "recall:        0.709\n",
            "f1:            0.613\n",
            "val loss: 9.435796439647675\n",
            "accuracy:      0.759\n",
            "precision:     0.594\n",
            "recall:        0.749\n",
            "f1:            0.594\n",
            "===== Start training: epoch 4 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.765240430831909, Epoch: 4, training loss: 34.58725208044052, current learning rate 1e-05\n",
            "val loss: 7.003818064928055\n",
            "accuracy:      0.844\n",
            "precision:     0.644\n",
            "recall:        0.681\n",
            "f1:            0.658\n",
            "val loss: 6.289217632263899\n",
            "accuracy:      0.856\n",
            "precision:     0.626\n",
            "recall:        0.712\n",
            "f1:            0.651\n",
            "===== Start training: epoch 5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.753658294677734, Epoch: 5, training loss: 27.01233971118927, current learning rate 1e-05\n",
            "val loss: 6.34970822930336\n",
            "accuracy:      0.870\n",
            "precision:     0.672\n",
            "recall:        0.655\n",
            "f1:            0.663\n",
            "val loss: 5.450833261013031\n",
            "accuracy:      0.884\n",
            "precision:     0.650\n",
            "recall:        0.697\n",
            "f1:            0.669\n",
            "===== Start training: epoch 6 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.7456746101379395, Epoch: 6, training loss: 22.50232794880867, current learning rate 1e-05\n",
            "val loss: 9.78340059518814\n",
            "accuracy:      0.802\n",
            "precision:     0.620\n",
            "recall:        0.701\n",
            "f1:            0.639\n",
            "val loss: 10.483716905117035\n",
            "accuracy:      0.800\n",
            "precision:     0.608\n",
            "recall:        0.756\n",
            "f1:            0.625\n",
            "===== Start training: epoch 7 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.757261276245117, Epoch: 7, training loss: 17.11434108018875, current learning rate 1e-05\n",
            "val loss: 8.151970475912094\n",
            "accuracy:      0.860\n",
            "precision:     0.667\n",
            "recall:        0.693\n",
            "f1:            0.678\n",
            "val loss: 8.739655613899231\n",
            "accuracy:      0.860\n",
            "precision:     0.631\n",
            "recall:        0.719\n",
            "f1:            0.657\n",
            "===== Start training: epoch 8 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.750847101211548, Epoch: 8, training loss: 14.346321493387222, current learning rate 1e-05\n",
            "val loss: 7.5999486446380615\n",
            "accuracy:      0.880\n",
            "precision:     0.692\n",
            "recall:        0.651\n",
            "f1:            0.668\n",
            "val loss: 6.7021065056324005\n",
            "accuracy:      0.898\n",
            "precision:     0.666\n",
            "recall:        0.670\n",
            "f1:            0.668\n",
            "===== Start training: epoch 9 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.770345211029053, Epoch: 9, training loss: 10.43159157037735, current learning rate 1e-05\n",
            "val loss: 9.11551807820797\n",
            "accuracy:      0.889\n",
            "precision:     0.717\n",
            "recall:        0.619\n",
            "f1:            0.647\n",
            "val loss: 7.704587370157242\n",
            "accuracy:      0.905\n",
            "precision:     0.673\n",
            "recall:        0.643\n",
            "f1:            0.656\n",
            "===== Start training: epoch 10 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.739965915679932, Epoch: 10, training loss: 11.154188179410994, current learning rate 1e-05\n",
            "val loss: 9.072454690933228\n",
            "accuracy:      0.885\n",
            "precision:     0.710\n",
            "recall:        0.670\n",
            "f1:            0.687\n",
            "val loss: 8.273334443569183\n",
            "accuracy:      0.891\n",
            "precision:     0.654\n",
            "recall:        0.676\n",
            "f1:            0.664\n",
            "===== Start training: epoch 11 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.737668514251709, Epoch: 11, training loss: 8.437218494713306, current learning rate 1e-05\n",
            "val loss: 9.770945459604263\n",
            "accuracy:      0.898\n",
            "precision:     0.758\n",
            "recall:        0.651\n",
            "f1:            0.685\n",
            "val loss: 8.087552845478058\n",
            "accuracy:      0.908\n",
            "precision:     0.685\n",
            "recall:        0.645\n",
            "f1:            0.662\n",
            "===== Start training: epoch 12 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.742837429046631, Epoch: 12, training loss: 7.226190112531185, current learning rate 1e-05\n",
            "val loss: 10.121239364147186\n",
            "accuracy:      0.900\n",
            "precision:     0.780\n",
            "recall:        0.625\n",
            "f1:            0.663\n",
            "val loss: 7.946104168891907\n",
            "accuracy:      0.918\n",
            "precision:     0.724\n",
            "recall:        0.625\n",
            "f1:            0.657\n",
            "===== Start training: epoch 13 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.738837242126465, Epoch: 13, training loss: 12.253919288516045, current learning rate 1e-05\n",
            "val loss: 8.584372460842133\n",
            "accuracy:      0.894\n",
            "precision:     0.738\n",
            "recall:        0.655\n",
            "f1:            0.684\n",
            "val loss: 7.464864939451218\n",
            "accuracy:      0.915\n",
            "precision:     0.714\n",
            "recall:        0.683\n",
            "f1:            0.697\n",
            "===== Start training: epoch 14 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.738189935684204, Epoch: 14, training loss: 6.6395059623755515, current learning rate 1e-05\n",
            "val loss: 9.143887430429459\n",
            "accuracy:      0.901\n",
            "precision:     0.767\n",
            "recall:        0.663\n",
            "f1:            0.697\n",
            "val loss: 6.7654247879981995\n",
            "accuracy:      0.915\n",
            "precision:     0.709\n",
            "recall:        0.653\n",
            "f1:            0.676\n",
            "===== Start training: epoch 15 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.710854768753052, Epoch: 15, training loss: 3.512923235539347, current learning rate 1e-05\n",
            "val loss: 11.22438058629632\n",
            "accuracy:      0.882\n",
            "precision:     0.701\n",
            "recall:        0.675\n",
            "f1:            0.687\n",
            "val loss: 9.936739549040794\n",
            "accuracy:      0.894\n",
            "precision:     0.658\n",
            "recall:        0.672\n",
            "f1:            0.665\n",
            "===== Start training: epoch 16 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.737304925918579, Epoch: 16, training loss: 4.397307340055704, current learning rate 1e-05\n",
            "val loss: 12.728438973426819\n",
            "accuracy:      0.885\n",
            "precision:     0.708\n",
            "recall:        0.660\n",
            "f1:            0.680\n",
            "val loss: 11.516772910952568\n",
            "accuracy:      0.895\n",
            "precision:     0.656\n",
            "recall:        0.663\n",
            "f1:            0.659\n",
            "===== Start training: epoch 17 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.729533672332764, Epoch: 17, training loss: 8.03999880189076, current learning rate 1e-05\n",
            "val loss: 12.114305138587952\n",
            "accuracy:      0.884\n",
            "precision:     0.701\n",
            "recall:        0.646\n",
            "f1:            0.667\n",
            "val loss: 10.786251544952393\n",
            "accuracy:      0.896\n",
            "precision:     0.655\n",
            "recall:        0.649\n",
            "f1:            0.652\n",
            "===== Start training: epoch 18 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.7101593017578125, Epoch: 18, training loss: 4.178658757358789, current learning rate 1e-05\n",
            "val loss: 11.366767600178719\n",
            "accuracy:      0.903\n",
            "precision:     0.791\n",
            "recall:        0.637\n",
            "f1:            0.677\n",
            "val loss: 9.173387318849564\n",
            "accuracy:      0.916\n",
            "precision:     0.715\n",
            "recall:        0.634\n",
            "f1:            0.663\n",
            "===== Start training: epoch 19 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.703939914703369, Epoch: 19, training loss: 3.3520991867408156, current learning rate 1e-05\n",
            "val loss: 8.712272018194199\n",
            "accuracy:      0.903\n",
            "precision:     0.786\n",
            "recall:        0.643\n",
            "f1:            0.683\n",
            "val loss: 7.121508235111833\n",
            "accuracy:      0.917\n",
            "precision:     0.719\n",
            "recall:        0.635\n",
            "f1:            0.664\n",
            "===== Start training: epoch 20 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.72911524772644, Epoch: 20, training loss: 1.361448385170661, current learning rate 1e-05\n",
            "val loss: 13.554105550050735\n",
            "accuracy:      0.890\n",
            "precision:     0.721\n",
            "recall:        0.653\n",
            "f1:            0.678\n",
            "val loss: 11.944578185677528\n",
            "accuracy:      0.907\n",
            "precision:     0.690\n",
            "recall:        0.675\n",
            "f1:            0.682\n",
            "===== Start training: epoch 21 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.707988262176514, Epoch: 21, training loss: 1.6745777588803321, current learning rate 1e-05\n",
            "val loss: 12.66573141515255\n",
            "accuracy:      0.894\n",
            "precision:     0.737\n",
            "recall:        0.669\n",
            "f1:            0.694\n",
            "val loss: 10.265271564479917\n",
            "accuracy:      0.908\n",
            "precision:     0.690\n",
            "recall:        0.665\n",
            "f1:            0.676\n",
            "===== Start training: epoch 22 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.716861009597778, Epoch: 22, training loss: 2.346746128052473, current learning rate 1e-05\n",
            "val loss: 13.439376384019852\n",
            "accuracy:      0.889\n",
            "precision:     0.718\n",
            "recall:        0.642\n",
            "f1:            0.668\n",
            "val loss: 11.642925709486008\n",
            "accuracy:      0.908\n",
            "precision:     0.691\n",
            "recall:        0.670\n",
            "f1:            0.680\n",
            "===== Start training: epoch 23 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.709836721420288, Epoch: 23, training loss: 2.3727111760526896, current learning rate 1e-05\n",
            "val loss: 11.703760288655758\n",
            "accuracy:      0.898\n",
            "precision:     0.763\n",
            "recall:        0.624\n",
            "f1:            0.659\n",
            "val loss: 8.97150644659996\n",
            "accuracy:      0.920\n",
            "precision:     0.734\n",
            "recall:        0.651\n",
            "f1:            0.681\n",
            "===== Start training: epoch 24 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.715802192687988, Epoch: 24, training loss: 1.7935336019145325, current learning rate 1e-05\n",
            "val loss: 14.37534373998642\n",
            "accuracy:      0.892\n",
            "precision:     0.732\n",
            "recall:        0.641\n",
            "f1:            0.670\n",
            "val loss: 11.652050971984863\n",
            "accuracy:      0.914\n",
            "precision:     0.711\n",
            "recall:        0.683\n",
            "f1:            0.696\n",
            "===== Start training: epoch 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.696642875671387, Epoch: 25, training loss: 0.840712160221301, current learning rate 1e-05\n",
            "val loss: 13.113854765892029\n",
            "accuracy:      0.891\n",
            "precision:     0.726\n",
            "recall:        0.606\n",
            "f1:            0.636\n",
            "val loss: 9.067776704847347\n",
            "accuracy:      0.921\n",
            "precision:     0.739\n",
            "recall:        0.647\n",
            "f1:            0.679\n",
            "===== Start training: epoch 26 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.733952283859253, Epoch: 26, training loss: 3.323373144492507, current learning rate 1e-05\n",
            "val loss: 13.50602400302887\n",
            "accuracy:      0.896\n",
            "precision:     0.754\n",
            "recall:        0.619\n",
            "f1:            0.653\n",
            "val loss: 10.790794387459755\n",
            "accuracy:      0.919\n",
            "precision:     0.730\n",
            "recall:        0.661\n",
            "f1:            0.687\n",
            "===== Start training: epoch 27 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.717961311340332, Epoch: 27, training loss: 6.043012237176299, current learning rate 1e-05\n",
            "val loss: 13.913256615400314\n",
            "accuracy:      0.901\n",
            "precision:     0.770\n",
            "recall:        0.656\n",
            "f1:            0.692\n",
            "val loss: 11.244239429652225\n",
            "accuracy:      0.912\n",
            "precision:     0.704\n",
            "recall:        0.677\n",
            "f1:            0.689\n",
            "===== Start training: epoch 28 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.706308126449585, Epoch: 28, training loss: 1.4264150448143482, current learning rate 1e-05\n",
            "val loss: 14.15811488032341\n",
            "accuracy:      0.884\n",
            "precision:     0.702\n",
            "recall:        0.653\n",
            "f1:            0.672\n",
            "val loss: 11.106706261634827\n",
            "accuracy:      0.899\n",
            "precision:     0.665\n",
            "recall:        0.660\n",
            "f1:            0.662\n",
            "===== Start training: epoch 29 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.69365668296814, Epoch: 29, training loss: 3.1620226074010134, current learning rate 1e-05\n",
            "val loss: 13.950615346431732\n",
            "accuracy:      0.894\n",
            "precision:     0.742\n",
            "recall:        0.625\n",
            "f1:            0.658\n",
            "val loss: 12.425690710544586\n",
            "accuracy:      0.912\n",
            "precision:     0.699\n",
            "recall:        0.652\n",
            "f1:            0.671\n",
            "===== Start training: epoch 30 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.715838193893433, Epoch: 30, training loss: 3.97555582318455, current learning rate 1e-05\n",
            "val loss: 12.716745853424072\n",
            "accuracy:      0.889\n",
            "precision:     0.719\n",
            "recall:        0.669\n",
            "f1:            0.689\n",
            "val loss: 10.136414614855312\n",
            "accuracy:      0.902\n",
            "precision:     0.682\n",
            "recall:        0.697\n",
            "f1:            0.689\n",
            "best result:\n",
            "0.9145454545454546\n",
            "0.7094760312151617\n",
            "0.6534813056121282\n",
            "0.675723819559436\n",
            "[[0.9145454545454546, 0.7094760312151617, 0.6534813056121282, 0.675723819559436]]\n",
            "**** trying with seed 1 ****\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing...: 100%|██████████| 3070/3070 [00:01<00:00, 3001.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished preprocessing examples in train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing...: 100%|██████████| 1142/1142 [00:00<00:00, 2990.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished preprocessing examples in dev\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing...: 100%|██████████| 1100/1100 [00:00<00:00, 3015.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished preprocessing examples in test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Start training: epoch 1 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.743454456329346, Epoch: 1, training loss: 59.93883240222931, current learning rate 1e-05\n",
            "val loss: 14.156277120113373\n",
            "accuracy:      0.114\n",
            "precision:     0.057\n",
            "recall:        0.500\n",
            "f1:            0.102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val loss: 14.327746093273163\n",
            "accuracy:      0.083\n",
            "precision:     0.041\n",
            "recall:        0.500\n",
            "f1:            0.076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Start training: epoch 2 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.770113229751587, Epoch: 2, training loss: 59.04464542865753, current learning rate 1e-05\n",
            "val loss: 12.88006603717804\n",
            "accuracy:      0.412\n",
            "precision:     0.553\n",
            "recall:        0.615\n",
            "f1:            0.385\n",
            "val loss: 12.847136199474335\n",
            "accuracy:      0.444\n",
            "precision:     0.559\n",
            "recall:        0.682\n",
            "f1:            0.395\n",
            "===== Start training: epoch 3 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.760703802108765, Epoch: 3, training loss: 48.44602680206299, current learning rate 1e-05\n",
            "val loss: 10.844818532466888\n",
            "accuracy:      0.697\n",
            "precision:     0.594\n",
            "recall:        0.715\n",
            "f1:            0.579\n",
            "val loss: 11.04536759853363\n",
            "accuracy:      0.691\n",
            "precision:     0.583\n",
            "recall:        0.752\n",
            "f1:            0.554\n",
            "===== Start training: epoch 4 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.752890110015869, Epoch: 4, training loss: 35.20898273587227, current learning rate 1e-05\n",
            "val loss: 8.302786409854889\n",
            "accuracy:      0.791\n",
            "precision:     0.614\n",
            "recall:        0.698\n",
            "f1:            0.630\n",
            "val loss: 8.058888137340546\n",
            "accuracy:      0.792\n",
            "precision:     0.604\n",
            "recall:        0.752\n",
            "f1:            0.617\n",
            "===== Start training: epoch 5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.754040718078613, Epoch: 5, training loss: 24.45261698961258, current learning rate 1e-05\n",
            "val loss: 8.634464502334595\n",
            "accuracy:      0.815\n",
            "precision:     0.626\n",
            "recall:        0.695\n",
            "f1:            0.645\n",
            "val loss: 8.611675143241882\n",
            "accuracy:      0.815\n",
            "precision:     0.616\n",
            "recall:        0.759\n",
            "f1:            0.636\n",
            "===== Start training: epoch 6 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.752350568771362, Epoch: 6, training loss: 22.212018966674805, current learning rate 1e-05\n",
            "val loss: 6.537734389305115\n",
            "accuracy:      0.883\n",
            "precision:     0.698\n",
            "recall:        0.646\n",
            "f1:            0.666\n",
            "val loss: 5.7665634751319885\n",
            "accuracy:      0.891\n",
            "precision:     0.654\n",
            "recall:        0.676\n",
            "f1:            0.664\n",
            "===== Start training: epoch 7 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.7613959312438965, Epoch: 7, training loss: 16.615010023117065, current learning rate 1e-05\n",
            "val loss: 7.255587875843048\n",
            "accuracy:      0.881\n",
            "precision:     0.702\n",
            "recall:        0.691\n",
            "f1:            0.697\n",
            "val loss: 6.649036884307861\n",
            "accuracy:      0.878\n",
            "precision:     0.645\n",
            "recall:        0.704\n",
            "f1:            0.667\n",
            "===== Start training: epoch 8 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.733135223388672, Epoch: 8, training loss: 13.055280283093452, current learning rate 1e-05\n",
            "val loss: 8.119709700345993\n",
            "accuracy:      0.873\n",
            "precision:     0.688\n",
            "recall:        0.697\n",
            "f1:            0.693\n",
            "val loss: 7.990323632955551\n",
            "accuracy:      0.865\n",
            "precision:     0.632\n",
            "recall:        0.707\n",
            "f1:            0.656\n",
            "===== Start training: epoch 9 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.75330662727356, Epoch: 9, training loss: 7.846300058066845, current learning rate 1e-05\n",
            "val loss: 8.876904636621475\n",
            "accuracy:      0.891\n",
            "precision:     0.724\n",
            "recall:        0.650\n",
            "f1:            0.676\n",
            "val loss: 8.294081151485443\n",
            "accuracy:      0.886\n",
            "precision:     0.648\n",
            "recall:        0.678\n",
            "f1:            0.661\n",
            "===== Start training: epoch 10 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.719976902008057, Epoch: 10, training loss: 6.708992483094335, current learning rate 1e-05\n",
            "val loss: 9.798033207654953\n",
            "accuracy:      0.889\n",
            "precision:     0.717\n",
            "recall:        0.619\n",
            "f1:            0.647\n",
            "val loss: 8.178106807172298\n",
            "accuracy:      0.896\n",
            "precision:     0.649\n",
            "recall:        0.634\n",
            "f1:            0.640\n",
            "===== Start training: epoch 11 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.7207558155059814, Epoch: 11, training loss: 10.48784925043583, current learning rate 1e-05\n",
            "val loss: 9.17675419151783\n",
            "accuracy:      0.877\n",
            "precision:     0.689\n",
            "recall:        0.663\n",
            "f1:            0.674\n",
            "val loss: 9.023627623915672\n",
            "accuracy:      0.872\n",
            "precision:     0.624\n",
            "recall:        0.665\n",
            "f1:            0.640\n",
            "===== Start training: epoch 12 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.697725057601929, Epoch: 12, training loss: 7.574386224150658, current learning rate 1e-05\n",
            "val loss: 11.064963638782501\n",
            "accuracy:      0.889\n",
            "precision:     0.717\n",
            "recall:        0.599\n",
            "f1:            0.627\n",
            "val loss: 9.532777972519398\n",
            "accuracy:      0.895\n",
            "precision:     0.642\n",
            "recall:        0.623\n",
            "f1:            0.631\n",
            "===== Start training: epoch 13 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.698605298995972, Epoch: 13, training loss: 5.213096812367439, current learning rate 1e-05\n",
            "val loss: 12.976805657148361\n",
            "accuracy:      0.885\n",
            "precision:     0.706\n",
            "recall:        0.644\n",
            "f1:            0.666\n",
            "val loss: 11.619838833808899\n",
            "accuracy:      0.882\n",
            "precision:     0.636\n",
            "recall:        0.666\n",
            "f1:            0.649\n",
            "===== Start training: epoch 14 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.722217082977295, Epoch: 14, training loss: 4.160807700944133, current learning rate 1e-05\n",
            "val loss: 12.65356457233429\n",
            "accuracy:      0.887\n",
            "precision:     0.711\n",
            "recall:        0.641\n",
            "f1:            0.666\n",
            "val loss: 11.036688938736916\n",
            "accuracy:      0.896\n",
            "precision:     0.653\n",
            "recall:        0.644\n",
            "f1:            0.648\n",
            "===== Start training: epoch 15 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.7081427574157715, Epoch: 15, training loss: 4.959144582506269, current learning rate 1e-05\n",
            "val loss: 10.403862118721008\n",
            "accuracy:      0.890\n",
            "precision:     0.721\n",
            "recall:        0.619\n",
            "f1:            0.648\n",
            "val loss: 9.191470474004745\n",
            "accuracy:      0.897\n",
            "precision:     0.653\n",
            "recall:        0.639\n",
            "f1:            0.646\n",
            "===== Start training: epoch 16 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.701936960220337, Epoch: 16, training loss: 5.1844582124613225, current learning rate 1e-05\n",
            "val loss: 13.360639795660973\n",
            "accuracy:      0.890\n",
            "precision:     0.721\n",
            "recall:        0.629\n",
            "f1:            0.658\n",
            "val loss: 12.695162236690521\n",
            "accuracy:      0.902\n",
            "precision:     0.665\n",
            "recall:        0.642\n",
            "f1:            0.652\n",
            "===== Start training: epoch 17 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.711802959442139, Epoch: 17, training loss: 15.540218401700258, current learning rate 1e-05\n",
            "val loss: 13.615821838378906\n",
            "accuracy:      0.886\n",
            "precision:     0.711\n",
            "recall:        0.661\n",
            "f1:            0.681\n",
            "val loss: 12.925584882497787\n",
            "accuracy:      0.888\n",
            "precision:     0.661\n",
            "recall:        0.709\n",
            "f1:            0.680\n",
            "===== Start training: epoch 18 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.707991123199463, Epoch: 18, training loss: 5.037890948355198, current learning rate 1e-05\n",
            "val loss: 14.276320397853851\n",
            "accuracy:      0.885\n",
            "precision:     0.698\n",
            "recall:        0.587\n",
            "f1:            0.611\n",
            "val loss: 11.130375082313549\n",
            "accuracy:      0.903\n",
            "precision:     0.664\n",
            "recall:        0.632\n",
            "f1:            0.646\n",
            "===== Start training: epoch 19 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.701220512390137, Epoch: 19, training loss: 3.682710464578122, current learning rate 1e-05\n",
            "val loss: 12.671486467123032\n",
            "accuracy:      0.891\n",
            "precision:     0.725\n",
            "recall:        0.623\n",
            "f1:            0.653\n",
            "val loss: 11.607832670211792\n",
            "accuracy:      0.904\n",
            "precision:     0.684\n",
            "recall:        0.688\n",
            "f1:            0.686\n",
            "===== Start training: epoch 20 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.73125696182251, Epoch: 20, training loss: 3.490920833661221, current learning rate 1e-05\n",
            "val loss: 13.12696447968483\n",
            "accuracy:      0.886\n",
            "precision:     0.703\n",
            "recall:        0.597\n",
            "f1:            0.623\n",
            "val loss: 10.73597847437486\n",
            "accuracy:      0.899\n",
            "precision:     0.658\n",
            "recall:        0.640\n",
            "f1:            0.648\n",
            "===== Start training: epoch 21 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.715866804122925, Epoch: 21, training loss: 1.5375833325088024, current learning rate 1e-05\n",
            "val loss: 12.631966322660446\n",
            "accuracy:      0.894\n",
            "precision:     0.744\n",
            "recall:        0.618\n",
            "f1:            0.651\n",
            "val loss: 11.163707450032234\n",
            "accuracy:      0.903\n",
            "precision:     0.666\n",
            "recall:        0.637\n",
            "f1:            0.649\n",
            "===== Start training: epoch 22 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.724258661270142, Epoch: 22, training loss: 1.9732894338667393, current learning rate 1e-05\n",
            "val loss: 13.953213393688202\n",
            "accuracy:      0.896\n",
            "precision:     0.762\n",
            "recall:        0.603\n",
            "f1:            0.636\n",
            "val loss: 10.201259424298769\n",
            "accuracy:      0.916\n",
            "precision:     0.712\n",
            "recall:        0.614\n",
            "f1:            0.644\n",
            "===== Start training: epoch 23 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.702880382537842, Epoch: 23, training loss: 2.7763628400862217, current learning rate 1e-05\n",
            "val loss: 14.758638471364975\n",
            "accuracy:      0.886\n",
            "precision:     0.707\n",
            "recall:        0.631\n",
            "f1:            0.656\n",
            "val loss: 13.244417637586594\n",
            "accuracy:      0.903\n",
            "precision:     0.673\n",
            "recall:        0.657\n",
            "f1:            0.664\n",
            "===== Start training: epoch 24 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.705482482910156, Epoch: 24, training loss: 1.2293398273759522, current learning rate 1e-05\n",
            "val loss: 15.203418284654617\n",
            "accuracy:      0.886\n",
            "precision:     0.709\n",
            "recall:        0.647\n",
            "f1:            0.670\n",
            "val loss: 13.630041733384132\n",
            "accuracy:      0.900\n",
            "precision:     0.678\n",
            "recall:        0.696\n",
            "f1:            0.686\n",
            "===== Start training: epoch 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.721609830856323, Epoch: 25, training loss: 2.2712596451165155, current learning rate 1e-05\n",
            "val loss: 13.919069916009903\n",
            "accuracy:      0.894\n",
            "precision:     0.757\n",
            "recall:        0.588\n",
            "f1:            0.618\n",
            "val loss: 11.340859904885292\n",
            "accuracy:      0.920\n",
            "precision:     0.735\n",
            "recall:        0.626\n",
            "f1:            0.660\n",
            "===== Start training: epoch 26 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.709125280380249, Epoch: 26, training loss: 3.6443391459761187, current learning rate 1e-05\n",
            "val loss: 14.057468503713608\n",
            "accuracy:      0.891\n",
            "precision:     0.730\n",
            "recall:        0.586\n",
            "f1:            0.613\n",
            "val loss: 10.395136028528214\n",
            "accuracy:      0.923\n",
            "precision:     0.750\n",
            "recall:        0.643\n",
            "f1:            0.678\n",
            "===== Start training: epoch 27 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.708126783370972, Epoch: 27, training loss: 0.34028736501932144, current learning rate 1e-05\n",
            "val loss: 15.489700108766556\n",
            "accuracy:      0.884\n",
            "precision:     0.693\n",
            "recall:        0.602\n",
            "f1:            0.627\n",
            "val loss: 12.967994342267048\n",
            "accuracy:      0.902\n",
            "precision:     0.665\n",
            "recall:        0.642\n",
            "f1:            0.652\n",
            "===== Start training: epoch 28 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.700568914413452, Epoch: 28, training loss: 1.4646033474709839, current learning rate 1e-05\n",
            "val loss: 15.501698806881905\n",
            "accuracy:      0.889\n",
            "precision:     0.717\n",
            "recall:        0.599\n",
            "f1:            0.627\n",
            "val loss: 11.634579047560692\n",
            "accuracy:      0.915\n",
            "precision:     0.712\n",
            "recall:        0.644\n",
            "f1:            0.669\n",
            "===== Start training: epoch 29 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.697887420654297, Epoch: 29, training loss: 1.7114612922014203, current learning rate 1e-05\n",
            "val loss: 15.679251611232758\n",
            "accuracy:      0.891\n",
            "precision:     0.733\n",
            "recall:        0.600\n",
            "f1:            0.630\n",
            "val loss: 11.428666730731493\n",
            "accuracy:      0.917\n",
            "precision:     0.720\n",
            "recall:        0.640\n",
            "f1:            0.668\n",
            "===== Start training: epoch 30 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.697869539260864, Epoch: 30, training loss: 2.547098667389946, current learning rate 1e-05\n",
            "val loss: 15.233474016189575\n",
            "accuracy:      0.891\n",
            "precision:     0.725\n",
            "recall:        0.626\n",
            "f1:            0.656\n",
            "val loss: 12.241331761091715\n",
            "accuracy:      0.911\n",
            "precision:     0.694\n",
            "recall:        0.647\n",
            "f1:            0.666\n",
            "best result:\n",
            "0.8781818181818182\n",
            "0.6453880305728126\n",
            "0.7036452150426382\n",
            "0.666985974551764\n",
            "[[0.8781818181818182, 0.6453880305728126, 0.7036452150426382, 0.666985974551764]]\n",
            "**** trying with seed 2 ****\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing...: 100%|██████████| 3070/3070 [00:01<00:00, 2998.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished preprocessing examples in train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing...: 100%|██████████| 1142/1142 [00:00<00:00, 3045.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished preprocessing examples in dev\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizing...: 100%|██████████| 1100/1100 [00:00<00:00, 3078.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished preprocessing examples in test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Start training: epoch 1 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.759571075439453, Epoch: 1, training loss: 59.848284006118774, current learning rate 1e-05\n",
            "val loss: 14.817934691905975\n",
            "accuracy:      0.114\n",
            "precision:     0.057\n",
            "recall:        0.500\n",
            "f1:            0.102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val loss: 15.087481200695038\n",
            "accuracy:      0.083\n",
            "precision:     0.041\n",
            "recall:        0.500\n",
            "f1:            0.076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Start training: epoch 2 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.768396615982056, Epoch: 2, training loss: 57.85422056913376, current learning rate 1e-05\n",
            "val loss: 11.692639529705048\n",
            "accuracy:      0.588\n",
            "precision:     0.562\n",
            "recall:        0.653\n",
            "f1:            0.500\n",
            "val loss: 11.422449767589569\n",
            "accuracy:      0.600\n",
            "precision:     0.554\n",
            "recall:        0.677\n",
            "f1:            0.485\n",
            "===== Start training: epoch 3 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.748024225234985, Epoch: 3, training loss: 46.973882138729095, current learning rate 1e-05\n",
            "val loss: 15.088802933692932\n",
            "accuracy:      0.500\n",
            "precision:     0.571\n",
            "recall:        0.671\n",
            "f1:            0.452\n",
            "val loss: 14.947996854782104\n",
            "accuracy:      0.540\n",
            "precision:     0.559\n",
            "recall:        0.694\n",
            "f1:            0.455\n",
            "===== Start training: epoch 4 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.767448425292969, Epoch: 4, training loss: 38.9149826169014, current learning rate 1e-05\n",
            "val loss: 17.26581299304962\n",
            "accuracy:      0.504\n",
            "precision:     0.569\n",
            "recall:        0.667\n",
            "f1:            0.454\n",
            "val loss: 16.894371032714844\n",
            "accuracy:      0.531\n",
            "precision:     0.561\n",
            "recall:        0.699\n",
            "f1:            0.451\n",
            "===== Start training: epoch 5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.763638496398926, Epoch: 5, training loss: 30.32334941625595, current learning rate 1e-05\n",
            "val loss: 7.776436448097229\n",
            "accuracy:      0.819\n",
            "precision:     0.640\n",
            "recall:        0.727\n",
            "f1:            0.663\n",
            "val loss: 8.05561725795269\n",
            "accuracy:      0.795\n",
            "precision:     0.593\n",
            "recall:        0.713\n",
            "f1:            0.605\n",
            "===== Start training: epoch 6 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.745370149612427, Epoch: 6, training loss: 21.041440963745117, current learning rate 1e-05\n",
            "val loss: 6.819026708602905\n",
            "accuracy:      0.873\n",
            "precision:     0.681\n",
            "recall:        0.670\n",
            "f1:            0.675\n",
            "val loss: 7.288709998130798\n",
            "accuracy:      0.847\n",
            "precision:     0.592\n",
            "recall:        0.642\n",
            "f1:            0.607\n",
            "===== Start training: epoch 7 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.754063606262207, Epoch: 7, training loss: 19.20647007226944, current learning rate 1e-05\n",
            "val loss: 7.18718034029007\n",
            "accuracy:      0.863\n",
            "precision:     0.669\n",
            "recall:        0.688\n",
            "f1:            0.677\n",
            "val loss: 8.029399320483208\n",
            "accuracy:      0.840\n",
            "precision:     0.600\n",
            "recall:        0.673\n",
            "f1:            0.619\n",
            "===== Start training: epoch 8 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.751664400100708, Epoch: 8, training loss: 11.926053762435913, current learning rate 1e-05\n",
            "val loss: 8.306320190429688\n",
            "accuracy:      0.882\n",
            "precision:     0.696\n",
            "recall:        0.645\n",
            "f1:            0.665\n",
            "val loss: 7.753557354211807\n",
            "accuracy:      0.864\n",
            "precision:     0.607\n",
            "recall:        0.646\n",
            "f1:            0.621\n",
            "===== Start training: epoch 9 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.738660097122192, Epoch: 9, training loss: 10.946492660790682, current learning rate 1e-05\n",
            "val loss: 8.490041568875313\n",
            "accuracy:      0.885\n",
            "precision:     0.700\n",
            "recall:        0.603\n",
            "f1:            0.629\n",
            "val loss: 7.499669939279556\n",
            "accuracy:      0.892\n",
            "precision:     0.638\n",
            "recall:        0.631\n",
            "f1:            0.634\n",
            "===== Start training: epoch 10 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.728647232055664, Epoch: 10, training loss: 9.848496913909912, current learning rate 1e-05\n",
            "val loss: 8.905177474021912\n",
            "accuracy:      0.889\n",
            "precision:     0.718\n",
            "recall:        0.639\n",
            "f1:            0.666\n",
            "val loss: 7.509102776646614\n",
            "accuracy:      0.895\n",
            "precision:     0.649\n",
            "recall:        0.638\n",
            "f1:            0.643\n",
            "===== Start training: epoch 11 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.721697092056274, Epoch: 11, training loss: 12.137572273612022, current learning rate 1e-05\n",
            "val loss: 10.667888462543488\n",
            "accuracy:      0.868\n",
            "precision:     0.674\n",
            "recall:        0.677\n",
            "f1:            0.676\n",
            "val loss: 12.550426304340363\n",
            "accuracy:      0.855\n",
            "precision:     0.613\n",
            "recall:        0.681\n",
            "f1:            0.634\n",
            "===== Start training: epoch 12 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.713619947433472, Epoch: 12, training loss: 7.440164856612682, current learning rate 1e-05\n",
            "val loss: 10.062730967998505\n",
            "accuracy:      0.880\n",
            "precision:     0.697\n",
            "recall:        0.674\n",
            "f1:            0.685\n",
            "val loss: 10.833018153905869\n",
            "accuracy:      0.873\n",
            "precision:     0.627\n",
            "recall:        0.671\n",
            "f1:            0.644\n",
            "===== Start training: epoch 13 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.72478175163269, Epoch: 13, training loss: 7.442655675113201, current learning rate 1e-05\n",
            "val loss: 9.881079331040382\n",
            "accuracy:      0.890\n",
            "precision:     0.723\n",
            "recall:        0.676\n",
            "f1:            0.695\n",
            "val loss: 10.26331090927124\n",
            "accuracy:      0.880\n",
            "precision:     0.643\n",
            "recall:        0.690\n",
            "f1:            0.661\n",
            "===== Start training: epoch 14 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.734848260879517, Epoch: 14, training loss: 5.199147239327431, current learning rate 1e-05\n",
            "val loss: 11.733269274234772\n",
            "accuracy:      0.884\n",
            "precision:     0.705\n",
            "recall:        0.657\n",
            "f1:            0.676\n",
            "val loss: 11.391617625951767\n",
            "accuracy:      0.882\n",
            "precision:     0.640\n",
            "recall:        0.676\n",
            "f1:            0.655\n",
            "===== Start training: epoch 15 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.721583843231201, Epoch: 15, training loss: 4.144258376210928, current learning rate 1e-05\n",
            "val loss: 12.448563754558563\n",
            "accuracy:      0.884\n",
            "precision:     0.700\n",
            "recall:        0.643\n",
            "f1:            0.664\n",
            "val loss: 11.350945134996437\n",
            "accuracy:      0.888\n",
            "precision:     0.641\n",
            "recall:        0.654\n",
            "f1:            0.647\n",
            "===== Start training: epoch 16 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.71639347076416, Epoch: 16, training loss: 4.70066408906132, current learning rate 1e-05\n",
            "val loss: 11.40921026468277\n",
            "accuracy:      0.881\n",
            "precision:     0.692\n",
            "recall:        0.641\n",
            "f1:            0.661\n",
            "val loss: 10.851828381419182\n",
            "accuracy:      0.889\n",
            "precision:     0.641\n",
            "recall:        0.650\n",
            "f1:            0.645\n",
            "===== Start training: epoch 17 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.71134090423584, Epoch: 17, training loss: 7.679823767393827, current learning rate 1e-05\n",
            "val loss: 14.304481744766235\n",
            "accuracy:      0.885\n",
            "precision:     0.695\n",
            "recall:        0.570\n",
            "f1:            0.590\n",
            "val loss: 11.07724191993475\n",
            "accuracy:      0.906\n",
            "precision:     0.661\n",
            "recall:        0.599\n",
            "f1:            0.620\n",
            "===== Start training: epoch 18 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.700047731399536, Epoch: 18, training loss: 6.071425080299377, current learning rate 1e-05\n",
            "val loss: 11.187721759080887\n",
            "accuracy:      0.886\n",
            "precision:     0.706\n",
            "recall:        0.624\n",
            "f1:            0.650\n",
            "val loss: 11.622774571180344\n",
            "accuracy:      0.885\n",
            "precision:     0.636\n",
            "recall:        0.653\n",
            "f1:            0.644\n",
            "===== Start training: epoch 19 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.7318503856658936, Epoch: 19, training loss: 5.0126352701336145, current learning rate 1e-05\n",
            "val loss: 11.460989564657211\n",
            "accuracy:      0.891\n",
            "precision:     0.726\n",
            "recall:        0.606\n",
            "f1:            0.636\n",
            "val loss: 10.338993931887671\n",
            "accuracy:      0.896\n",
            "precision:     0.646\n",
            "recall:        0.629\n",
            "f1:            0.637\n",
            "===== Start training: epoch 20 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.717923879623413, Epoch: 20, training loss: 2.8393011174630374, current learning rate 1e-05\n",
            "val loss: 11.991062358021736\n",
            "accuracy:      0.894\n",
            "precision:     0.750\n",
            "recall:        0.602\n",
            "f1:            0.633\n",
            "val loss: 11.549651056528091\n",
            "accuracy:      0.905\n",
            "precision:     0.659\n",
            "recall:        0.608\n",
            "f1:            0.627\n",
            "===== Start training: epoch 21 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.725298166275024, Epoch: 21, training loss: 3.8021827191114426, current learning rate 1e-05\n",
            "val loss: 12.012453705072403\n",
            "accuracy:      0.891\n",
            "precision:     0.736\n",
            "recall:        0.570\n",
            "f1:            0.592\n",
            "val loss: 8.486480176448822\n",
            "accuracy:      0.916\n",
            "precision:     0.711\n",
            "recall:        0.604\n",
            "f1:            0.634\n",
            "===== Start training: epoch 22 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.718227863311768, Epoch: 22, training loss: 2.807033648248762, current learning rate 1e-05\n",
            "val loss: 11.831149369478226\n",
            "accuracy:      0.893\n",
            "precision:     0.743\n",
            "recall:        0.605\n",
            "f1:            0.636\n",
            "val loss: 10.336463382001966\n",
            "accuracy:      0.905\n",
            "precision:     0.669\n",
            "recall:        0.624\n",
            "f1:            0.641\n",
            "===== Start training: epoch 23 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.700584411621094, Epoch: 23, training loss: 2.761611169204116, current learning rate 1e-05\n",
            "val loss: 11.89375525712967\n",
            "accuracy:      0.886\n",
            "precision:     0.709\n",
            "recall:        0.644\n",
            "f1:            0.668\n",
            "val loss: 11.653043270111084\n",
            "accuracy:      0.893\n",
            "precision:     0.647\n",
            "recall:        0.647\n",
            "f1:            0.647\n",
            "===== Start training: epoch 24 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.702394723892212, Epoch: 24, training loss: 4.238268941175193, current learning rate 1e-05\n",
            "val loss: 12.246438890695572\n",
            "accuracy:      0.886\n",
            "precision:     0.703\n",
            "recall:        0.594\n",
            "f1:            0.620\n",
            "val loss: 10.077241078019142\n",
            "accuracy:      0.907\n",
            "precision:     0.678\n",
            "recall:        0.635\n",
            "f1:            0.652\n",
            "===== Start training: epoch 25 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.725478410720825, Epoch: 25, training loss: 3.169587672338821, current learning rate 1e-05\n",
            "val loss: 14.309978485107422\n",
            "accuracy:      0.889\n",
            "precision:     0.728\n",
            "recall:        0.548\n",
            "f1:            0.560\n",
            "val loss: 10.668179154396057\n",
            "accuracy:      0.922\n",
            "precision:     0.759\n",
            "recall:        0.587\n",
            "f1:            0.621\n",
            "===== Start training: epoch 26 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.712735414505005, Epoch: 26, training loss: 3.808637017966248, current learning rate 1e-05\n",
            "val loss: 12.787858486175537\n",
            "accuracy:      0.891\n",
            "precision:     0.753\n",
            "recall:        0.560\n",
            "f1:            0.578\n",
            "val loss: 10.055981285870075\n",
            "accuracy:      0.922\n",
            "precision:     0.751\n",
            "recall:        0.607\n",
            "f1:            0.643\n",
            "===== Start training: epoch 27 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.709736585617065, Epoch: 27, training loss: 4.429646231234074, current learning rate 1e-05\n",
            "val loss: 15.2909876704216\n",
            "accuracy:      0.885\n",
            "precision:     0.694\n",
            "recall:        0.567\n",
            "f1:            0.586\n",
            "val loss: 12.488514602184296\n",
            "accuracy:      0.915\n",
            "precision:     0.705\n",
            "recall:        0.628\n",
            "f1:            0.655\n",
            "===== Start training: epoch 28 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.70209264755249, Epoch: 28, training loss: 0.8941020534257405, current learning rate 1e-05\n",
            "val loss: 15.34474292397499\n",
            "accuracy:      0.888\n",
            "precision:     0.714\n",
            "recall:        0.561\n",
            "f1:            0.580\n",
            "val loss: 11.36662882566452\n",
            "accuracy:      0.919\n",
            "precision:     0.729\n",
            "recall:        0.616\n",
            "f1:            0.649\n",
            "===== Start training: epoch 29 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.710364103317261, Epoch: 29, training loss: 5.068010649178177, current learning rate 1e-05\n",
            "val loss: 12.533159375190735\n",
            "accuracy:      0.881\n",
            "precision:     0.686\n",
            "recall:        0.614\n",
            "f1:            0.637\n",
            "val loss: 13.392964094877243\n",
            "accuracy:      0.886\n",
            "precision:     0.632\n",
            "recall:        0.638\n",
            "f1:            0.635\n",
            "===== Start training: epoch 30 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 48/48 [00:07<00:00,  6.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timing: 7.714066982269287, Epoch: 30, training loss: 2.29906048940029, current learning rate 1e-05\n",
            "val loss: 14.449624001979828\n",
            "accuracy:      0.889\n",
            "precision:     0.717\n",
            "recall:        0.632\n",
            "f1:            0.660\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "import time\n",
        "import datasets\n",
        "import pickle\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.optim.lr_scheduler import LinearLR\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "args = {\n",
        "    \"model_name\": \"roberta-base\",\n",
        "    \"num_classes\": 2, #3, #2,\n",
        "    \"num_classes_adv\": 3, #174,\n",
        "    \"embed_size\": 768,\n",
        "    \"first_last_avg\": False,\n",
        "    \"seed\": [0,1,2],\n",
        "    \"batch_size\": 64,\n",
        "    \"epochs\": 30,\n",
        "    \"class_weight\": 10, #[9.375, 30, 1], #10 [2.071, 1.933, 1]\n",
        "    \"lr\": 1e-5\n",
        "}\n",
        "\n",
        "config = {\n",
        "    \"dataset\": \"student_essay\", #\"student_essay\", #debate, m-arg\n",
        "    \"adversarial\": False,\n",
        "    \"double_adversarial\": False,\n",
        "    \"dataset_from_saved\": False,\n",
        "    \"injection\": False,\n",
        "    \"grid_search\": False,\n",
        "    \"visualize\": True,\n",
        "    \"train\": True,\n",
        "    \"scheduler\": False,\n",
        "    \"attention\": True\n",
        "}\n",
        "\n",
        "def train(epoch, model, loss_fn, optimizer, train_loader, scheduler=None, discovery_weight=0.3, adv_weight=0.3):\n",
        "    epoch_start_time = time.time()\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    loss_fn2 = nn.CrossEntropyLoss()\n",
        "\n",
        "    for step, batch in enumerate(tqdm(train_loader, desc='Iteration')):\n",
        "        if config[\"adversarial\"]:\n",
        "          batch = tuple(t.to(device) if not isinstance(t, list) else t for t in batch)\n",
        "        else:\n",
        "          batch = tuple(t.to(device) if not isinstance(t, list) else t for t in batch) #tuple(t.to(device) for t in batch)\n",
        "\n",
        "        ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels = batch\n",
        "\n",
        "        if config[\"adversarial\"]:\n",
        "          pred, pred_adv, task_pred = model(ids_sent1, segs_sent1, att_mask_sent1, position_sep)\n",
        "          try:\n",
        "            half_batch_size = len(labels) // 2\n",
        "            targets, targets_adv, targets_task = labels[:half_batch_size], labels[half_batch_size:], [[0, 1]] * half_batch_size + [[1, 0]] * half_batch_size\n",
        "            targets, targets_adv, targets_task = torch.tensor(np.array(targets)).to(device), \\\n",
        "                                                 torch.tensor(np.array(targets_adv)).to(device), \\\n",
        "                                                 torch.tensor(np.array(targets_task)).to(device)\n",
        "          except:\n",
        "            print(\"error\")\n",
        "\n",
        "          loss1 = loss_fn(pred, targets.float())\n",
        "          loss2 = loss_fn2(pred_adv, targets_adv.float())\n",
        "          loss3 = loss_fn2(task_pred, targets_task.float())\n",
        "          loss = loss1 + discovery_weight*loss2 + adv_weight*loss3\n",
        "        elif config[\"double_adversarial\"]:\n",
        "          pred, pred_adv, task_pred, attack_pred, support_pred = model(ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels)\n",
        "          try:\n",
        "            half_batch_size = len(labels) // 2\n",
        "            targets, targets_adv, targets_task = labels[:half_batch_size], labels[half_batch_size:], [[0, 1]] * half_batch_size + [[1, 0]] * half_batch_size\n",
        "            targets, targets_adv, targets_task = torch.tensor(np.array(targets)).to(device), \\\n",
        "                                                 torch.tensor(np.array(targets_adv)).to(device), \\\n",
        "                                                 torch.tensor(np.array(targets_task)).to(device)\n",
        "            attack_target = targets[targets == [0,1]]\n",
        "            support_target = targets[targets == [1,0]]\n",
        "\n",
        "            cause_target = targets_adv[targets_adv == [1,0,0]]\n",
        "            other_target = targets_adv[targets_adv == [0,1,0] or targets_adv == [0,0,1]]\n",
        "          except:\n",
        "            print(\"error\")\n",
        "\n",
        "          loss1 = loss_fn(pred, targets.float())\n",
        "          loss2 = loss_fn2(pred_adv, targets_adv.float())\n",
        "          loss3 = loss_fn2(task_pred, targets_task.float())\n",
        "          loss4 = loss_fn2(attack_pred, attack_target.float())\n",
        "          loss5 = loss_fn2(support_pred, support_target.float())\n",
        "          loss = loss1 + discovery_weight*loss2 + adv_weight*loss3 + .2*loss4 + .2*loss5\n",
        "        else:\n",
        "          out = model(ids_sent1, segs_sent1, att_mask_sent1, position_sep)\n",
        "          if isinstance(labels, list):\n",
        "            labels = torch.tensor(np.array(labels)).to(device)\n",
        "          loss = loss_fn(out, labels.float())\n",
        "\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    timing = time.time() - epoch_start_time\n",
        "    cur_lr = optimizer.param_groups[0][\"lr\"]\n",
        "    print(f\"Timing: {timing}, Epoch: {epoch + 1}, training loss: {tr_loss}, current learning rate {cur_lr}\")\n",
        "\n",
        "def val(model, val_loader):\n",
        "    model.eval()\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    val_loss = 0\n",
        "    val_preds = []\n",
        "    val_labels = []\n",
        "    for batch in val_loader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = model(ids_sent1, segs_sent1, att_mask_sent1, position_sep)\n",
        "            preds = torch.max(out.data, 1)[1].cpu().numpy().tolist()\n",
        "            loss = loss_fn(out, labels.float())\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            labels = labels.cpu().numpy().tolist()\n",
        "\n",
        "            val_labels.extend(labels)\n",
        "            if len(labels[0]) != 2:\n",
        "              for pred in preds:\n",
        "                if pred == 0:\n",
        "                  val_preds.append([1,0,0])\n",
        "                elif pred == 1:\n",
        "                  val_preds.append([0,1,0])\n",
        "                else:\n",
        "                  val_preds.append([0,0,1])\n",
        "            else:\n",
        "              val_preds.extend([[1,0] if pred == 0 else [0,1] for pred in preds])\n",
        "\n",
        "    print(f\"val loss: {val_loss}\")\n",
        "\n",
        "    val_acc, val_prec, val_recall, val_f1 = output_metrics(val_labels, val_preds)\n",
        "    return val_acc, val_prec, val_recall, val_f1\n",
        "\n",
        "def visualize(epoch, model, test_dataloader, train_adv_dataloader, discovery_weight = 0.2, adv_weight = 0.2):\n",
        "  if not config[\"adversarial\"]:\n",
        "    return\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "  tot_labels = None\n",
        "  embeddings = None\n",
        "\n",
        "  tot_labels_adv = None\n",
        "  embeddings_adv = None\n",
        "\n",
        "  print(\"Visualizing...\")\n",
        "  for batch in tqdm(test_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels = batch\n",
        "    labels = torch.argmax(labels, dim=-1)\n",
        "    if tot_labels is None:\n",
        "      tot_labels = labels\n",
        "    else:\n",
        "      tot_labels = torch.cat([tot_labels, labels], dim=0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      out = model(ids_sent1, segs_sent1, att_mask_sent1, position_sep, visualize=True)\n",
        "      if embeddings is None:\n",
        "        embeddings = out\n",
        "      else:\n",
        "        embeddings = torch.cat([embeddings, out], dim=0)\n",
        "\n",
        "  for i, batch in tqdm(enumerate(train_adv_dataloader)):\n",
        "    if i == 20: break\n",
        "    batch = tuple(t.to(device) if not isinstance(t, list) else t for t in batch)\n",
        "    ids_sent1, segs_sent1, att_mask_sent1, position_sep, labels = batch\n",
        "    labels = torch.tensor(np.array(labels)).to(device)\n",
        "    labels = torch.argmax(labels, dim=-1)+2\n",
        "\n",
        "    if tot_labels_adv is None:\n",
        "      tot_labels_adv = labels\n",
        "    else:\n",
        "      tot_labels_adv = torch.cat([tot_labels_adv, labels], dim=0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      out = model(ids_sent1, segs_sent1, att_mask_sent1, position_sep, visualize=True)\n",
        "      if embeddings_adv is None:\n",
        "        embeddings_adv = out\n",
        "      else:\n",
        "        embeddings_adv = torch.cat([embeddings_adv, out], dim=0)\n",
        "\n",
        "  tsne = TSNE(random_state=0)\n",
        "  tsne_results = tsne.fit_transform(embeddings.cpu().numpy())\n",
        "  tsne_results_adv = tsne.fit_transform(embeddings_adv.cpu().numpy())\n",
        "\n",
        "  df_tsne = pd.DataFrame(tsne_results, columns=[\"x\",\"y\"])\n",
        "  df_tsne_adv = pd.DataFrame(tsne_results_adv, columns=[\"x\",\"y\"])\n",
        "\n",
        "  df_tsne[\"label\"] = tot_labels.cpu().numpy()\n",
        "  df_tsne_adv[\"label\"] = tot_labels_adv.cpu().numpy()\n",
        "\n",
        "  print(df_tsne_adv[\"label\"].unique())\n",
        "\n",
        "  fig1, ax1 = plt.subplots(figsize=(8,6))\n",
        "  sns.set_style('darkgrid', {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\n",
        "  sns.scatterplot(data=df_tsne, x='x', y='y', hue='label', palette='deep')\n",
        "  sns.move_legend(ax1, \"upper left\", bbox_to_anchor=(1, 1))\n",
        "  plt.title(f'Scatter plot of embeddings trained with α = {discovery_weight} and μ = {adv_weight}');\n",
        "  plt.xlabel('x');\n",
        "  plt.ylabel('y');\n",
        "  plt.axis('equal')\n",
        "  plt.show()\n",
        "\n",
        "  fig2, ax2 = plt.subplots(figsize=(8,6))\n",
        "  sns.set_style('darkgrid', {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\n",
        "  sns.scatterplot(data=df_tsne_adv, x='x', y='y', hue='label', palette='deep')\n",
        "  sns.move_legend(ax2, \"upper left\", bbox_to_anchor=(1, 1))\n",
        "  plt.title(f'Scatter plot of embeddings trained with α = {discovery_weight} and μ = {adv_weight}');\n",
        "  plt.xlabel('x');\n",
        "  plt.ylabel('y');\n",
        "  plt.axis('equal')\n",
        "  plt.show()\n",
        "\n",
        "def run(seed):\n",
        "  set_random_seeds(seed)\n",
        "\n",
        "  if config[\"dataset\"] == \"student_essay\":\n",
        "    if config[\"injection\"]:\n",
        "      processor = StudentEssayWithDiscourseInjectionProcessor()\n",
        "    else:\n",
        "      processor = StudentEssayProcessor()\n",
        "\n",
        "    path_train = \"./data/student_essay/train_essay.txt\"\n",
        "    path_dev = \"./data/student_essay/dev_essay.txt\"\n",
        "    path_test = \"./data/student_essay/test_essay.txt\"\n",
        "  elif config[\"dataset\"] == \"debate\":\n",
        "    if config[\"injection\"]:\n",
        "      processor = DebateWithDiscourseInjectionProcessor()\n",
        "    else:\n",
        "      processor = DebateProcessor()\n",
        "\n",
        "    path_train = \"./data/debate/train_debate_concept.txt\"\n",
        "    path_dev = \"./data/debate/dev_debate_concept.txt\"\n",
        "    path_test = \"./data/debate/test_debate_concept.txt\"\n",
        "  elif config[\"dataset\"] == \"m-arg\":\n",
        "    if config[\"injection\"]:\n",
        "      processor = MARGWithDiscourseInjectionProcessor()\n",
        "    else:\n",
        "      processor = MARGProcessor()\n",
        "\n",
        "    path_train = \"./data/m-arg/presidential_final.csv\"\n",
        "    path_dev = path_train\n",
        "    path_test = path_train\n",
        "  elif config[\"dataset\"] == \"nk\":\n",
        "    if config[\"injection\"]:\n",
        "      processor = NKWithDiscourseInjectionProcessor()\n",
        "    else:\n",
        "      processor = NKProcessor()\n",
        "\n",
        "    path_train = \"./data/nk/balanced_dataset.tsv\"\n",
        "  else:\n",
        "    raise ValueError(f\"{config['dataset']} is not a valid database name (choose from 'student_essay' and 'debate')\")\n",
        "\n",
        "  max_sent_length = -1\n",
        "\n",
        "  data_train = processor.read_input_files(path_train, max_sent_length, name=\"train\")\n",
        "\n",
        "  if config[\"dataset\"] == \"nk\":\n",
        "    data_dev = data_train[:len(data_train) // 10]\n",
        "    data_test = data_train[-(len(data_train) // 10):]\n",
        "    data_train = data_train[(len(data_train) // 10) : -(len(data_train) // 10)]\n",
        "  else:\n",
        "    data_dev = processor.read_input_files(path_dev, max_sent_length, name=\"dev\")\n",
        "    data_test = processor.read_input_files(path_test, max_sent_length, name=\"test\")\n",
        "\n",
        "  if config[\"adversarial\"]:\n",
        "    df = datasets.load_dataset(\"discovery\",\"discovery\")\n",
        "    adv_processor = DiscourseMarkerProcessor()\n",
        "    if not config[\"dataset_from_saved\"]:\n",
        "      print(\"processing discourse marker dataset...\")\n",
        "      train_adv = adv_processor.process_dataset(df[\"train\"])\n",
        "      with open(\"./adv_dataset.pkl\", \"wb\") as writer:\n",
        "        pickle.dump(train_adv, writer)\n",
        "    else:\n",
        "      with open(\"./adv_dataset.pkl\", \"rb\") as reader:\n",
        "        train_adv = pickle.load(reader)\n",
        "\n",
        "    data_train_tot = data_train + train_adv\n",
        "    train_set_adv = dataset(train_adv)\n",
        "  else:\n",
        "    data_train_tot = data_train\n",
        "\n",
        "  train_set = dataset(data_train_tot)\n",
        "  dev_set = dataset(data_dev)\n",
        "  test_set = dataset(data_test)\n",
        "\n",
        "  if not config[\"adversarial\"]:\n",
        "    #sampler_train = BalancedSampler(data_train, train_adv, args[\"batch_size\"])\n",
        "    #train_dataloader = DataLoader(train_set, batch_sampler=sampler_train, collate_fn=collate_fn_concatenated_adv)\n",
        "    train_dataloader = DataLoader(train_set, batch_size=args[\"batch_size\"], shuffle=True, collate_fn=collate_fn_concatenated)\n",
        "    model = BaselineModelWithSentenceComparison(attention=config[\"attention\"])\n",
        "  else:\n",
        "    sampler_train = BalancedSampler(data_train, train_adv, args[\"batch_size\"])\n",
        "    train_dataloader = DataLoader(train_set, batch_sampler=sampler_train, collate_fn=collate_fn_concatenated_adv)\n",
        "    train_adv_dataloader = DataLoader(train_set_adv, batch_size=args[\"batch_size\"], shuffle=True, collate_fn=collate_fn_concatenated_adv)\n",
        "\n",
        "    model = AdversarialNet()\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  dev_dataloader = DataLoader(dev_set, batch_size=args[\"batch_size\"], shuffle=True, collate_fn=collate_fn_concatenated)\n",
        "  test_dataloader = DataLoader(test_set, batch_size=args[\"batch_size\"], shuffle=True, collate_fn=collate_fn_concatenated)\n",
        "\n",
        "  no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "  optimizer_grouped_parameters = [\n",
        "    {\n",
        "      \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "      \"weight_decay\": 0.01,\n",
        "    },\n",
        "    {\n",
        "      \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "      \"weight_decay\": 0.0\n",
        "    },\n",
        "  ]\n",
        "  optimizer = AdamW(optimizer_grouped_parameters, lr=args[\"lr\"])\n",
        "\n",
        "  if config[\"dataset\"] in [\"m-arg\",\"nk\"]:\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=torch.tensor(args[\"class_weight\"]).to(device))\n",
        "  else:\n",
        "    loss_fn = nn.CrossEntropyLoss(weight=torch.Tensor([1, args[\"class_weight\"]]).to(device))\n",
        "\n",
        "  best_acc = -1\n",
        "  best_pre = -1\n",
        "  best_rec = -1\n",
        "  best_f1 = -1\n",
        "  best_dev_acc, best_dev_pre, best_dev_rec, best_dev_f1 = -1, -1, -1, -1\n",
        "\n",
        "  result_metrics = []\n",
        "\n",
        "  if config[\"grid_search\"]:\n",
        "    range_disc = np.arange(0,1.2,0.2)\n",
        "    range_adv = np.arange(0,1.2,0.2)\n",
        "\n",
        "    for discovery_weight in range_disc:\n",
        "      for adv_weight in range_adv:\n",
        "        for epoch in range(args[\"epochs\"]):\n",
        "          print('===== Start training: epoch {} ====='.format(epoch + 1))\n",
        "          print(f\"*** trying with discovery_weight = {discovery_weight}, adv_weight = {adv_weight}\")\n",
        "          train(epoch, model, loss_fn, optimizer, train_dataloader, discovery_weight=discovery_weight, adv_weight=adv_weight)\n",
        "          dev_a, dev_p, dev_r, dev_f1 = val(model, dev_dataloader)\n",
        "          test_a, test_p, test_r, test_f1 = val(model, test_dataloader)\n",
        "          if dev_f1 > best_dev_f1:\n",
        "            best_dev_acc, best_dev_pre, best_dev_rec, best_dev_f1 = dev_a, dev_p, dev_r, dev_f1\n",
        "            best_test_acc, best_test_pre, best_test_rec, best_test_f1 = test_a, test_p, test_r, test_f1\n",
        "            #save model\n",
        "\n",
        "        print('best result:')\n",
        "        print(best_test_acc)\n",
        "        print(best_test_pre)\n",
        "        print(best_test_rec)\n",
        "        print(best_test_f1)\n",
        "        result_metrics.append([best_test_acc, best_test_pre, best_test_rec, best_test_f1])\n",
        "        del model\n",
        "        del optimizer\n",
        "\n",
        "        set_random_seeds(args[\"seed\"])\n",
        "        model = AdversarialNet()\n",
        "        model = model.to(device)\n",
        "\n",
        "        optimizer_grouped_parameters = [\n",
        "          {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": 0.01,\n",
        "          },\n",
        "          {\n",
        "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": 0.0\n",
        "          },\n",
        "        ]\n",
        "        optimizer = AdamW(optimizer_grouped_parameters, lr=args[\"lr\"])\n",
        "\n",
        "        best_acc = -1\n",
        "        best_pre = -1\n",
        "        best_rec = -1\n",
        "        best_f1 = -1\n",
        "        best_dev_acc, best_dev_pre, best_dev_rec, best_dev_f1 = -1, -1, -1, -1\n",
        "  else:\n",
        "    if config[\"scheduler\"]:\n",
        "      scheduler = LinearLR(optimizer, start_factor=1, end_factor=1e-1, total_iters = 30)\n",
        "    for epoch in range(args[\"epochs\"]):\n",
        "      if config[\"train\"]:\n",
        "        print('===== Start training: epoch {} ====='.format(epoch + 1))\n",
        "        train(epoch, model, loss_fn, optimizer, train_dataloader, discovery_weight=0.6, adv_weight=0.6)\n",
        "        dev_a, dev_p, dev_r, dev_f1 = val(model, dev_dataloader)\n",
        "        test_a, test_p, test_r, test_f1 = val(model, test_dataloader)\n",
        "        if config[\"scheduler\"]:\n",
        "          scheduler.step()\n",
        "        if dev_f1 > best_dev_f1:\n",
        "          best_dev_acc, best_dev_pre, best_dev_rec, best_dev_f1 = dev_a, dev_p, dev_r, dev_f1\n",
        "          best_test_acc, best_test_pre, best_test_rec, best_test_f1 = test_a, test_p, test_r, test_f1\n",
        "          torch.save(model.state_dict(), f\"./{config['dataset']}_model.pt\")\n",
        "\n",
        "    if config[\"visualize\"] and config[\"adversarial\"]:\n",
        "      model.load_state_dict(torch.load(f\"./{config['dataset']}_model.pt\"))\n",
        "      visualize(epoch, model, test_dataloader, train_adv_dataloader, 0.6, 0.6)\n",
        "\n",
        "        #save model\n",
        "\n",
        "    print('best result:')\n",
        "    print(best_test_acc)\n",
        "    print(best_test_pre)\n",
        "    print(best_test_rec)\n",
        "    print(best_test_f1)\n",
        "    result_metrics.append([best_test_acc, best_test_pre, best_test_rec, best_test_f1])\n",
        "\n",
        "  print(result_metrics)\n",
        "  return result_metrics[0]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  results = []\n",
        "  for seed in args[\"seed\"]:\n",
        "    print(f\"**** trying with seed {seed} ****\")\n",
        "    result_metrics = run(seed)\n",
        "    results.append(result_metrics)\n",
        "  avg = torch.mean(torch.tensor(results), dim=0)\n",
        "  print(avg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w7siPoLeqiKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "3HwOo-fjjQpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DPCKGHFDeHpO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c18eedc7abe7424ab703825e852ee540": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a42235236d440a8a73fbfb886fefef3",
              "IPY_MODEL_bc4fb44404974a2798968b45319a9461",
              "IPY_MODEL_2a819d509f7d4c2f9a8dc17253b62d4f"
            ],
            "layout": "IPY_MODEL_d5ba67e64d334ee3878bf917c5736964"
          }
        },
        "8a42235236d440a8a73fbfb886fefef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a26382d7e4bd4fa7bd2d92b57c56da2c",
            "placeholder": "​",
            "style": "IPY_MODEL_443e5c11611a48efb2f0f790a5164d09",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "bc4fb44404974a2798968b45319a9461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a42d6a5c2f44148bb2d3f29f8fc0752",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5500233fb32543a88d7f3e06e636da13",
            "value": 25
          }
        },
        "2a819d509f7d4c2f9a8dc17253b62d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcde457264604e928234b6a0b824a062",
            "placeholder": "​",
            "style": "IPY_MODEL_8b5f66b5a2ec406f9dbfdd42d2cdf08b",
            "value": " 25.0/25.0 [00:00&lt;00:00, 1.90kB/s]"
          }
        },
        "d5ba67e64d334ee3878bf917c5736964": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a26382d7e4bd4fa7bd2d92b57c56da2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "443e5c11611a48efb2f0f790a5164d09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a42d6a5c2f44148bb2d3f29f8fc0752": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5500233fb32543a88d7f3e06e636da13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcde457264604e928234b6a0b824a062": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b5f66b5a2ec406f9dbfdd42d2cdf08b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "937cf0697d894a0381f308f317fc176a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a626e023c7f8467f8ebb4cbb11253760",
              "IPY_MODEL_d9c3e79097c64de98bc393ca3ecb0b8f",
              "IPY_MODEL_edd0b6c222c54ee9a6772c5d8dff9a67"
            ],
            "layout": "IPY_MODEL_ddf7064f0db5416eae0a0146cb9479d7"
          }
        },
        "a626e023c7f8467f8ebb4cbb11253760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0852a96548904af3916603ccd67b06ed",
            "placeholder": "​",
            "style": "IPY_MODEL_e18ad21ec9a54b2eaa7875e5c3b7bb1f",
            "value": "config.json: 100%"
          }
        },
        "d9c3e79097c64de98bc393ca3ecb0b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62939053da3b4d98bd83413af5d5f8ad",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f5830d36e9243389481448487555adc",
            "value": 481
          }
        },
        "edd0b6c222c54ee9a6772c5d8dff9a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f86827dd09954244a45160e465ff5c0d",
            "placeholder": "​",
            "style": "IPY_MODEL_1f4505324bf341dc80b4fef6d75b6b12",
            "value": " 481/481 [00:00&lt;00:00, 42.7kB/s]"
          }
        },
        "ddf7064f0db5416eae0a0146cb9479d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0852a96548904af3916603ccd67b06ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e18ad21ec9a54b2eaa7875e5c3b7bb1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62939053da3b4d98bd83413af5d5f8ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f5830d36e9243389481448487555adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f86827dd09954244a45160e465ff5c0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f4505324bf341dc80b4fef6d75b6b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6aa45c0dc01f496281bb4d602682e1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f3fddbad5e84e1cbfc5273c7d3c8c25",
              "IPY_MODEL_dc016f6b60f84fbb9c252044b9d31be5",
              "IPY_MODEL_6c57b4e578b54488b28e99ab44ad99e2"
            ],
            "layout": "IPY_MODEL_0d3ca5e7768e49bdb687402fa0d7445a"
          }
        },
        "7f3fddbad5e84e1cbfc5273c7d3c8c25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b74f56e2dd44aef846e78d7706ac625",
            "placeholder": "​",
            "style": "IPY_MODEL_db6e6f823abd4f8b8af25bbfa33cd9ba",
            "value": "vocab.json: 100%"
          }
        },
        "dc016f6b60f84fbb9c252044b9d31be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98b4cc46b42d484caaad86f22ab8fb02",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbaba3897d694cf4a33d70c3a1079f84",
            "value": 898823
          }
        },
        "6c57b4e578b54488b28e99ab44ad99e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a7d9db330e74d62afce40d26f239423",
            "placeholder": "​",
            "style": "IPY_MODEL_6ec90dbbc6a3412997de64184d7234b9",
            "value": " 899k/899k [00:00&lt;00:00, 3.56MB/s]"
          }
        },
        "0d3ca5e7768e49bdb687402fa0d7445a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b74f56e2dd44aef846e78d7706ac625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db6e6f823abd4f8b8af25bbfa33cd9ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98b4cc46b42d484caaad86f22ab8fb02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbaba3897d694cf4a33d70c3a1079f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a7d9db330e74d62afce40d26f239423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ec90dbbc6a3412997de64184d7234b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6022dfe94450439ab2c23b6076f45d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f29e2ba39f5646c8b757cca20135f3fd",
              "IPY_MODEL_84febb5759b4421a8d67b93657202e22",
              "IPY_MODEL_ff3cff3c67e94a8f9a4de646ec34acc1"
            ],
            "layout": "IPY_MODEL_fae60483c8c74b4db6243361c04c7187"
          }
        },
        "f29e2ba39f5646c8b757cca20135f3fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf93a134d8a146a5aaa837876a1f0945",
            "placeholder": "​",
            "style": "IPY_MODEL_44c65138cc74423398458dbc711a4318",
            "value": "merges.txt: 100%"
          }
        },
        "84febb5759b4421a8d67b93657202e22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4d20be069bf451b9a38429f8fef93be",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb6d08e88eff4a238a86d514c62a6578",
            "value": 456318
          }
        },
        "ff3cff3c67e94a8f9a4de646ec34acc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1259e88cfe644fd1a9e6b002b0c3cf43",
            "placeholder": "​",
            "style": "IPY_MODEL_8f893b90291347e2a8d4242279a064af",
            "value": " 456k/456k [00:00&lt;00:00, 28.3MB/s]"
          }
        },
        "fae60483c8c74b4db6243361c04c7187": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf93a134d8a146a5aaa837876a1f0945": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44c65138cc74423398458dbc711a4318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4d20be069bf451b9a38429f8fef93be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb6d08e88eff4a238a86d514c62a6578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1259e88cfe644fd1a9e6b002b0c3cf43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f893b90291347e2a8d4242279a064af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2dfe438d2594a2ab596465409488b27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b264ffb18204b77a849cd41b2ab65ee",
              "IPY_MODEL_5678de3798d1404c97aaa5b5bf2033e9",
              "IPY_MODEL_e15b1749e0c34688a84d4a1b7e287621"
            ],
            "layout": "IPY_MODEL_fbe30515e3e54cefa059ec01f25073be"
          }
        },
        "1b264ffb18204b77a849cd41b2ab65ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_685fb6c2e161458ab6941e475d80a7e5",
            "placeholder": "​",
            "style": "IPY_MODEL_22a1f72bd9294448826e66fc498525cb",
            "value": "tokenizer.json: 100%"
          }
        },
        "5678de3798d1404c97aaa5b5bf2033e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d515e206ec9049f1bd963968d4a6588c",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d1ba4fb1679403690e5ecf350ef42a5",
            "value": 1355863
          }
        },
        "e15b1749e0c34688a84d4a1b7e287621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_362080a3b8e54fc6b5c2de71445db3a8",
            "placeholder": "​",
            "style": "IPY_MODEL_97b80e7fe60a47609e3d35ab285fcedb",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 1.41MB/s]"
          }
        },
        "fbe30515e3e54cefa059ec01f25073be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "685fb6c2e161458ab6941e475d80a7e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22a1f72bd9294448826e66fc498525cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d515e206ec9049f1bd963968d4a6588c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d1ba4fb1679403690e5ecf350ef42a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "362080a3b8e54fc6b5c2de71445db3a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97b80e7fe60a47609e3d35ab285fcedb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a7cf1577fca49c6a54a215cd0b1d643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e22a92431e746709792868d3f7eae29",
              "IPY_MODEL_1b48457ed6de413ba0249fd72300635b",
              "IPY_MODEL_1909ab51eca44001ab9c5e1356cde704"
            ],
            "layout": "IPY_MODEL_eca92145a54a495e81c5e3bfefe42676"
          }
        },
        "1e22a92431e746709792868d3f7eae29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44cb560bbd3247bcb4d5e53ffe4d1f29",
            "placeholder": "​",
            "style": "IPY_MODEL_69171f81e70740de9703b0a3cfb0b088",
            "value": "model.safetensors: 100%"
          }
        },
        "1b48457ed6de413ba0249fd72300635b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc4815d494d4441b9c5dcda2c50f7910",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1965161496c34f5ea8b5bbb3b1989f4a",
            "value": 498818054
          }
        },
        "1909ab51eca44001ab9c5e1356cde704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f940e68c7c964291ab0a1c40f67d7097",
            "placeholder": "​",
            "style": "IPY_MODEL_b2471e210623410f8f7292a269b79fdd",
            "value": " 499M/499M [00:09&lt;00:00, 46.6MB/s]"
          }
        },
        "eca92145a54a495e81c5e3bfefe42676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44cb560bbd3247bcb4d5e53ffe4d1f29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69171f81e70740de9703b0a3cfb0b088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc4815d494d4441b9c5dcda2c50f7910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1965161496c34f5ea8b5bbb3b1989f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f940e68c7c964291ab0a1c40f67d7097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2471e210623410f8f7292a269b79fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}